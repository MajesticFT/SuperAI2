{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajesticFT/SuperAI2/blob/main/Week11_SmartMaintenance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPsnSOdc8GQJ",
        "outputId": "af3159fb-9893-4970-bbdc-45ba45101c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiuPuXD6O50P",
        "outputId": "7318b350-900d-4b66-fdab-3760b2342652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1YrFt22iuc_Oujg46D1-DHOX3Xs0gZJml \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1YrFt22iuc_Oujg46D1-DHOX3Xs0gZJml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JWGQr6SSp-J",
        "outputId": "22c3ed6a-6aa6-4dbc-fd45-12bb156a09d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-08 08:27:18--  https://learn.aiat.or.th/download/ryxderyseyh3535/train_data1200.zip\n",
            "Resolving learn.aiat.or.th (learn.aiat.or.th)... 110.78.211.34\n",
            "Connecting to learn.aiat.or.th (learn.aiat.or.th)|110.78.211.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-04-08 08:27:19 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://learn.aiat.or.th/download/ryxderyseyh3535/train_data1200.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX06VgMJRLuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071b71da-c5b4-4a14-a7d4-580ce2295ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/train_data600.zip, /content/train_data600.zip.zip or /content/train_data600.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q '/content/train_data600.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PhhLC-XRQYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df4b5bf-f5e1-45de-c6aa-26b84d1cdf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/train_data1200.zip, /content/train_data1200.zip.zip or /content/train_data1200.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q '/content/train_data1200.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0dX2SFMCbZG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fftpack import fft\n",
        "from scipy.signal import wiener, hilbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdJSnbifkO47",
        "outputId": "720cbc13-a363-4345-ed81-785ccdcfb0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29001"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count = 0\n",
        "for files in os.listdir('/content/drive/Shareddrives/Hackathon_Week11_Smart_Maintenance/train_data600'):\n",
        "  count+=1\n",
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYLqZaQeSFKQ"
      },
      "outputs": [],
      "source": [
        "label_600 = pd.read_csv(\"/content/drive/Shareddrives/Hackathon_Week11_Smart_Maintenance/label600.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ln1N1Jz5TESE",
        "outputId": "e28ffab4-aac3-4d1f-cbba-fce8cf3ab203"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-76e5b688-4eaf-43cb-bf9f-f65847558a37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_data1.csv</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_data2.csv</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_data3.csv</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_data4.csv</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_data5.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28995</th>\n",
              "      <td>train_data28996.csv</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28996</th>\n",
              "      <td>train_data28997.csv</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28997</th>\n",
              "      <td>train_data28998.csv</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28998</th>\n",
              "      <td>train_data28999.csv</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28999</th>\n",
              "      <td>train_data29000.csv</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76e5b688-4eaf-43cb-bf9f-f65847558a37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76e5b688-4eaf-43cb-bf9f-f65847558a37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76e5b688-4eaf-43cb-bf9f-f65847558a37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                         0   1\n",
              "0          train_data1.csv  10\n",
              "1          train_data2.csv  26\n",
              "2          train_data3.csv  14\n",
              "3          train_data4.csv   4\n",
              "4          train_data5.csv   8\n",
              "...                    ...  ..\n",
              "28995  train_data28996.csv  14\n",
              "28996  train_data28997.csv  24\n",
              "28997  train_data28998.csv   9\n",
              "28998  train_data28999.csv  19\n",
              "28999  train_data29000.csv  10\n",
              "\n",
              "[29000 rows x 2 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VRGKSq0Z71Y"
      },
      "outputs": [],
      "source": [
        "label_600[label_600[1]==0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for converting the time series to frequency domain by using FFT and applying Wiener Filter"
      ],
      "metadata": {
        "id": "V__tV5IBIIJP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMSNZ7eMSHYa"
      },
      "outputs": [],
      "source": [
        "def getFeature(sinewave):\n",
        "    sample_rate = 51200\n",
        "    start_time = 0\n",
        "    end_time = 0.25\n",
        "    time = np.arange(start_time, end_time, 1/sample_rate)\n",
        "\n",
        "    freq = fft(sinewave)/len(time)\n",
        "    hz = np.linspace(0, sample_rate/2, int(np.floor(len(time)/2)+1))\n",
        "    y=2 * np.abs(freq)\n",
        "    filtered_img = wiener(y)\n",
        "    tmp = filtered_img\n",
        "    return tmp[1:2001]\n",
        "def getFeature3channel(data):\n",
        "    return np.array(list(map(getFeature, data)))\n",
        "\n",
        "def getFeatureDataset(dataset):\n",
        "    return np.array(list(map(getFeature3channel, dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert csv to ndarray and apply FFT and Wiener filter"
      ],
      "metadata": {
        "id": "pqXJRv_-I0LQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMdQEMxhJy-2"
      },
      "outputs": [],
      "source": [
        "def preprocessing(directory, training=True):\n",
        "  x_array = []\n",
        "  y_array = []\n",
        "  file_list = []\n",
        "  for filename in tqdm(os.listdir(directory)):\n",
        "    if filename != \"label.csv\" and filename.endswith('.csv'):\n",
        "      df = pd.read_csv(os.path.join(directory, filename), header=None)\n",
        "      arr = df.to_numpy()\n",
        "      #arr_t = np.swapaxes(arr, 0, 1)\n",
        "      #ffted=[]\n",
        "      #for i in arr_t:\n",
        "\n",
        "        # dt = 0.25/12500\n",
        "        # t = np.arange(0,0.25,dt)\n",
        "        # n = len(t)\n",
        "        # L = np.arange(1,np.floor(n/2),dtype='int')\n",
        "        # fhat = np.fft.rfft(i,n)\n",
        "        # PSD = fhat*np.conj(fhat) / n\n",
        "        # freq = (1/(dt*n)) * np.arange(n)\n",
        "        # indices = PSD > 3\n",
        "        # PSDclean = PSD * indices\n",
        "        # fhat = indices * fhat\n",
        "        # ffilt = np.fft.ifft(fhat)\n",
        "        # ffted.append(np.real(PSD[L][0:200]))\n",
        "        #ffted.append(X_train)\n",
        "      #ffted = np.asarray(ffted)\n",
        "      x_array.append(arr)\n",
        "     \n",
        "      if training:\n",
        "        label = label_600[label_600[0]==filename][1]\n",
        "        y_array.append(label)\n",
        "      else: \n",
        "        file_list.append(filename)\n",
        "  \n",
        "  \n",
        "  x_array = getFeatureDataset(np.swapaxes(np.asarray(x_array), 1, 2))\n",
        "  x_array = np.expand_dims(x_array, axis=1)\n",
        "  if training:\n",
        "    y_array = np.asarray(y_array)\n",
        "    return x_array, y_array\n",
        "  else: return x_array, file_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "Gw4aHvU11CQs",
        "outputId": "d31d4407-9d8a-423b-9d9f-8a3b2929a0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 6/29029 [00:07<10:32:48,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0c7c698ce453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_array_600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_array_600\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/Shareddrives/Hackathon_Week11_Smart_Maintenance/train_data600\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_array_600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0b61ac34c637>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(directory, training)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"label.csv\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;31m#arr_t = np.swapaxes(arr, 0, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "x_array_600, y_array_600 = preprocessing(\"/content/drive/Shareddrives/Hackathon_Week11_Smart_Maintenance/train_data600\")\n",
        "x_array_600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVq5wR1GSyLi",
        "outputId": "6ed93199-429c-4dbd-e4c1-9f63605c2b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29000, 1, 3, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_array_600.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying to convert labels to 3 catagories (although it didn't work)"
      ],
      "metadata": {
        "id": "ulxgAqRkJX97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7-TVjJtp3E0"
      },
      "outputs": [],
      "source": [
        "def to3Labels(y_array):\n",
        "  size = y_array.shape[0]\n",
        "  y_array_ub = []\n",
        "  y_array_ma = []\n",
        "  y_array_mp = []\n",
        "  for i in range(size):\n",
        "\n",
        "    if y_array[i] in [0, 4, 5, 6, 7, 8, 9, 10]:\n",
        "        y_array_ub.append(0)\n",
        "    elif y_array[i] in [1, 11, 14, 17, 20, 23, 26]:  \n",
        "        y_array_ub.append(1)\n",
        "    elif y_array[i] in [2, 12, 15, 18, 21, 24, 27]:  \n",
        "        y_array_ub.append(2)\n",
        "    else:  y_array_ub.append(3)\n",
        "\n",
        "    if y_array[i] in [0, 1, 2, 3, 7, 8, 9, 10, 20, 21, 22, 23, 24, 25, 26, 27, 28]:\n",
        "        y_array_ma.append(0)\n",
        "    elif y_array[i] in [4, 11, 12, 13]:  \n",
        "        y_array_ma.append(1)\n",
        "    elif y_array[i] in [5, 14, 15, 16]:  \n",
        "        y_array_ma.append(2)\n",
        "    else: y_array_ma.append(3)\n",
        "\n",
        "    if y_array[i] in [0, 1, 2, 3, 4, 5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19]:\n",
        "        y_array_mp.append(0)\n",
        "    elif y_array[i] in [7, 20, 21, 22]:  \n",
        "        y_array_mp.append(1)\n",
        "    elif y_array[i] in [8, 23, 24, 25]:  \n",
        "        y_array_mp.append(2)\n",
        "    elif y_array[i] in [9, 26, 27, 28]:  \n",
        "        y_array_mp.append(3)\n",
        "    else: y_array_mp.append(4)\n",
        "  y_array_ub = np.asarray(y_array_ub)\n",
        "  y_array_ma = np.asarray(y_array_ma)\n",
        "  y_array_mp = np.asarray(y_array_mp)\n",
        "  return y_array_ub, y_array_ma, y_array_mp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex03H2OzUKcf"
      },
      "source": [
        "# Combined with 1200rpm dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wi0LByiUATb",
        "outputId": "da31881d-731a-4047-a5f5-27f8af9adf24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29001/29001 [08:13<00:00, 58.75it/s]\n"
          ]
        }
      ],
      "source": [
        "x_array_1200, y_array_1200 = preprocessing('/content/train_data1200')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky4upirkWnZU"
      },
      "outputs": [],
      "source": [
        "x_array = np.concatenate((x_array_600, x_array_1200))\n",
        "y_array = np.concatenate((y_array_600, y_array_1200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-skmrguW7ix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899fb2f8-13bf-4020-fcc1-17e21ad32014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58000, 1, 3, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uy9KSF0W-I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be66a726-d026-43d2-8656-e668c7b75043"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y_array.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjIlAH1UUP4F"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGuNESghXFxj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10DuqCA3XDCj"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_array, y_array, test_size=0.25, stratify= y_array, random_state=112)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9awrHHp1c-5",
        "outputId": "b60c169a-883b-4e6c-e76c-6c0caa722e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43500, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTXck4inyUvE"
      },
      "outputs": [],
      "source": [
        "#if doing 3 label categories\n",
        "y_train_ub, y_train_ma, y_train_mp = to3Labels(y_train)\n",
        "y_test_ub, y_test_ma, y_test_mp = to3Labels(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZCbHM5yaTY7",
        "outputId": "997d2d95-1274-4fd6-bc36-b8577cf6816e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43500, 1, 3, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgNB90st3NiJ",
        "outputId": "db14b2ee-0251-4613-9f6a-d7a924d2d8f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43500,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y_train_ub.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGCacC475xQQ",
        "outputId": "fae7a03d-2d1d-41f4-e392-39e2d678b490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting min2net\n",
            "  Downloading min2net-1.0.1-py3-none-any.whl (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting wget>=3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting tensorflow-addons==0.9.1\n",
            "  Downloading tensorflow_addons-0.9.1-cp37-cp37m-manylinux2010_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 17.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from min2net) (1.0.2)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.7/dist-packages (from min2net) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.37.0 in /usr/local/lib/python3.7/dist-packages (from min2net) (0.37.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.9.1->min2net) (2.7.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->min2net) (3.1.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=2349e6c3ee284ae60063144784e63b715efd997c67965db28dd43bd02eabe0d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, tensorflow-addons, min2net\n",
            "Successfully installed min2net-1.0.1 tensorflow-addons-0.9.1 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install min2net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6NuJlnQtVag"
      },
      "outputs": [],
      "source": [
        "from min2net.model import EEGNet, DeepConvNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d1969b-af21-4ac8-8e9c-b39b37505585",
        "id": "Vw7glCSZFXrD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1, 3, 2000)]      0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 8, 3, 2000)        1600      \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 8, 3, 2000)       8000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  (None, 16, 1, 2000)      48        \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 16, 1, 2000)      8000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 16, 1, 2000)       0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 16, 1, 500)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16, 1, 500)        0         \n",
            "                                                                 \n",
            " separable_conv2d (Separable  (None, 16, 1, 500)       1056      \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 16, 1, 500)       2000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 16, 1, 500)        0         \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 16, 1, 62)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 16, 1, 62)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 992)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 29)                28797     \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 29)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,501\n",
            "Trainable params: 40,501\n",
            "Non-trainable params: 9,000\n",
            "_________________________________________________________________\n",
            "The first kernel size is (1, 200)\n",
            "Epoch 1/300\n",
            "  6/170 [>.............................] - ETA: 12s - loss: 3.4422 - accuracy: 0.0332WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0511s). Check your callbacks.\n",
            "170/170 [==============================] - ETA: 0s - loss: 3.1379 - accuracy: 0.0958\n",
            "Epoch 1: val_loss improved from inf to 3.04286, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 14s 81ms/step - loss: 3.1379 - accuracy: 0.0958 - val_loss: 3.0429 - val_accuracy: 0.1214 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.7445 - accuracy: 0.1882\n",
            "Epoch 2: val_loss improved from 3.04286 to 2.75970, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.7445 - accuracy: 0.1882 - val_loss: 2.7597 - val_accuracy: 0.1924 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.7001 - accuracy: 0.1981\n",
            "Epoch 3: val_loss improved from 2.75970 to 2.67483, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.7001 - accuracy: 0.1981 - val_loss: 2.6748 - val_accuracy: 0.2097 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.6561 - accuracy: 0.1983\n",
            "Epoch 4: val_loss improved from 2.67483 to 2.62551, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 14s 80ms/step - loss: 2.6561 - accuracy: 0.1983 - val_loss: 2.6255 - val_accuracy: 0.2134 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.6259 - accuracy: 0.1943\n",
            "Epoch 5: val_loss improved from 2.62551 to 2.58197, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.6259 - accuracy: 0.1943 - val_loss: 2.5820 - val_accuracy: 0.2239 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.6006 - accuracy: 0.1975\n",
            "Epoch 6: val_loss improved from 2.58197 to 2.54252, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.6006 - accuracy: 0.1975 - val_loss: 2.5425 - val_accuracy: 0.2217 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.5757 - accuracy: 0.2037\n",
            "Epoch 7: val_loss improved from 2.54252 to 2.53319, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.5757 - accuracy: 0.2037 - val_loss: 2.5332 - val_accuracy: 0.2242 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.5613 - accuracy: 0.2078\n",
            "Epoch 8: val_loss improved from 2.53319 to 2.51137, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.5613 - accuracy: 0.2078 - val_loss: 2.5114 - val_accuracy: 0.2074 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.5398 - accuracy: 0.2099\n",
            "Epoch 9: val_loss improved from 2.51137 to 2.48027, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.5398 - accuracy: 0.2099 - val_loss: 2.4803 - val_accuracy: 0.2272 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.5249 - accuracy: 0.2139\n",
            "Epoch 10: val_loss did not improve from 2.48027\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.5249 - accuracy: 0.2139 - val_loss: 2.4905 - val_accuracy: 0.2197 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.5059 - accuracy: 0.2188\n",
            "Epoch 11: val_loss improved from 2.48027 to 2.45261, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.5059 - accuracy: 0.2188 - val_loss: 2.4526 - val_accuracy: 0.2305 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.4779 - accuracy: 0.2240\n",
            "Epoch 12: val_loss improved from 2.45261 to 2.42718, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.4779 - accuracy: 0.2240 - val_loss: 2.4272 - val_accuracy: 0.2454 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.4460 - accuracy: 0.2317\n",
            "Epoch 13: val_loss improved from 2.42718 to 2.39715, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.4460 - accuracy: 0.2317 - val_loss: 2.3971 - val_accuracy: 0.2528 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.4123 - accuracy: 0.2426\n",
            "Epoch 14: val_loss improved from 2.39715 to 2.34571, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.4123 - accuracy: 0.2426 - val_loss: 2.3457 - val_accuracy: 0.2459 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.3769 - accuracy: 0.2483\n",
            "Epoch 15: val_loss improved from 2.34571 to 2.29867, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.3769 - accuracy: 0.2483 - val_loss: 2.2987 - val_accuracy: 0.2653 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.3379 - accuracy: 0.2545\n",
            "Epoch 16: val_loss improved from 2.29867 to 2.23800, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.3379 - accuracy: 0.2545 - val_loss: 2.2380 - val_accuracy: 0.2983 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.3047 - accuracy: 0.2582\n",
            "Epoch 17: val_loss improved from 2.23800 to 2.21086, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.3047 - accuracy: 0.2582 - val_loss: 2.2109 - val_accuracy: 0.3006 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.2647 - accuracy: 0.2690\n",
            "Epoch 18: val_loss improved from 2.21086 to 2.16315, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.2647 - accuracy: 0.2690 - val_loss: 2.1632 - val_accuracy: 0.3199 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.2395 - accuracy: 0.2765\n",
            "Epoch 19: val_loss improved from 2.16315 to 2.15706, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.2395 - accuracy: 0.2765 - val_loss: 2.1571 - val_accuracy: 0.2922 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.2078 - accuracy: 0.2790\n",
            "Epoch 20: val_loss improved from 2.15706 to 2.13325, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.2078 - accuracy: 0.2790 - val_loss: 2.1332 - val_accuracy: 0.3141 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.1870 - accuracy: 0.2865\n",
            "Epoch 21: val_loss improved from 2.13325 to 2.06426, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.1870 - accuracy: 0.2865 - val_loss: 2.0643 - val_accuracy: 0.3335 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.1800 - accuracy: 0.2893\n",
            "Epoch 22: val_loss did not improve from 2.06426\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.1800 - accuracy: 0.2893 - val_loss: 2.0725 - val_accuracy: 0.3490 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.1437 - accuracy: 0.2996\n",
            "Epoch 23: val_loss improved from 2.06426 to 2.06341, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.1437 - accuracy: 0.2996 - val_loss: 2.0634 - val_accuracy: 0.3484 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.1253 - accuracy: 0.3024\n",
            "Epoch 24: val_loss improved from 2.06341 to 2.02966, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.1253 - accuracy: 0.3024 - val_loss: 2.0297 - val_accuracy: 0.3483 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.1108 - accuracy: 0.3080\n",
            "Epoch 25: val_loss improved from 2.02966 to 2.02091, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.1108 - accuracy: 0.3080 - val_loss: 2.0209 - val_accuracy: 0.3271 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.0848 - accuracy: 0.3129\n",
            "Epoch 26: val_loss improved from 2.02091 to 1.97460, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.0848 - accuracy: 0.3129 - val_loss: 1.9746 - val_accuracy: 0.3508 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.0706 - accuracy: 0.3140\n",
            "Epoch 27: val_loss improved from 1.97460 to 1.96343, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.0706 - accuracy: 0.3140 - val_loss: 1.9634 - val_accuracy: 0.3646 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.0442 - accuracy: 0.3231\n",
            "Epoch 28: val_loss improved from 1.96343 to 1.92176, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.0442 - accuracy: 0.3231 - val_loss: 1.9218 - val_accuracy: 0.3861 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.0232 - accuracy: 0.3289\n",
            "Epoch 29: val_loss improved from 1.92176 to 1.91373, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 2.0232 - accuracy: 0.3289 - val_loss: 1.9137 - val_accuracy: 0.3695 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 2.0033 - accuracy: 0.3364\n",
            "Epoch 30: val_loss improved from 1.91373 to 1.88096, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 2.0033 - accuracy: 0.3364 - val_loss: 1.8810 - val_accuracy: 0.3993 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9970 - accuracy: 0.3374\n",
            "Epoch 31: val_loss improved from 1.88096 to 1.87678, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.9970 - accuracy: 0.3374 - val_loss: 1.8768 - val_accuracy: 0.3977 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9731 - accuracy: 0.3422\n",
            "Epoch 32: val_loss did not improve from 1.87678\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.9731 - accuracy: 0.3422 - val_loss: 1.9210 - val_accuracy: 0.3528 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9655 - accuracy: 0.3461\n",
            "Epoch 33: val_loss improved from 1.87678 to 1.85899, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.9655 - accuracy: 0.3461 - val_loss: 1.8590 - val_accuracy: 0.4144 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9466 - accuracy: 0.3524\n",
            "Epoch 34: val_loss improved from 1.85899 to 1.83887, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.9466 - accuracy: 0.3524 - val_loss: 1.8389 - val_accuracy: 0.3662 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9402 - accuracy: 0.3494\n",
            "Epoch 35: val_loss improved from 1.83887 to 1.80931, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.9402 - accuracy: 0.3494 - val_loss: 1.8093 - val_accuracy: 0.3994 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9174 - accuracy: 0.3595\n",
            "Epoch 36: val_loss did not improve from 1.80931\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.9174 - accuracy: 0.3595 - val_loss: 1.8103 - val_accuracy: 0.4197 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.9101 - accuracy: 0.3578\n",
            "Epoch 37: val_loss improved from 1.80931 to 1.76935, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.9101 - accuracy: 0.3578 - val_loss: 1.7693 - val_accuracy: 0.4146 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8968 - accuracy: 0.3631\n",
            "Epoch 38: val_loss improved from 1.76935 to 1.75007, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8968 - accuracy: 0.3631 - val_loss: 1.7501 - val_accuracy: 0.4474 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8905 - accuracy: 0.3669\n",
            "Epoch 39: val_loss did not improve from 1.75007\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8905 - accuracy: 0.3669 - val_loss: 1.7766 - val_accuracy: 0.4339 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8729 - accuracy: 0.3692\n",
            "Epoch 40: val_loss improved from 1.75007 to 1.72589, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8729 - accuracy: 0.3692 - val_loss: 1.7259 - val_accuracy: 0.4157 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8631 - accuracy: 0.3713\n",
            "Epoch 41: val_loss did not improve from 1.72589\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.8631 - accuracy: 0.3713 - val_loss: 1.7310 - val_accuracy: 0.4415 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8508 - accuracy: 0.3756\n",
            "Epoch 42: val_loss did not improve from 1.72589\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8508 - accuracy: 0.3756 - val_loss: 1.7267 - val_accuracy: 0.4712 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8480 - accuracy: 0.3773\n",
            "Epoch 43: val_loss did not improve from 1.72589\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.8480 - accuracy: 0.3773 - val_loss: 1.7313 - val_accuracy: 0.4528 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8317 - accuracy: 0.3792\n",
            "Epoch 44: val_loss improved from 1.72589 to 1.70811, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8317 - accuracy: 0.3792 - val_loss: 1.7081 - val_accuracy: 0.4175 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8167 - accuracy: 0.3841\n",
            "Epoch 45: val_loss did not improve from 1.70811\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.8167 - accuracy: 0.3841 - val_loss: 1.7265 - val_accuracy: 0.4159 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8104 - accuracy: 0.3852\n",
            "Epoch 46: val_loss improved from 1.70811 to 1.69354, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8104 - accuracy: 0.3852 - val_loss: 1.6935 - val_accuracy: 0.4120 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8032 - accuracy: 0.3917\n",
            "Epoch 47: val_loss improved from 1.69354 to 1.66883, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.8032 - accuracy: 0.3917 - val_loss: 1.6688 - val_accuracy: 0.4690 - lr: 0.0010\n",
            "Epoch 48/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7941 - accuracy: 0.3964\n",
            "Epoch 48: val_loss did not improve from 1.66883\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7941 - accuracy: 0.3964 - val_loss: 1.6822 - val_accuracy: 0.4410 - lr: 0.0010\n",
            "Epoch 49/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.8018 - accuracy: 0.3906\n",
            "Epoch 49: val_loss improved from 1.66883 to 1.64360, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.8018 - accuracy: 0.3906 - val_loss: 1.6436 - val_accuracy: 0.4672 - lr: 0.0010\n",
            "Epoch 50/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7703 - accuracy: 0.4002\n",
            "Epoch 50: val_loss improved from 1.64360 to 1.63338, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7703 - accuracy: 0.4002 - val_loss: 1.6334 - val_accuracy: 0.4647 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7617 - accuracy: 0.4044\n",
            "Epoch 51: val_loss improved from 1.63338 to 1.62222, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7617 - accuracy: 0.4044 - val_loss: 1.6222 - val_accuracy: 0.4639 - lr: 0.0010\n",
            "Epoch 52/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7469 - accuracy: 0.4077\n",
            "Epoch 52: val_loss did not improve from 1.62222\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7469 - accuracy: 0.4077 - val_loss: 1.6926 - val_accuracy: 0.4779 - lr: 0.0010\n",
            "Epoch 53/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7490 - accuracy: 0.4095\n",
            "Epoch 53: val_loss improved from 1.62222 to 1.61164, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7490 - accuracy: 0.4095 - val_loss: 1.6116 - val_accuracy: 0.4865 - lr: 0.0010\n",
            "Epoch 54/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7208 - accuracy: 0.4146\n",
            "Epoch 54: val_loss improved from 1.61164 to 1.59438, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7208 - accuracy: 0.4146 - val_loss: 1.5944 - val_accuracy: 0.4714 - lr: 0.0010\n",
            "Epoch 55/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7274 - accuracy: 0.4156\n",
            "Epoch 55: val_loss improved from 1.59438 to 1.57077, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7274 - accuracy: 0.4156 - val_loss: 1.5708 - val_accuracy: 0.5137 - lr: 0.0010\n",
            "Epoch 56/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.7141 - accuracy: 0.4160\n",
            "Epoch 56: val_loss did not improve from 1.57077\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.7141 - accuracy: 0.4160 - val_loss: 1.5765 - val_accuracy: 0.5081 - lr: 0.0010\n",
            "Epoch 57/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6963 - accuracy: 0.4238\n",
            "Epoch 57: val_loss improved from 1.57077 to 1.55979, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6963 - accuracy: 0.4238 - val_loss: 1.5598 - val_accuracy: 0.4899 - lr: 0.0010\n",
            "Epoch 58/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6798 - accuracy: 0.4291\n",
            "Epoch 58: val_loss improved from 1.55979 to 1.55237, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6798 - accuracy: 0.4291 - val_loss: 1.5524 - val_accuracy: 0.4734 - lr: 0.0010\n",
            "Epoch 59/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6690 - accuracy: 0.4279\n",
            "Epoch 59: val_loss did not improve from 1.55237\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.6690 - accuracy: 0.4279 - val_loss: 1.5570 - val_accuracy: 0.5032 - lr: 0.0010\n",
            "Epoch 60/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6794 - accuracy: 0.4248\n",
            "Epoch 60: val_loss improved from 1.55237 to 1.51404, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6794 - accuracy: 0.4248 - val_loss: 1.5140 - val_accuracy: 0.4974 - lr: 0.0010\n",
            "Epoch 61/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6521 - accuracy: 0.4360\n",
            "Epoch 61: val_loss did not improve from 1.51404\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.6521 - accuracy: 0.4360 - val_loss: 1.5214 - val_accuracy: 0.4923 - lr: 0.0010\n",
            "Epoch 62/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 0.4348\n",
            "Epoch 62: val_loss did not improve from 1.51404\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6456 - accuracy: 0.4348 - val_loss: 1.5256 - val_accuracy: 0.4996 - lr: 0.0010\n",
            "Epoch 63/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6427 - accuracy: 0.4364\n",
            "Epoch 63: val_loss improved from 1.51404 to 1.50276, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6427 - accuracy: 0.4364 - val_loss: 1.5028 - val_accuracy: 0.5032 - lr: 0.0010\n",
            "Epoch 64/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6195 - accuracy: 0.4479\n",
            "Epoch 64: val_loss improved from 1.50276 to 1.47625, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6195 - accuracy: 0.4479 - val_loss: 1.4763 - val_accuracy: 0.5207 - lr: 0.0010\n",
            "Epoch 65/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6216 - accuracy: 0.4462\n",
            "Epoch 65: val_loss did not improve from 1.47625\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6216 - accuracy: 0.4462 - val_loss: 1.4880 - val_accuracy: 0.5022 - lr: 0.0010\n",
            "Epoch 66/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.6009 - accuracy: 0.4503\n",
            "Epoch 66: val_loss did not improve from 1.47625\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.6009 - accuracy: 0.4503 - val_loss: 1.5065 - val_accuracy: 0.5018 - lr: 0.0010\n",
            "Epoch 67/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5959 - accuracy: 0.4532\n",
            "Epoch 67: val_loss improved from 1.47625 to 1.46867, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5959 - accuracy: 0.4532 - val_loss: 1.4687 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 68/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5832 - accuracy: 0.4537\n",
            "Epoch 68: val_loss improved from 1.46867 to 1.43073, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5832 - accuracy: 0.4537 - val_loss: 1.4307 - val_accuracy: 0.5165 - lr: 0.0010\n",
            "Epoch 69/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5755 - accuracy: 0.4590\n",
            "Epoch 69: val_loss improved from 1.43073 to 1.41663, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5755 - accuracy: 0.4590 - val_loss: 1.4166 - val_accuracy: 0.5314 - lr: 0.0010\n",
            "Epoch 70/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5713 - accuracy: 0.4548\n",
            "Epoch 70: val_loss did not improve from 1.41663\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.5713 - accuracy: 0.4548 - val_loss: 1.4495 - val_accuracy: 0.5088 - lr: 0.0010\n",
            "Epoch 71/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5676 - accuracy: 0.4618\n",
            "Epoch 71: val_loss did not improve from 1.41663\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5676 - accuracy: 0.4618 - val_loss: 1.4331 - val_accuracy: 0.5339 - lr: 0.0010\n",
            "Epoch 72/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5428 - accuracy: 0.4666\n",
            "Epoch 72: val_loss improved from 1.41663 to 1.41634, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5428 - accuracy: 0.4666 - val_loss: 1.4163 - val_accuracy: 0.5112 - lr: 0.0010\n",
            "Epoch 73/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5386 - accuracy: 0.4673\n",
            "Epoch 73: val_loss improved from 1.41634 to 1.38785, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5386 - accuracy: 0.4673 - val_loss: 1.3879 - val_accuracy: 0.5393 - lr: 0.0010\n",
            "Epoch 74/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5380 - accuracy: 0.4681\n",
            "Epoch 74: val_loss did not improve from 1.38785\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5380 - accuracy: 0.4681 - val_loss: 1.3973 - val_accuracy: 0.5526 - lr: 0.0010\n",
            "Epoch 75/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5222 - accuracy: 0.4759\n",
            "Epoch 75: val_loss improved from 1.38785 to 1.37080, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5222 - accuracy: 0.4759 - val_loss: 1.3708 - val_accuracy: 0.5341 - lr: 0.0010\n",
            "Epoch 76/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5231 - accuracy: 0.4696\n",
            "Epoch 76: val_loss did not improve from 1.37080\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5231 - accuracy: 0.4696 - val_loss: 1.3947 - val_accuracy: 0.5378 - lr: 0.0010\n",
            "Epoch 77/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5160 - accuracy: 0.4723\n",
            "Epoch 77: val_loss did not improve from 1.37080\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5160 - accuracy: 0.4723 - val_loss: 1.3807 - val_accuracy: 0.5249 - lr: 0.0010\n",
            "Epoch 78/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5080 - accuracy: 0.4722\n",
            "Epoch 78: val_loss did not improve from 1.37080\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.5080 - accuracy: 0.4722 - val_loss: 1.3781 - val_accuracy: 0.5462 - lr: 0.0010\n",
            "Epoch 79/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.5160 - accuracy: 0.4706\n",
            "Epoch 79: val_loss improved from 1.37080 to 1.34767, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.5160 - accuracy: 0.4706 - val_loss: 1.3477 - val_accuracy: 0.5623 - lr: 0.0010\n",
            "Epoch 80/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4855 - accuracy: 0.4824\n",
            "Epoch 80: val_loss did not improve from 1.34767\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4855 - accuracy: 0.4824 - val_loss: 1.3547 - val_accuracy: 0.5478 - lr: 0.0010\n",
            "Epoch 81/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4859 - accuracy: 0.4822\n",
            "Epoch 81: val_loss did not improve from 1.34767\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4859 - accuracy: 0.4822 - val_loss: 1.3618 - val_accuracy: 0.5495 - lr: 0.0010\n",
            "Epoch 82/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4914 - accuracy: 0.4755\n",
            "Epoch 82: val_loss did not improve from 1.34767\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4914 - accuracy: 0.4755 - val_loss: 1.3677 - val_accuracy: 0.5581 - lr: 0.0010\n",
            "Epoch 83/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4700 - accuracy: 0.4837\n",
            "Epoch 83: val_loss improved from 1.34767 to 1.34423, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4700 - accuracy: 0.4837 - val_loss: 1.3442 - val_accuracy: 0.5406 - lr: 0.0010\n",
            "Epoch 84/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4672 - accuracy: 0.4826\n",
            "Epoch 84: val_loss improved from 1.34423 to 1.32979, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4672 - accuracy: 0.4826 - val_loss: 1.3298 - val_accuracy: 0.5423 - lr: 0.0010\n",
            "Epoch 85/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4590 - accuracy: 0.4825\n",
            "Epoch 85: val_loss improved from 1.32979 to 1.30779, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4590 - accuracy: 0.4825 - val_loss: 1.3078 - val_accuracy: 0.5582 - lr: 0.0010\n",
            "Epoch 86/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4546 - accuracy: 0.4902\n",
            "Epoch 86: val_loss did not improve from 1.30779\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4546 - accuracy: 0.4902 - val_loss: 1.3125 - val_accuracy: 0.5370 - lr: 0.0010\n",
            "Epoch 87/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4464 - accuracy: 0.4885\n",
            "Epoch 87: val_loss improved from 1.30779 to 1.28575, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4464 - accuracy: 0.4885 - val_loss: 1.2858 - val_accuracy: 0.5770 - lr: 0.0010\n",
            "Epoch 88/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4333 - accuracy: 0.4944\n",
            "Epoch 88: val_loss did not improve from 1.28575\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4333 - accuracy: 0.4944 - val_loss: 1.3215 - val_accuracy: 0.5494 - lr: 0.0010\n",
            "Epoch 89/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4493 - accuracy: 0.4878\n",
            "Epoch 89: val_loss did not improve from 1.28575\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4493 - accuracy: 0.4878 - val_loss: 1.3002 - val_accuracy: 0.5474 - lr: 0.0010\n",
            "Epoch 90/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4414 - accuracy: 0.4890\n",
            "Epoch 90: val_loss improved from 1.28575 to 1.27981, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4414 - accuracy: 0.4890 - val_loss: 1.2798 - val_accuracy: 0.5834 - lr: 0.0010\n",
            "Epoch 91/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4211 - accuracy: 0.4955\n",
            "Epoch 91: val_loss improved from 1.27981 to 1.27645, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4211 - accuracy: 0.4955 - val_loss: 1.2765 - val_accuracy: 0.5836 - lr: 0.0010\n",
            "Epoch 92/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4380 - accuracy: 0.4885\n",
            "Epoch 92: val_loss improved from 1.27645 to 1.26037, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4380 - accuracy: 0.4885 - val_loss: 1.2604 - val_accuracy: 0.5557 - lr: 0.0010\n",
            "Epoch 93/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4303 - accuracy: 0.4904\n",
            "Epoch 93: val_loss did not improve from 1.26037\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4303 - accuracy: 0.4904 - val_loss: 1.2688 - val_accuracy: 0.5623 - lr: 0.0010\n",
            "Epoch 94/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4084 - accuracy: 0.4998\n",
            "Epoch 94: val_loss did not improve from 1.26037\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4084 - accuracy: 0.4998 - val_loss: 1.3446 - val_accuracy: 0.5676 - lr: 0.0010\n",
            "Epoch 95/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4151 - accuracy: 0.4970\n",
            "Epoch 95: val_loss did not improve from 1.26037\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.4151 - accuracy: 0.4970 - val_loss: 1.3040 - val_accuracy: 0.5428 - lr: 0.0010\n",
            "Epoch 96/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4059 - accuracy: 0.4990\n",
            "Epoch 96: val_loss did not improve from 1.26037\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4059 - accuracy: 0.4990 - val_loss: 1.2833 - val_accuracy: 0.5749 - lr: 0.0010\n",
            "Epoch 97/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4049 - accuracy: 0.5007\n",
            "Epoch 97: val_loss did not improve from 1.26037\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.4049 - accuracy: 0.5007 - val_loss: 1.2634 - val_accuracy: 0.5620 - lr: 0.0010\n",
            "Epoch 98/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3896 - accuracy: 0.5020\n",
            "Epoch 98: val_loss improved from 1.26037 to 1.21918, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.3896 - accuracy: 0.5020 - val_loss: 1.2192 - val_accuracy: 0.5863 - lr: 0.0010\n",
            "Epoch 99/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3977 - accuracy: 0.5024\n",
            "Epoch 99: val_loss did not improve from 1.21918\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3977 - accuracy: 0.5024 - val_loss: 1.2657 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 100/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3822 - accuracy: 0.5078\n",
            "Epoch 100: val_loss did not improve from 1.21918\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3822 - accuracy: 0.5078 - val_loss: 1.2226 - val_accuracy: 0.5754 - lr: 0.0010\n",
            "Epoch 101/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.5074\n",
            "Epoch 101: val_loss did not improve from 1.21918\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3761 - accuracy: 0.5074 - val_loss: 1.2244 - val_accuracy: 0.5844 - lr: 0.0010\n",
            "Epoch 102/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3784 - accuracy: 0.5063\n",
            "Epoch 102: val_loss improved from 1.21918 to 1.21734, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3784 - accuracy: 0.5063 - val_loss: 1.2173 - val_accuracy: 0.5743 - lr: 0.0010\n",
            "Epoch 103/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3756 - accuracy: 0.5043\n",
            "Epoch 103: val_loss did not improve from 1.21734\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.3756 - accuracy: 0.5043 - val_loss: 1.2256 - val_accuracy: 0.5447 - lr: 0.0010\n",
            "Epoch 104/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3793 - accuracy: 0.5073\n",
            "Epoch 104: val_loss did not improve from 1.21734\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3793 - accuracy: 0.5073 - val_loss: 1.2554 - val_accuracy: 0.5632 - lr: 0.0010\n",
            "Epoch 105/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3726 - accuracy: 0.5036\n",
            "Epoch 105: val_loss did not improve from 1.21734\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3726 - accuracy: 0.5036 - val_loss: 1.2348 - val_accuracy: 0.5810 - lr: 0.0010\n",
            "Epoch 106/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3758 - accuracy: 0.5055\n",
            "Epoch 106: val_loss improved from 1.21734 to 1.21301, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3758 - accuracy: 0.5055 - val_loss: 1.2130 - val_accuracy: 0.5766 - lr: 0.0010\n",
            "Epoch 107/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3623 - accuracy: 0.5117\n",
            "Epoch 107: val_loss did not improve from 1.21301\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3623 - accuracy: 0.5117 - val_loss: 1.2301 - val_accuracy: 0.5247 - lr: 0.0010\n",
            "Epoch 108/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3552 - accuracy: 0.5094\n",
            "Epoch 108: val_loss improved from 1.21301 to 1.19777, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3552 - accuracy: 0.5094 - val_loss: 1.1978 - val_accuracy: 0.5952 - lr: 0.0010\n",
            "Epoch 109/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3584 - accuracy: 0.5112\n",
            "Epoch 109: val_loss did not improve from 1.19777\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3584 - accuracy: 0.5112 - val_loss: 1.2198 - val_accuracy: 0.5766 - lr: 0.0010\n",
            "Epoch 110/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3448 - accuracy: 0.5128\n",
            "Epoch 110: val_loss improved from 1.19777 to 1.16553, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3448 - accuracy: 0.5128 - val_loss: 1.1655 - val_accuracy: 0.5985 - lr: 0.0010\n",
            "Epoch 111/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3480 - accuracy: 0.5146\n",
            "Epoch 111: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3480 - accuracy: 0.5146 - val_loss: 1.2214 - val_accuracy: 0.5547 - lr: 0.0010\n",
            "Epoch 112/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3383 - accuracy: 0.5157\n",
            "Epoch 112: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3383 - accuracy: 0.5157 - val_loss: 1.1759 - val_accuracy: 0.5867 - lr: 0.0010\n",
            "Epoch 113/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3330 - accuracy: 0.5171\n",
            "Epoch 113: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3330 - accuracy: 0.5171 - val_loss: 1.1712 - val_accuracy: 0.5886 - lr: 0.0010\n",
            "Epoch 114/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3389 - accuracy: 0.5148\n",
            "Epoch 114: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3389 - accuracy: 0.5148 - val_loss: 1.1865 - val_accuracy: 0.5957 - lr: 0.0010\n",
            "Epoch 115/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3301 - accuracy: 0.5213\n",
            "Epoch 115: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3301 - accuracy: 0.5213 - val_loss: 1.2107 - val_accuracy: 0.5748 - lr: 0.0010\n",
            "Epoch 116/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3384 - accuracy: 0.5178\n",
            "Epoch 116: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3384 - accuracy: 0.5178 - val_loss: 1.1734 - val_accuracy: 0.5856 - lr: 0.0010\n",
            "Epoch 117/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3145 - accuracy: 0.5257\n",
            "Epoch 117: val_loss did not improve from 1.16553\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.3145 - accuracy: 0.5257 - val_loss: 1.1866 - val_accuracy: 0.5880 - lr: 0.0010\n",
            "Epoch 118/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3241 - accuracy: 0.5203\n",
            "Epoch 118: val_loss did not improve from 1.16553\n",
            "\n",
            "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.3241 - accuracy: 0.5203 - val_loss: 1.1738 - val_accuracy: 0.5865 - lr: 0.0010\n",
            "Epoch 119/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2243 - accuracy: 0.5593\n",
            "Epoch 119: val_loss improved from 1.16553 to 1.11229, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2243 - accuracy: 0.5593 - val_loss: 1.1123 - val_accuracy: 0.6195 - lr: 5.0000e-04\n",
            "Epoch 120/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2156 - accuracy: 0.5601\n",
            "Epoch 120: val_loss improved from 1.11229 to 1.10412, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2156 - accuracy: 0.5601 - val_loss: 1.1041 - val_accuracy: 0.5921 - lr: 5.0000e-04\n",
            "Epoch 121/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2077 - accuracy: 0.5657\n",
            "Epoch 121: val_loss improved from 1.10412 to 1.07263, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2077 - accuracy: 0.5657 - val_loss: 1.0726 - val_accuracy: 0.6230 - lr: 5.0000e-04\n",
            "Epoch 122/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2087 - accuracy: 0.5606\n",
            "Epoch 122: val_loss did not improve from 1.07263\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2087 - accuracy: 0.5606 - val_loss: 1.0937 - val_accuracy: 0.6305 - lr: 5.0000e-04\n",
            "Epoch 123/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2062 - accuracy: 0.5610\n",
            "Epoch 123: val_loss did not improve from 1.07263\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2062 - accuracy: 0.5610 - val_loss: 1.0824 - val_accuracy: 0.6268 - lr: 5.0000e-04\n",
            "Epoch 124/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2125 - accuracy: 0.5626\n",
            "Epoch 124: val_loss did not improve from 1.07263\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2125 - accuracy: 0.5626 - val_loss: 1.0729 - val_accuracy: 0.6110 - lr: 5.0000e-04\n",
            "Epoch 125/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2088 - accuracy: 0.5635\n",
            "Epoch 125: val_loss improved from 1.07263 to 1.06322, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2088 - accuracy: 0.5635 - val_loss: 1.0632 - val_accuracy: 0.6230 - lr: 5.0000e-04\n",
            "Epoch 126/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2097 - accuracy: 0.5582\n",
            "Epoch 126: val_loss did not improve from 1.06322\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2097 - accuracy: 0.5582 - val_loss: 1.0700 - val_accuracy: 0.6296 - lr: 5.0000e-04\n",
            "Epoch 127/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2028 - accuracy: 0.5640\n",
            "Epoch 127: val_loss improved from 1.06322 to 1.06032, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2028 - accuracy: 0.5640 - val_loss: 1.0603 - val_accuracy: 0.6334 - lr: 5.0000e-04\n",
            "Epoch 128/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2027 - accuracy: 0.5630\n",
            "Epoch 128: val_loss improved from 1.06032 to 1.04364, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2027 - accuracy: 0.5630 - val_loss: 1.0436 - val_accuracy: 0.6400 - lr: 5.0000e-04\n",
            "Epoch 129/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1946 - accuracy: 0.5661\n",
            "Epoch 129: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1946 - accuracy: 0.5661 - val_loss: 1.0572 - val_accuracy: 0.6219 - lr: 5.0000e-04\n",
            "Epoch 130/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.2001 - accuracy: 0.5647\n",
            "Epoch 130: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.2001 - accuracy: 0.5647 - val_loss: 1.0739 - val_accuracy: 0.6279 - lr: 5.0000e-04\n",
            "Epoch 131/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1941 - accuracy: 0.5680\n",
            "Epoch 131: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1941 - accuracy: 0.5680 - val_loss: 1.0581 - val_accuracy: 0.6181 - lr: 5.0000e-04\n",
            "Epoch 132/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1953 - accuracy: 0.5639\n",
            "Epoch 132: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1953 - accuracy: 0.5639 - val_loss: 1.0656 - val_accuracy: 0.6282 - lr: 5.0000e-04\n",
            "Epoch 133/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1949 - accuracy: 0.5644\n",
            "Epoch 133: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1949 - accuracy: 0.5644 - val_loss: 1.0468 - val_accuracy: 0.6283 - lr: 5.0000e-04\n",
            "Epoch 134/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1904 - accuracy: 0.5642\n",
            "Epoch 134: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1904 - accuracy: 0.5642 - val_loss: 1.0662 - val_accuracy: 0.6325 - lr: 5.0000e-04\n",
            "Epoch 135/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1892 - accuracy: 0.5667\n",
            "Epoch 135: val_loss did not improve from 1.04364\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1892 - accuracy: 0.5667 - val_loss: 1.0608 - val_accuracy: 0.6203 - lr: 5.0000e-04\n",
            "Epoch 136/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1861 - accuracy: 0.5673\n",
            "Epoch 136: val_loss did not improve from 1.04364\n",
            "\n",
            "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1861 - accuracy: 0.5673 - val_loss: 1.0437 - val_accuracy: 0.6223 - lr: 5.0000e-04\n",
            "Epoch 137/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1335 - accuracy: 0.5889\n",
            "Epoch 137: val_loss improved from 1.04364 to 1.00544, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1335 - accuracy: 0.5889 - val_loss: 1.0054 - val_accuracy: 0.6490 - lr: 2.5000e-04\n",
            "Epoch 138/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1242 - accuracy: 0.5924\n",
            "Epoch 138: val_loss did not improve from 1.00544\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1242 - accuracy: 0.5924 - val_loss: 1.0091 - val_accuracy: 0.6475 - lr: 2.5000e-04\n",
            "Epoch 139/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1243 - accuracy: 0.5918\n",
            "Epoch 139: val_loss did not improve from 1.00544\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1243 - accuracy: 0.5918 - val_loss: 1.0100 - val_accuracy: 0.6468 - lr: 2.5000e-04\n",
            "Epoch 140/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1172 - accuracy: 0.5966\n",
            "Epoch 140: val_loss improved from 1.00544 to 1.00334, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1172 - accuracy: 0.5966 - val_loss: 1.0033 - val_accuracy: 0.6430 - lr: 2.5000e-04\n",
            "Epoch 141/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1135 - accuracy: 0.5984\n",
            "Epoch 141: val_loss improved from 1.00334 to 0.99967, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1135 - accuracy: 0.5984 - val_loss: 0.9997 - val_accuracy: 0.6448 - lr: 2.5000e-04\n",
            "Epoch 142/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1136 - accuracy: 0.5991\n",
            "Epoch 142: val_loss did not improve from 0.99967\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1136 - accuracy: 0.5991 - val_loss: 0.9999 - val_accuracy: 0.6545 - lr: 2.5000e-04\n",
            "Epoch 143/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1107 - accuracy: 0.5996\n",
            "Epoch 143: val_loss did not improve from 0.99967\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1107 - accuracy: 0.5996 - val_loss: 1.0047 - val_accuracy: 0.6466 - lr: 2.5000e-04\n",
            "Epoch 144/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1145 - accuracy: 0.5976\n",
            "Epoch 144: val_loss improved from 0.99967 to 0.99848, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1145 - accuracy: 0.5976 - val_loss: 0.9985 - val_accuracy: 0.6469 - lr: 2.5000e-04\n",
            "Epoch 145/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1136 - accuracy: 0.5966\n",
            "Epoch 145: val_loss improved from 0.99848 to 0.99087, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.1136 - accuracy: 0.5966 - val_loss: 0.9909 - val_accuracy: 0.6477 - lr: 2.5000e-04\n",
            "Epoch 146/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1095 - accuracy: 0.5957\n",
            "Epoch 146: val_loss did not improve from 0.99087\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1095 - accuracy: 0.5957 - val_loss: 0.9931 - val_accuracy: 0.6532 - lr: 2.5000e-04\n",
            "Epoch 147/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1166 - accuracy: 0.5899\n",
            "Epoch 147: val_loss did not improve from 0.99087\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1166 - accuracy: 0.5899 - val_loss: 1.0119 - val_accuracy: 0.6327 - lr: 2.5000e-04\n",
            "Epoch 148/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1135 - accuracy: 0.5914\n",
            "Epoch 148: val_loss did not improve from 0.99087\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1135 - accuracy: 0.5914 - val_loss: 0.9914 - val_accuracy: 0.6552 - lr: 2.5000e-04\n",
            "Epoch 149/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1090 - accuracy: 0.5952\n",
            "Epoch 149: val_loss did not improve from 0.99087\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1090 - accuracy: 0.5952 - val_loss: 0.9914 - val_accuracy: 0.6539 - lr: 2.5000e-04\n",
            "Epoch 150/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1076 - accuracy: 0.5970\n",
            "Epoch 150: val_loss did not improve from 0.99087\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1076 - accuracy: 0.5970 - val_loss: 0.9944 - val_accuracy: 0.6421 - lr: 2.5000e-04\n",
            "Epoch 151/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1128 - accuracy: 0.5947\n",
            "Epoch 151: val_loss improved from 0.99087 to 0.99026, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1128 - accuracy: 0.5947 - val_loss: 0.9903 - val_accuracy: 0.6490 - lr: 2.5000e-04\n",
            "Epoch 152/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1037 - accuracy: 0.5980\n",
            "Epoch 152: val_loss did not improve from 0.99026\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1037 - accuracy: 0.5980 - val_loss: 1.0027 - val_accuracy: 0.6555 - lr: 2.5000e-04\n",
            "Epoch 153/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1036 - accuracy: 0.5943\n",
            "Epoch 153: val_loss improved from 0.99026 to 0.98579, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1036 - accuracy: 0.5943 - val_loss: 0.9858 - val_accuracy: 0.6589 - lr: 2.5000e-04\n",
            "Epoch 154/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1010 - accuracy: 0.6037\n",
            "Epoch 154: val_loss improved from 0.98579 to 0.98189, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1010 - accuracy: 0.6037 - val_loss: 0.9819 - val_accuracy: 0.6570 - lr: 2.5000e-04\n",
            "Epoch 155/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.6016\n",
            "Epoch 155: val_loss did not improve from 0.98189\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0960 - accuracy: 0.6016 - val_loss: 0.9880 - val_accuracy: 0.6557 - lr: 2.5000e-04\n",
            "Epoch 156/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0979 - accuracy: 0.6024\n",
            "Epoch 156: val_loss improved from 0.98189 to 0.98153, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.0979 - accuracy: 0.6024 - val_loss: 0.9815 - val_accuracy: 0.6631 - lr: 2.5000e-04\n",
            "Epoch 157/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.6001\n",
            "Epoch 157: val_loss did not improve from 0.98153\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0958 - accuracy: 0.6001 - val_loss: 0.9946 - val_accuracy: 0.6366 - lr: 2.5000e-04\n",
            "Epoch 158/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.1037 - accuracy: 0.5970\n",
            "Epoch 158: val_loss improved from 0.98153 to 0.97079, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.1037 - accuracy: 0.5970 - val_loss: 0.9708 - val_accuracy: 0.6670 - lr: 2.5000e-04\n",
            "Epoch 159/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0941 - accuracy: 0.6023\n",
            "Epoch 159: val_loss improved from 0.97079 to 0.96467, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0941 - accuracy: 0.6023 - val_loss: 0.9647 - val_accuracy: 0.6707 - lr: 2.5000e-04\n",
            "Epoch 160/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0938 - accuracy: 0.6023\n",
            "Epoch 160: val_loss did not improve from 0.96467\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0938 - accuracy: 0.6023 - val_loss: 0.9659 - val_accuracy: 0.6659 - lr: 2.5000e-04\n",
            "Epoch 161/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0936 - accuracy: 0.6020\n",
            "Epoch 161: val_loss did not improve from 0.96467\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0936 - accuracy: 0.6020 - val_loss: 0.9986 - val_accuracy: 0.6590 - lr: 2.5000e-04\n",
            "Epoch 162/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0931 - accuracy: 0.6005\n",
            "Epoch 162: val_loss did not improve from 0.96467\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0931 - accuracy: 0.6005 - val_loss: 0.9830 - val_accuracy: 0.6585 - lr: 2.5000e-04\n",
            "Epoch 163/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.6025\n",
            "Epoch 163: val_loss did not improve from 0.96467\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0932 - accuracy: 0.6025 - val_loss: 0.9790 - val_accuracy: 0.6648 - lr: 2.5000e-04\n",
            "Epoch 164/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0955 - accuracy: 0.5986\n",
            "Epoch 164: val_loss improved from 0.96467 to 0.95890, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0955 - accuracy: 0.5986 - val_loss: 0.9589 - val_accuracy: 0.6681 - lr: 2.5000e-04\n",
            "Epoch 165/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0898 - accuracy: 0.6023\n",
            "Epoch 165: val_loss did not improve from 0.95890\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0898 - accuracy: 0.6023 - val_loss: 0.9640 - val_accuracy: 0.6661 - lr: 2.5000e-04\n",
            "Epoch 166/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.6022\n",
            "Epoch 166: val_loss did not improve from 0.95890\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0952 - accuracy: 0.6022 - val_loss: 0.9841 - val_accuracy: 0.6488 - lr: 2.5000e-04\n",
            "Epoch 167/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0865 - accuracy: 0.6022\n",
            "Epoch 167: val_loss did not improve from 0.95890\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0865 - accuracy: 0.6022 - val_loss: 0.9691 - val_accuracy: 0.6657 - lr: 2.5000e-04\n",
            "Epoch 168/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0914 - accuracy: 0.6003\n",
            "Epoch 168: val_loss improved from 0.95890 to 0.95786, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0914 - accuracy: 0.6003 - val_loss: 0.9579 - val_accuracy: 0.6727 - lr: 2.5000e-04\n",
            "Epoch 169/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0899 - accuracy: 0.6000\n",
            "Epoch 169: val_loss did not improve from 0.95786\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0899 - accuracy: 0.6000 - val_loss: 0.9726 - val_accuracy: 0.6529 - lr: 2.5000e-04\n",
            "Epoch 170/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0779 - accuracy: 0.6051\n",
            "Epoch 170: val_loss did not improve from 0.95786\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0779 - accuracy: 0.6051 - val_loss: 0.9671 - val_accuracy: 0.6657 - lr: 2.5000e-04\n",
            "Epoch 171/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0849 - accuracy: 0.6017\n",
            "Epoch 171: val_loss improved from 0.95786 to 0.94969, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0849 - accuracy: 0.6017 - val_loss: 0.9497 - val_accuracy: 0.6776 - lr: 2.5000e-04\n",
            "Epoch 172/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.5992\n",
            "Epoch 172: val_loss did not improve from 0.94969\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0860 - accuracy: 0.5992 - val_loss: 0.9666 - val_accuracy: 0.6629 - lr: 2.5000e-04\n",
            "Epoch 173/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0801 - accuracy: 0.6069\n",
            "Epoch 173: val_loss did not improve from 0.94969\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0801 - accuracy: 0.6069 - val_loss: 0.9549 - val_accuracy: 0.6682 - lr: 2.5000e-04\n",
            "Epoch 174/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0787 - accuracy: 0.6025\n",
            "Epoch 174: val_loss did not improve from 0.94969\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0787 - accuracy: 0.6025 - val_loss: 0.9667 - val_accuracy: 0.6621 - lr: 2.5000e-04\n",
            "Epoch 175/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0795 - accuracy: 0.6040\n",
            "Epoch 175: val_loss improved from 0.94969 to 0.94497, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0795 - accuracy: 0.6040 - val_loss: 0.9450 - val_accuracy: 0.6741 - lr: 2.5000e-04\n",
            "Epoch 176/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0836 - accuracy: 0.5995\n",
            "Epoch 176: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0836 - accuracy: 0.5995 - val_loss: 0.9752 - val_accuracy: 0.6459 - lr: 2.5000e-04\n",
            "Epoch 177/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0843 - accuracy: 0.6027\n",
            "Epoch 177: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0843 - accuracy: 0.6027 - val_loss: 0.9575 - val_accuracy: 0.6666 - lr: 2.5000e-04\n",
            "Epoch 178/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.6065\n",
            "Epoch 178: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0743 - accuracy: 0.6065 - val_loss: 0.9490 - val_accuracy: 0.6697 - lr: 2.5000e-04\n",
            "Epoch 179/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.6034\n",
            "Epoch 179: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0829 - accuracy: 0.6034 - val_loss: 0.9687 - val_accuracy: 0.6476 - lr: 2.5000e-04\n",
            "Epoch 180/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0720 - accuracy: 0.6055\n",
            "Epoch 180: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0720 - accuracy: 0.6055 - val_loss: 0.9551 - val_accuracy: 0.6552 - lr: 2.5000e-04\n",
            "Epoch 181/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0779 - accuracy: 0.6038\n",
            "Epoch 181: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0779 - accuracy: 0.6038 - val_loss: 0.9505 - val_accuracy: 0.6668 - lr: 2.5000e-04\n",
            "Epoch 182/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0758 - accuracy: 0.6060\n",
            "Epoch 182: val_loss did not improve from 0.94497\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0758 - accuracy: 0.6060 - val_loss: 0.9592 - val_accuracy: 0.6671 - lr: 2.5000e-04\n",
            "Epoch 183/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0741 - accuracy: 0.6106\n",
            "Epoch 183: val_loss improved from 0.94497 to 0.94392, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0741 - accuracy: 0.6106 - val_loss: 0.9439 - val_accuracy: 0.6641 - lr: 2.5000e-04\n",
            "Epoch 184/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0756 - accuracy: 0.6057\n",
            "Epoch 184: val_loss did not improve from 0.94392\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0756 - accuracy: 0.6057 - val_loss: 0.9631 - val_accuracy: 0.6566 - lr: 2.5000e-04\n",
            "Epoch 185/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.6085\n",
            "Epoch 185: val_loss did not improve from 0.94392\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.0692 - accuracy: 0.6085 - val_loss: 0.9645 - val_accuracy: 0.6553 - lr: 2.5000e-04\n",
            "Epoch 186/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0715 - accuracy: 0.6072\n",
            "Epoch 186: val_loss did not improve from 0.94392\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0715 - accuracy: 0.6072 - val_loss: 0.9459 - val_accuracy: 0.6683 - lr: 2.5000e-04\n",
            "Epoch 187/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0736 - accuracy: 0.6079\n",
            "Epoch 187: val_loss did not improve from 0.94392\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0736 - accuracy: 0.6079 - val_loss: 0.9494 - val_accuracy: 0.6631 - lr: 2.5000e-04\n",
            "Epoch 188/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0682 - accuracy: 0.6096\n",
            "Epoch 188: val_loss did not improve from 0.94392\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0682 - accuracy: 0.6096 - val_loss: 0.9564 - val_accuracy: 0.6619 - lr: 2.5000e-04\n",
            "Epoch 189/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0616 - accuracy: 0.6123\n",
            "Epoch 189: val_loss did not improve from 0.94392\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0616 - accuracy: 0.6123 - val_loss: 0.9474 - val_accuracy: 0.6682 - lr: 2.5000e-04\n",
            "Epoch 190/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0632 - accuracy: 0.6095\n",
            "Epoch 190: val_loss improved from 0.94392 to 0.93735, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.0632 - accuracy: 0.6095 - val_loss: 0.9373 - val_accuracy: 0.6689 - lr: 2.5000e-04\n",
            "Epoch 191/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0642 - accuracy: 0.6087\n",
            "Epoch 191: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0642 - accuracy: 0.6087 - val_loss: 0.9616 - val_accuracy: 0.6514 - lr: 2.5000e-04\n",
            "Epoch 192/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0656 - accuracy: 0.6071\n",
            "Epoch 192: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0656 - accuracy: 0.6071 - val_loss: 0.9438 - val_accuracy: 0.6711 - lr: 2.5000e-04\n",
            "Epoch 193/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0709 - accuracy: 0.6021\n",
            "Epoch 193: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0709 - accuracy: 0.6021 - val_loss: 0.9513 - val_accuracy: 0.6668 - lr: 2.5000e-04\n",
            "Epoch 194/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0609 - accuracy: 0.6086\n",
            "Epoch 194: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0609 - accuracy: 0.6086 - val_loss: 0.9394 - val_accuracy: 0.6643 - lr: 2.5000e-04\n",
            "Epoch 195/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0612 - accuracy: 0.6091\n",
            "Epoch 195: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0612 - accuracy: 0.6091 - val_loss: 0.9499 - val_accuracy: 0.6743 - lr: 2.5000e-04\n",
            "Epoch 196/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0553 - accuracy: 0.6163\n",
            "Epoch 196: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0553 - accuracy: 0.6163 - val_loss: 0.9599 - val_accuracy: 0.6579 - lr: 2.5000e-04\n",
            "Epoch 197/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0599 - accuracy: 0.6117\n",
            "Epoch 197: val_loss did not improve from 0.93735\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0599 - accuracy: 0.6117 - val_loss: 0.9452 - val_accuracy: 0.6511 - lr: 2.5000e-04\n",
            "Epoch 198/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0597 - accuracy: 0.6093\n",
            "Epoch 198: val_loss did not improve from 0.93735\n",
            "\n",
            "Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0597 - accuracy: 0.6093 - val_loss: 0.9502 - val_accuracy: 0.6661 - lr: 2.5000e-04\n",
            "Epoch 199/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0287 - accuracy: 0.6243\n",
            "Epoch 199: val_loss improved from 0.93735 to 0.91330, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.0287 - accuracy: 0.6243 - val_loss: 0.9133 - val_accuracy: 0.6812 - lr: 1.2500e-04\n",
            "Epoch 200/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0192 - accuracy: 0.6297\n",
            "Epoch 200: val_loss did not improve from 0.91330\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0192 - accuracy: 0.6297 - val_loss: 0.9158 - val_accuracy: 0.6861 - lr: 1.2500e-04\n",
            "Epoch 201/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0187 - accuracy: 0.6278\n",
            "Epoch 201: val_loss improved from 0.91330 to 0.91072, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0187 - accuracy: 0.6278 - val_loss: 0.9107 - val_accuracy: 0.6777 - lr: 1.2500e-04\n",
            "Epoch 202/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.6266\n",
            "Epoch 202: val_loss did not improve from 0.91072\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0197 - accuracy: 0.6266 - val_loss: 0.9184 - val_accuracy: 0.6726 - lr: 1.2500e-04\n",
            "Epoch 203/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0185 - accuracy: 0.6304\n",
            "Epoch 203: val_loss did not improve from 0.91072\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0185 - accuracy: 0.6304 - val_loss: 0.9123 - val_accuracy: 0.6844 - lr: 1.2500e-04\n",
            "Epoch 204/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0166 - accuracy: 0.6277\n",
            "Epoch 204: val_loss improved from 0.91072 to 0.90613, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0166 - accuracy: 0.6277 - val_loss: 0.9061 - val_accuracy: 0.6899 - lr: 1.2500e-04\n",
            "Epoch 205/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0196 - accuracy: 0.6281\n",
            "Epoch 205: val_loss did not improve from 0.90613\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0196 - accuracy: 0.6281 - val_loss: 0.9066 - val_accuracy: 0.6894 - lr: 1.2500e-04\n",
            "Epoch 206/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0195 - accuracy: 0.6279\n",
            "Epoch 206: val_loss did not improve from 0.90613\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0195 - accuracy: 0.6279 - val_loss: 0.9136 - val_accuracy: 0.6861 - lr: 1.2500e-04\n",
            "Epoch 207/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0150 - accuracy: 0.6317\n",
            "Epoch 207: val_loss improved from 0.90613 to 0.90319, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0150 - accuracy: 0.6317 - val_loss: 0.9032 - val_accuracy: 0.6867 - lr: 1.2500e-04\n",
            "Epoch 208/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0165 - accuracy: 0.6274\n",
            "Epoch 208: val_loss did not improve from 0.90319\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0165 - accuracy: 0.6274 - val_loss: 0.9123 - val_accuracy: 0.6879 - lr: 1.2500e-04\n",
            "Epoch 209/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0189 - accuracy: 0.6291\n",
            "Epoch 209: val_loss did not improve from 0.90319\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 1.0189 - accuracy: 0.6291 - val_loss: 0.9055 - val_accuracy: 0.6914 - lr: 1.2500e-04\n",
            "Epoch 210/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0136 - accuracy: 0.6314\n",
            "Epoch 210: val_loss did not improve from 0.90319\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0136 - accuracy: 0.6314 - val_loss: 0.9034 - val_accuracy: 0.6823 - lr: 1.2500e-04\n",
            "Epoch 211/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0112 - accuracy: 0.6331\n",
            "Epoch 211: val_loss did not improve from 0.90319\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0112 - accuracy: 0.6331 - val_loss: 0.9043 - val_accuracy: 0.6783 - lr: 1.2500e-04\n",
            "Epoch 212/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0091 - accuracy: 0.6334\n",
            "Epoch 212: val_loss improved from 0.90319 to 0.90169, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0091 - accuracy: 0.6334 - val_loss: 0.9017 - val_accuracy: 0.6812 - lr: 1.2500e-04\n",
            "Epoch 213/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.6302\n",
            "Epoch 213: val_loss did not improve from 0.90169\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0083 - accuracy: 0.6302 - val_loss: 0.9075 - val_accuracy: 0.6844 - lr: 1.2500e-04\n",
            "Epoch 214/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0133 - accuracy: 0.6283\n",
            "Epoch 214: val_loss did not improve from 0.90169\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0133 - accuracy: 0.6283 - val_loss: 0.9081 - val_accuracy: 0.6861 - lr: 1.2500e-04\n",
            "Epoch 215/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0125 - accuracy: 0.6297\n",
            "Epoch 215: val_loss improved from 0.90169 to 0.89861, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0125 - accuracy: 0.6297 - val_loss: 0.8986 - val_accuracy: 0.6854 - lr: 1.2500e-04\n",
            "Epoch 216/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.6288\n",
            "Epoch 216: val_loss did not improve from 0.89861\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0131 - accuracy: 0.6288 - val_loss: 0.8989 - val_accuracy: 0.6905 - lr: 1.2500e-04\n",
            "Epoch 217/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.6286\n",
            "Epoch 217: val_loss did not improve from 0.89861\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0129 - accuracy: 0.6286 - val_loss: 0.9066 - val_accuracy: 0.6772 - lr: 1.2500e-04\n",
            "Epoch 218/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.6305\n",
            "Epoch 218: val_loss did not improve from 0.89861\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0126 - accuracy: 0.6305 - val_loss: 0.9016 - val_accuracy: 0.6879 - lr: 1.2500e-04\n",
            "Epoch 219/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0127 - accuracy: 0.6286\n",
            "Epoch 219: val_loss did not improve from 0.89861\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0127 - accuracy: 0.6286 - val_loss: 0.8997 - val_accuracy: 0.6843 - lr: 1.2500e-04\n",
            "Epoch 220/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0115 - accuracy: 0.6281\n",
            "Epoch 220: val_loss did not improve from 0.89861\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.0115 - accuracy: 0.6281 - val_loss: 0.8994 - val_accuracy: 0.6877 - lr: 1.2500e-04\n",
            "Epoch 221/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.6298\n",
            "Epoch 221: val_loss improved from 0.89861 to 0.89797, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0083 - accuracy: 0.6298 - val_loss: 0.8980 - val_accuracy: 0.6928 - lr: 1.2500e-04\n",
            "Epoch 222/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.6327\n",
            "Epoch 222: val_loss did not improve from 0.89797\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0056 - accuracy: 0.6327 - val_loss: 0.9006 - val_accuracy: 0.6874 - lr: 1.2500e-04\n",
            "Epoch 223/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0142 - accuracy: 0.6274\n",
            "Epoch 223: val_loss improved from 0.89797 to 0.89214, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 1.0142 - accuracy: 0.6274 - val_loss: 0.8921 - val_accuracy: 0.6957 - lr: 1.2500e-04\n",
            "Epoch 224/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0076 - accuracy: 0.6301\n",
            "Epoch 224: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0076 - accuracy: 0.6301 - val_loss: 0.9033 - val_accuracy: 0.6861 - lr: 1.2500e-04\n",
            "Epoch 225/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.6326\n",
            "Epoch 225: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0110 - accuracy: 0.6326 - val_loss: 0.9064 - val_accuracy: 0.6792 - lr: 1.2500e-04\n",
            "Epoch 226/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.6313\n",
            "Epoch 226: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0070 - accuracy: 0.6313 - val_loss: 0.8952 - val_accuracy: 0.6893 - lr: 1.2500e-04\n",
            "Epoch 227/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0035 - accuracy: 0.6336\n",
            "Epoch 227: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 79ms/step - loss: 1.0035 - accuracy: 0.6336 - val_loss: 0.9007 - val_accuracy: 0.6839 - lr: 1.2500e-04\n",
            "Epoch 228/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0132 - accuracy: 0.6301\n",
            "Epoch 228: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0132 - accuracy: 0.6301 - val_loss: 0.9063 - val_accuracy: 0.6843 - lr: 1.2500e-04\n",
            "Epoch 229/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.6297\n",
            "Epoch 229: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0060 - accuracy: 0.6297 - val_loss: 0.8964 - val_accuracy: 0.6881 - lr: 1.2500e-04\n",
            "Epoch 230/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.6308\n",
            "Epoch 230: val_loss did not improve from 0.89214\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0060 - accuracy: 0.6308 - val_loss: 0.8954 - val_accuracy: 0.6870 - lr: 1.2500e-04\n",
            "Epoch 231/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.0093 - accuracy: 0.6281\n",
            "Epoch 231: val_loss did not improve from 0.89214\n",
            "\n",
            "Epoch 231: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 1.0093 - accuracy: 0.6281 - val_loss: 0.8932 - val_accuracy: 0.6925 - lr: 1.2500e-04\n",
            "Epoch 232/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9873 - accuracy: 0.6423\n",
            "Epoch 232: val_loss improved from 0.89214 to 0.88566, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9873 - accuracy: 0.6423 - val_loss: 0.8857 - val_accuracy: 0.6908 - lr: 6.2500e-05\n",
            "Epoch 233/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9920 - accuracy: 0.6377\n",
            "Epoch 233: val_loss did not improve from 0.88566\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9920 - accuracy: 0.6377 - val_loss: 0.8866 - val_accuracy: 0.6906 - lr: 6.2500e-05\n",
            "Epoch 234/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9866 - accuracy: 0.6424\n",
            "Epoch 234: val_loss did not improve from 0.88566\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9866 - accuracy: 0.6424 - val_loss: 0.8875 - val_accuracy: 0.6914 - lr: 6.2500e-05\n",
            "Epoch 235/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9855 - accuracy: 0.6425\n",
            "Epoch 235: val_loss improved from 0.88566 to 0.88393, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 0.9855 - accuracy: 0.6425 - val_loss: 0.8839 - val_accuracy: 0.6969 - lr: 6.2500e-05\n",
            "Epoch 236/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9858 - accuracy: 0.6428\n",
            "Epoch 236: val_loss improved from 0.88393 to 0.87989, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 78ms/step - loss: 0.9858 - accuracy: 0.6428 - val_loss: 0.8799 - val_accuracy: 0.6938 - lr: 6.2500e-05\n",
            "Epoch 237/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9832 - accuracy: 0.6415\n",
            "Epoch 237: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9832 - accuracy: 0.6415 - val_loss: 0.8808 - val_accuracy: 0.6983 - lr: 6.2500e-05\n",
            "Epoch 238/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.6450\n",
            "Epoch 238: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9802 - accuracy: 0.6450 - val_loss: 0.8816 - val_accuracy: 0.6943 - lr: 6.2500e-05\n",
            "Epoch 239/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9831 - accuracy: 0.6418\n",
            "Epoch 239: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9831 - accuracy: 0.6418 - val_loss: 0.8887 - val_accuracy: 0.6920 - lr: 6.2500e-05\n",
            "Epoch 240/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.6465\n",
            "Epoch 240: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9779 - accuracy: 0.6465 - val_loss: 0.8818 - val_accuracy: 0.6946 - lr: 6.2500e-05\n",
            "Epoch 241/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.6440\n",
            "Epoch 241: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9819 - accuracy: 0.6440 - val_loss: 0.8861 - val_accuracy: 0.6893 - lr: 6.2500e-05\n",
            "Epoch 242/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9790 - accuracy: 0.6447\n",
            "Epoch 242: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9790 - accuracy: 0.6447 - val_loss: 0.8819 - val_accuracy: 0.6932 - lr: 6.2500e-05\n",
            "Epoch 243/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9761 - accuracy: 0.6461\n",
            "Epoch 243: val_loss did not improve from 0.87989\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9761 - accuracy: 0.6461 - val_loss: 0.8900 - val_accuracy: 0.6901 - lr: 6.2500e-05\n",
            "Epoch 244/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9787 - accuracy: 0.6429\n",
            "Epoch 244: val_loss improved from 0.87989 to 0.87953, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9787 - accuracy: 0.6429 - val_loss: 0.8795 - val_accuracy: 0.6914 - lr: 6.2500e-05\n",
            "Epoch 245/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.6436\n",
            "Epoch 245: val_loss improved from 0.87953 to 0.87939, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9819 - accuracy: 0.6436 - val_loss: 0.8794 - val_accuracy: 0.6937 - lr: 6.2500e-05\n",
            "Epoch 246/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.6422\n",
            "Epoch 246: val_loss did not improve from 0.87939\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9810 - accuracy: 0.6422 - val_loss: 0.8802 - val_accuracy: 0.6930 - lr: 6.2500e-05\n",
            "Epoch 247/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9805 - accuracy: 0.6417\n",
            "Epoch 247: val_loss did not improve from 0.87939\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9805 - accuracy: 0.6417 - val_loss: 0.8820 - val_accuracy: 0.6954 - lr: 6.2500e-05\n",
            "Epoch 248/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9796 - accuracy: 0.6432\n",
            "Epoch 248: val_loss improved from 0.87939 to 0.87489, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9796 - accuracy: 0.6432 - val_loss: 0.8749 - val_accuracy: 0.6993 - lr: 6.2500e-05\n",
            "Epoch 249/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9823 - accuracy: 0.6413\n",
            "Epoch 249: val_loss did not improve from 0.87489\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9823 - accuracy: 0.6413 - val_loss: 0.8779 - val_accuracy: 0.6947 - lr: 6.2500e-05\n",
            "Epoch 250/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9767 - accuracy: 0.6451\n",
            "Epoch 250: val_loss did not improve from 0.87489\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9767 - accuracy: 0.6451 - val_loss: 0.8782 - val_accuracy: 0.6957 - lr: 6.2500e-05\n",
            "Epoch 251/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9838 - accuracy: 0.6402\n",
            "Epoch 251: val_loss improved from 0.87489 to 0.87270, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 14s 81ms/step - loss: 0.9838 - accuracy: 0.6402 - val_loss: 0.8727 - val_accuracy: 0.7006 - lr: 6.2500e-05\n",
            "Epoch 252/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9766 - accuracy: 0.6458\n",
            "Epoch 252: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9766 - accuracy: 0.6458 - val_loss: 0.8813 - val_accuracy: 0.6958 - lr: 6.2500e-05\n",
            "Epoch 253/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9719 - accuracy: 0.6486\n",
            "Epoch 253: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9719 - accuracy: 0.6486 - val_loss: 0.8768 - val_accuracy: 0.7002 - lr: 6.2500e-05\n",
            "Epoch 254/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9818 - accuracy: 0.6416\n",
            "Epoch 254: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9818 - accuracy: 0.6416 - val_loss: 0.8830 - val_accuracy: 0.6946 - lr: 6.2500e-05\n",
            "Epoch 255/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9743 - accuracy: 0.6440\n",
            "Epoch 255: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9743 - accuracy: 0.6440 - val_loss: 0.8788 - val_accuracy: 0.6962 - lr: 6.2500e-05\n",
            "Epoch 256/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9740 - accuracy: 0.6455\n",
            "Epoch 256: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9740 - accuracy: 0.6455 - val_loss: 0.8789 - val_accuracy: 0.6964 - lr: 6.2500e-05\n",
            "Epoch 257/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.6427\n",
            "Epoch 257: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9777 - accuracy: 0.6427 - val_loss: 0.8740 - val_accuracy: 0.6932 - lr: 6.2500e-05\n",
            "Epoch 258/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9755 - accuracy: 0.6440\n",
            "Epoch 258: val_loss did not improve from 0.87270\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9755 - accuracy: 0.6440 - val_loss: 0.8778 - val_accuracy: 0.6941 - lr: 6.2500e-05\n",
            "Epoch 259/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9778 - accuracy: 0.6446\n",
            "Epoch 259: val_loss improved from 0.87270 to 0.87138, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9778 - accuracy: 0.6446 - val_loss: 0.8714 - val_accuracy: 0.6964 - lr: 6.2500e-05\n",
            "Epoch 260/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.6451\n",
            "Epoch 260: val_loss did not improve from 0.87138\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9751 - accuracy: 0.6451 - val_loss: 0.8716 - val_accuracy: 0.6981 - lr: 6.2500e-05\n",
            "Epoch 261/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.6464\n",
            "Epoch 261: val_loss did not improve from 0.87138\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9744 - accuracy: 0.6464 - val_loss: 0.8812 - val_accuracy: 0.6934 - lr: 6.2500e-05\n",
            "Epoch 262/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9764 - accuracy: 0.6438\n",
            "Epoch 262: val_loss improved from 0.87138 to 0.87132, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9764 - accuracy: 0.6438 - val_loss: 0.8713 - val_accuracy: 0.6921 - lr: 6.2500e-05\n",
            "Epoch 263/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.6460\n",
            "Epoch 263: val_loss did not improve from 0.87132\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9758 - accuracy: 0.6460 - val_loss: 0.8755 - val_accuracy: 0.6914 - lr: 6.2500e-05\n",
            "Epoch 264/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9745 - accuracy: 0.6438\n",
            "Epoch 264: val_loss did not improve from 0.87132\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9745 - accuracy: 0.6438 - val_loss: 0.8770 - val_accuracy: 0.6925 - lr: 6.2500e-05\n",
            "Epoch 265/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9794 - accuracy: 0.6410\n",
            "Epoch 265: val_loss did not improve from 0.87132\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9794 - accuracy: 0.6410 - val_loss: 0.8730 - val_accuracy: 0.6965 - lr: 6.2500e-05\n",
            "Epoch 266/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.6461\n",
            "Epoch 266: val_loss did not improve from 0.87132\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9732 - accuracy: 0.6461 - val_loss: 0.8740 - val_accuracy: 0.6944 - lr: 6.2500e-05\n",
            "Epoch 267/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9722 - accuracy: 0.6476\n",
            "Epoch 267: val_loss did not improve from 0.87132\n",
            "\n",
            "Epoch 267: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9722 - accuracy: 0.6476 - val_loss: 0.8788 - val_accuracy: 0.6969 - lr: 6.2500e-05\n",
            "Epoch 268/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.6494\n",
            "Epoch 268: val_loss improved from 0.87132 to 0.86685, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9642 - accuracy: 0.6494 - val_loss: 0.8669 - val_accuracy: 0.7024 - lr: 3.1250e-05\n",
            "Epoch 269/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.6528\n",
            "Epoch 269: val_loss did not improve from 0.86685\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9625 - accuracy: 0.6528 - val_loss: 0.8715 - val_accuracy: 0.6995 - lr: 3.1250e-05\n",
            "Epoch 270/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9654 - accuracy: 0.6491\n",
            "Epoch 270: val_loss improved from 0.86685 to 0.86641, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9654 - accuracy: 0.6491 - val_loss: 0.8664 - val_accuracy: 0.7032 - lr: 3.1250e-05\n",
            "Epoch 271/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9616 - accuracy: 0.6530\n",
            "Epoch 271: val_loss did not improve from 0.86641\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9616 - accuracy: 0.6530 - val_loss: 0.8682 - val_accuracy: 0.7014 - lr: 3.1250e-05\n",
            "Epoch 272/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9637 - accuracy: 0.6498\n",
            "Epoch 272: val_loss did not improve from 0.86641\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9637 - accuracy: 0.6498 - val_loss: 0.8683 - val_accuracy: 0.7019 - lr: 3.1250e-05\n",
            "Epoch 273/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9659 - accuracy: 0.6494\n",
            "Epoch 273: val_loss did not improve from 0.86641\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9659 - accuracy: 0.6494 - val_loss: 0.8694 - val_accuracy: 0.7001 - lr: 3.1250e-05\n",
            "Epoch 274/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9586 - accuracy: 0.6528\n",
            "Epoch 274: val_loss did not improve from 0.86641\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9586 - accuracy: 0.6528 - val_loss: 0.8685 - val_accuracy: 0.7032 - lr: 3.1250e-05\n",
            "Epoch 275/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9600 - accuracy: 0.6532\n",
            "Epoch 275: val_loss improved from 0.86641 to 0.86604, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9600 - accuracy: 0.6532 - val_loss: 0.8660 - val_accuracy: 0.7017 - lr: 3.1250e-05\n",
            "Epoch 276/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.6495\n",
            "Epoch 276: val_loss did not improve from 0.86604\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9625 - accuracy: 0.6495 - val_loss: 0.8671 - val_accuracy: 0.7002 - lr: 3.1250e-05\n",
            "Epoch 277/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9614 - accuracy: 0.6509\n",
            "Epoch 277: val_loss did not improve from 0.86604\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9614 - accuracy: 0.6509 - val_loss: 0.8664 - val_accuracy: 0.7027 - lr: 3.1250e-05\n",
            "Epoch 278/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9611 - accuracy: 0.6495\n",
            "Epoch 278: val_loss did not improve from 0.86604\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9611 - accuracy: 0.6495 - val_loss: 0.8689 - val_accuracy: 0.6986 - lr: 3.1250e-05\n",
            "Epoch 279/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.6467\n",
            "Epoch 279: val_loss did not improve from 0.86604\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9679 - accuracy: 0.6467 - val_loss: 0.8673 - val_accuracy: 0.6992 - lr: 3.1250e-05\n",
            "Epoch 280/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9603 - accuracy: 0.6538\n",
            "Epoch 280: val_loss did not improve from 0.86604\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9603 - accuracy: 0.6538 - val_loss: 0.8686 - val_accuracy: 0.7017 - lr: 3.1250e-05\n",
            "Epoch 281/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9610 - accuracy: 0.6510\n",
            "Epoch 281: val_loss did not improve from 0.86604\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9610 - accuracy: 0.6510 - val_loss: 0.8689 - val_accuracy: 0.6990 - lr: 3.1250e-05\n",
            "Epoch 282/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9626 - accuracy: 0.6501\n",
            "Epoch 282: val_loss improved from 0.86604 to 0.86587, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9626 - accuracy: 0.6501 - val_loss: 0.8659 - val_accuracy: 0.7011 - lr: 3.1250e-05\n",
            "Epoch 283/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9662 - accuracy: 0.6477\n",
            "Epoch 283: val_loss did not improve from 0.86587\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9662 - accuracy: 0.6477 - val_loss: 0.8708 - val_accuracy: 0.6962 - lr: 3.1250e-05\n",
            "Epoch 284/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9672 - accuracy: 0.6483\n",
            "Epoch 284: val_loss did not improve from 0.86587\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9672 - accuracy: 0.6483 - val_loss: 0.8665 - val_accuracy: 0.7017 - lr: 3.1250e-05\n",
            "Epoch 285/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9605 - accuracy: 0.6511\n",
            "Epoch 285: val_loss did not improve from 0.86587\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9605 - accuracy: 0.6511 - val_loss: 0.8672 - val_accuracy: 0.7026 - lr: 3.1250e-05\n",
            "Epoch 286/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9594 - accuracy: 0.6551\n",
            "Epoch 286: val_loss improved from 0.86587 to 0.86054, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9594 - accuracy: 0.6551 - val_loss: 0.8605 - val_accuracy: 0.7072 - lr: 3.1250e-05\n",
            "Epoch 287/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.6494\n",
            "Epoch 287: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9604 - accuracy: 0.6494 - val_loss: 0.8637 - val_accuracy: 0.7022 - lr: 3.1250e-05\n",
            "Epoch 288/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.6544\n",
            "Epoch 288: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9568 - accuracy: 0.6544 - val_loss: 0.8654 - val_accuracy: 0.7016 - lr: 3.1250e-05\n",
            "Epoch 289/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9585 - accuracy: 0.6515\n",
            "Epoch 289: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9585 - accuracy: 0.6515 - val_loss: 0.8686 - val_accuracy: 0.7030 - lr: 3.1250e-05\n",
            "Epoch 290/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.6517\n",
            "Epoch 290: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9588 - accuracy: 0.6517 - val_loss: 0.8637 - val_accuracy: 0.6995 - lr: 3.1250e-05\n",
            "Epoch 291/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9590 - accuracy: 0.6526\n",
            "Epoch 291: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9590 - accuracy: 0.6526 - val_loss: 0.8657 - val_accuracy: 0.7002 - lr: 3.1250e-05\n",
            "Epoch 292/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9636 - accuracy: 0.6493\n",
            "Epoch 292: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9636 - accuracy: 0.6493 - val_loss: 0.8656 - val_accuracy: 0.7026 - lr: 3.1250e-05\n",
            "Epoch 293/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9623 - accuracy: 0.6521\n",
            "Epoch 293: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9623 - accuracy: 0.6521 - val_loss: 0.8630 - val_accuracy: 0.7025 - lr: 3.1250e-05\n",
            "Epoch 294/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9576 - accuracy: 0.6537\n",
            "Epoch 294: val_loss did not improve from 0.86054\n",
            "\n",
            "Epoch 294: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9576 - accuracy: 0.6537 - val_loss: 0.8616 - val_accuracy: 0.7047 - lr: 3.1250e-05\n",
            "Epoch 295/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9548 - accuracy: 0.6559\n",
            "Epoch 295: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9548 - accuracy: 0.6559 - val_loss: 0.8609 - val_accuracy: 0.7032 - lr: 1.5625e-05\n",
            "Epoch 296/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9531 - accuracy: 0.6558\n",
            "Epoch 296: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9531 - accuracy: 0.6558 - val_loss: 0.8611 - val_accuracy: 0.7049 - lr: 1.5625e-05\n",
            "Epoch 297/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9559 - accuracy: 0.6535\n",
            "Epoch 297: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9559 - accuracy: 0.6535 - val_loss: 0.8619 - val_accuracy: 0.7034 - lr: 1.5625e-05\n",
            "Epoch 298/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9547 - accuracy: 0.6533\n",
            "Epoch 298: val_loss did not improve from 0.86054\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9547 - accuracy: 0.6533 - val_loss: 0.8622 - val_accuracy: 0.7018 - lr: 1.5625e-05\n",
            "Epoch 299/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9532 - accuracy: 0.6511\n",
            "Epoch 299: val_loss improved from 0.86054 to 0.86025, saving model to logs/EEGNet_out_weights.h5\n",
            "170/170 [==============================] - 13s 77ms/step - loss: 0.9532 - accuracy: 0.6511 - val_loss: 0.8602 - val_accuracy: 0.7050 - lr: 1.5625e-05\n",
            "Epoch 300/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.6518\n",
            "Epoch 300: val_loss did not improve from 0.86025\n",
            "170/170 [==============================] - 13s 76ms/step - loss: 0.9555 - accuracy: 0.6518 - val_loss: 0.8624 - val_accuracy: 0.7029 - lr: 1.5625e-05\n"
          ]
        }
      ],
      "source": [
        "model = DeepConvNet(input_shape=(1,3,2000),\n",
        "                    num_class=29,\n",
        "                    dropout_rate=0.2,\n",
        "                    patience = 8,\n",
        "                    epochs = 300,\n",
        "                    factor = 0.5,\n",
        "                    lr = 1e-3,\n",
        "                    min_lr = 1e-6,\n",
        "                    es_patience = 30,\n",
        "                    batch_size = 256,\n",
        "                    shuffle=True\n",
        "                    )\n",
        "model.fit(x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fh_1CW851KL",
        "outputId": "64ae1235-0061-4b99-a58a-e673a4534542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1, 3, 2000)]      0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 25, 3, 1996)       150       \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 25, 1, 1996)       1900      \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 25, 1, 1996)      100       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 25, 1, 1996)       0         \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 25, 1, 998)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 25, 1, 998)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 50, 1, 994)        6300      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 50, 1, 994)       200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 50, 1, 994)        0         \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 50, 1, 497)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 50, 1, 497)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 100, 1, 493)       25100     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 100, 1, 493)      400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 100, 1, 493)       0         \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 100, 1, 246)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 100, 1, 246)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 200, 1, 242)       100200    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 200, 1, 242)      800       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 200, 1, 242)       0         \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 200, 1, 121)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 200, 1, 121)       0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 24200)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 96804     \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231,954\n",
            "Trainable params: 231,204\n",
            "Non-trainable params: 750\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "  5/170 [..............................] - ETA: 6s - loss: 11.1001 - accuracy: 0.2672WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0161s vs `on_train_batch_end` time: 0.0206s). Check your callbacks.\n",
            "169/170 [============================>.] - ETA: 0s - loss: 4.5845 - accuracy: 0.2574\n",
            "Epoch 1: val_loss improved from inf to 1.71076, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 9s 46ms/step - loss: 4.5678 - accuracy: 0.2574 - val_loss: 1.7108 - val_accuracy: 0.2643 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.6081 - accuracy: 0.2721\n",
            "Epoch 2: val_loss improved from 1.71076 to 1.62306, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.6081 - accuracy: 0.2722 - val_loss: 1.6231 - val_accuracy: 0.2761 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.5057 - accuracy: 0.2875\n",
            "Epoch 3: val_loss improved from 1.62306 to 1.51404, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.5054 - accuracy: 0.2875 - val_loss: 1.5140 - val_accuracy: 0.2652 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.4717 - accuracy: 0.2923\n",
            "Epoch 4: val_loss did not improve from 1.51404\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 1.4719 - accuracy: 0.2929 - val_loss: 1.5413 - val_accuracy: 0.3012 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.4530 - accuracy: 0.2963\n",
            "Epoch 5: val_loss improved from 1.51404 to 1.45996, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.4536 - accuracy: 0.2963 - val_loss: 1.4600 - val_accuracy: 0.3090 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.4348 - accuracy: 0.3039\n",
            "Epoch 6: val_loss improved from 1.45996 to 1.40869, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.4348 - accuracy: 0.3037 - val_loss: 1.4087 - val_accuracy: 0.3149 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.4056 - accuracy: 0.3196\n",
            "Epoch 7: val_loss did not improve from 1.40869\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 1.4052 - accuracy: 0.3197 - val_loss: 1.4826 - val_accuracy: 0.3260 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.4197 - accuracy: 0.3251\n",
            "Epoch 8: val_loss improved from 1.40869 to 1.38118, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.4196 - accuracy: 0.3251 - val_loss: 1.3812 - val_accuracy: 0.3844 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.4030 - accuracy: 0.3367\n",
            "Epoch 9: val_loss did not improve from 1.38118\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.4030 - accuracy: 0.3367 - val_loss: 1.4094 - val_accuracy: 0.3501 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.3918 - accuracy: 0.3514\n",
            "Epoch 10: val_loss did not improve from 1.38118\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 1.3918 - accuracy: 0.3513 - val_loss: 1.4282 - val_accuracy: 0.3408 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3907 - accuracy: 0.3517\n",
            "Epoch 11: val_loss did not improve from 1.38118\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 1.3907 - accuracy: 0.3517 - val_loss: 1.3832 - val_accuracy: 0.3171 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.3627 - accuracy: 0.3697\n",
            "Epoch 12: val_loss did not improve from 1.38118\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 1.3631 - accuracy: 0.3693 - val_loss: 1.4289 - val_accuracy: 0.3154 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.3661 - accuracy: 0.3758\n",
            "Epoch 13: val_loss improved from 1.38118 to 1.34187, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.3660 - accuracy: 0.3757 - val_loss: 1.3419 - val_accuracy: 0.3881 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.3445 - accuracy: 0.3924\n",
            "Epoch 14: val_loss did not improve from 1.34187\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 1.3455 - accuracy: 0.3921 - val_loss: 1.4287 - val_accuracy: 0.3772 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 1.3046 - accuracy: 0.4138\n",
            "Epoch 15: val_loss improved from 1.34187 to 1.30576, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.3046 - accuracy: 0.4138 - val_loss: 1.3058 - val_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.2559 - accuracy: 0.4374\n",
            "Epoch 16: val_loss improved from 1.30576 to 1.23079, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.2563 - accuracy: 0.4369 - val_loss: 1.2308 - val_accuracy: 0.4139 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.1926 - accuracy: 0.4667\n",
            "Epoch 17: val_loss did not improve from 1.23079\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.1929 - accuracy: 0.4667 - val_loss: 1.3232 - val_accuracy: 0.3888 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.1558 - accuracy: 0.4912\n",
            "Epoch 18: val_loss improved from 1.23079 to 1.13332, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.1554 - accuracy: 0.4912 - val_loss: 1.1333 - val_accuracy: 0.4748 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.1169 - accuracy: 0.5141\n",
            "Epoch 19: val_loss did not improve from 1.13332\n",
            "170/170 [==============================] - 8s 45ms/step - loss: 1.1165 - accuracy: 0.5141 - val_loss: 1.1407 - val_accuracy: 0.4798 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.0688 - accuracy: 0.5345\n",
            "Epoch 20: val_loss improved from 1.13332 to 1.09146, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.0683 - accuracy: 0.5348 - val_loss: 1.0915 - val_accuracy: 0.5603 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.0172 - accuracy: 0.5533\n",
            "Epoch 21: val_loss improved from 1.09146 to 1.02339, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.0175 - accuracy: 0.5534 - val_loss: 1.0234 - val_accuracy: 0.5456 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9912 - accuracy: 0.5663\n",
            "Epoch 22: val_loss improved from 1.02339 to 1.01073, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.9916 - accuracy: 0.5660 - val_loss: 1.0107 - val_accuracy: 0.5588 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9664 - accuracy: 0.5786\n",
            "Epoch 23: val_loss improved from 1.01073 to 0.97615, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.9662 - accuracy: 0.5788 - val_loss: 0.9762 - val_accuracy: 0.5887 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9319 - accuracy: 0.5947\n",
            "Epoch 24: val_loss improved from 0.97615 to 0.96408, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.9312 - accuracy: 0.5949 - val_loss: 0.9641 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9039 - accuracy: 0.6072\n",
            "Epoch 25: val_loss improved from 0.96408 to 0.96275, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.9041 - accuracy: 0.6072 - val_loss: 0.9627 - val_accuracy: 0.5761 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8828 - accuracy: 0.6155\n",
            "Epoch 26: val_loss improved from 0.96275 to 0.92573, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.8825 - accuracy: 0.6158 - val_loss: 0.9257 - val_accuracy: 0.6041 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8656 - accuracy: 0.6293\n",
            "Epoch 27: val_loss improved from 0.92573 to 0.91067, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.8668 - accuracy: 0.6287 - val_loss: 0.9107 - val_accuracy: 0.5973 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8407 - accuracy: 0.6342\n",
            "Epoch 28: val_loss did not improve from 0.91067\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.8403 - accuracy: 0.6345 - val_loss: 0.9469 - val_accuracy: 0.5846 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8263 - accuracy: 0.6428\n",
            "Epoch 29: val_loss improved from 0.91067 to 0.86686, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.8265 - accuracy: 0.6428 - val_loss: 0.8669 - val_accuracy: 0.6201 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8073 - accuracy: 0.6545\n",
            "Epoch 30: val_loss did not improve from 0.86686\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.8077 - accuracy: 0.6544 - val_loss: 0.8987 - val_accuracy: 0.6059 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7904 - accuracy: 0.6583\n",
            "Epoch 31: val_loss improved from 0.86686 to 0.85890, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.7900 - accuracy: 0.6584 - val_loss: 0.8589 - val_accuracy: 0.6238 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.6706\n",
            "Epoch 32: val_loss did not improve from 0.85890\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.7690 - accuracy: 0.6706 - val_loss: 0.8611 - val_accuracy: 0.6205 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7670 - accuracy: 0.6693\n",
            "Epoch 33: val_loss improved from 0.85890 to 0.85888, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.7675 - accuracy: 0.6689 - val_loss: 0.8589 - val_accuracy: 0.6320 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7585 - accuracy: 0.6723\n",
            "Epoch 34: val_loss improved from 0.85888 to 0.82705, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.7584 - accuracy: 0.6723 - val_loss: 0.8270 - val_accuracy: 0.6382 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.6833\n",
            "Epoch 35: val_loss did not improve from 0.82705\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.7400 - accuracy: 0.6834 - val_loss: 0.8512 - val_accuracy: 0.6209 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7344 - accuracy: 0.6860\n",
            "Epoch 36: val_loss improved from 0.82705 to 0.81421, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.7345 - accuracy: 0.6861 - val_loss: 0.8142 - val_accuracy: 0.6474 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7315 - accuracy: 0.6853\n",
            "Epoch 37: val_loss did not improve from 0.81421\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.7314 - accuracy: 0.6853 - val_loss: 0.8905 - val_accuracy: 0.6024 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7042 - accuracy: 0.7005\n",
            "Epoch 38: val_loss did not improve from 0.81421\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.7045 - accuracy: 0.7003 - val_loss: 0.8170 - val_accuracy: 0.6471 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7074 - accuracy: 0.7000\n",
            "Epoch 39: val_loss did not improve from 0.81421\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.7077 - accuracy: 0.6997 - val_loss: 0.8585 - val_accuracy: 0.6152 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6836 - accuracy: 0.7091\n",
            "Epoch 40: val_loss improved from 0.81421 to 0.79907, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.6843 - accuracy: 0.7088 - val_loss: 0.7991 - val_accuracy: 0.6521 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6683 - accuracy: 0.7166\n",
            "Epoch 41: val_loss did not improve from 0.79907\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.6687 - accuracy: 0.7164 - val_loss: 0.8260 - val_accuracy: 0.6572 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.7120\n",
            "Epoch 42: val_loss improved from 0.79907 to 0.79216, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.6781 - accuracy: 0.7120 - val_loss: 0.7922 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.7215\n",
            "Epoch 43: val_loss did not improve from 0.79216\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.6589 - accuracy: 0.7214 - val_loss: 0.8029 - val_accuracy: 0.6459 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6499 - accuracy: 0.7270\n",
            "Epoch 44: val_loss improved from 0.79216 to 0.78794, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.6497 - accuracy: 0.7271 - val_loss: 0.7879 - val_accuracy: 0.6620 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6416 - accuracy: 0.7316\n",
            "Epoch 45: val_loss improved from 0.78794 to 0.78357, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.6416 - accuracy: 0.7317 - val_loss: 0.7836 - val_accuracy: 0.6594 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.7358\n",
            "Epoch 46: val_loss did not improve from 0.78357\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.6328 - accuracy: 0.7360 - val_loss: 0.7876 - val_accuracy: 0.6634 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6270 - accuracy: 0.7392\n",
            "Epoch 47: val_loss did not improve from 0.78357\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.6272 - accuracy: 0.7390 - val_loss: 0.8008 - val_accuracy: 0.6590 - lr: 0.0010\n",
            "Epoch 48/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.7450\n",
            "Epoch 48: val_loss did not improve from 0.78357\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.6125 - accuracy: 0.7450 - val_loss: 0.8135 - val_accuracy: 0.6513 - lr: 0.0010\n",
            "Epoch 49/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.7514\n",
            "Epoch 49: val_loss improved from 0.78357 to 0.77083, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.6017 - accuracy: 0.7516 - val_loss: 0.7708 - val_accuracy: 0.6670 - lr: 0.0010\n",
            "Epoch 50/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5913 - accuracy: 0.7588\n",
            "Epoch 50: val_loss did not improve from 0.77083\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5916 - accuracy: 0.7586 - val_loss: 0.7742 - val_accuracy: 0.6669 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.7585\n",
            "Epoch 51: val_loss did not improve from 0.77083\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5896 - accuracy: 0.7583 - val_loss: 0.7923 - val_accuracy: 0.6606 - lr: 0.0010\n",
            "Epoch 52/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.7597\n",
            "Epoch 52: val_loss did not improve from 0.77083\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5836 - accuracy: 0.7599 - val_loss: 0.7882 - val_accuracy: 0.6719 - lr: 0.0010\n",
            "Epoch 53/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5660 - accuracy: 0.7692\n",
            "Epoch 53: val_loss improved from 0.77083 to 0.76504, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5664 - accuracy: 0.7691 - val_loss: 0.7650 - val_accuracy: 0.6717 - lr: 0.0010\n",
            "Epoch 54/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5560 - accuracy: 0.7742\n",
            "Epoch 54: val_loss did not improve from 0.76504\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5564 - accuracy: 0.7741 - val_loss: 0.7839 - val_accuracy: 0.6683 - lr: 0.0010\n",
            "Epoch 55/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5609 - accuracy: 0.7724\n",
            "Epoch 55: val_loss did not improve from 0.76504\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5609 - accuracy: 0.7725 - val_loss: 0.8137 - val_accuracy: 0.6504 - lr: 0.0010\n",
            "Epoch 56/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5458 - accuracy: 0.7800\n",
            "Epoch 56: val_loss did not improve from 0.76504\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5458 - accuracy: 0.7801 - val_loss: 0.8079 - val_accuracy: 0.6677 - lr: 0.0010\n",
            "Epoch 57/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.7863\n",
            "Epoch 57: val_loss improved from 0.76504 to 0.76292, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5350 - accuracy: 0.7863 - val_loss: 0.7629 - val_accuracy: 0.6783 - lr: 0.0010\n",
            "Epoch 58/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.7859\n",
            "Epoch 58: val_loss did not improve from 0.76292\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5337 - accuracy: 0.7858 - val_loss: 0.7872 - val_accuracy: 0.6663 - lr: 0.0010\n",
            "Epoch 59/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5155 - accuracy: 0.7939\n",
            "Epoch 59: val_loss did not improve from 0.76292\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5161 - accuracy: 0.7935 - val_loss: 0.7819 - val_accuracy: 0.6805 - lr: 0.0010\n",
            "Epoch 60/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.7886\n",
            "Epoch 60: val_loss improved from 0.76292 to 0.76120, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.5278 - accuracy: 0.7882 - val_loss: 0.7612 - val_accuracy: 0.6851 - lr: 0.0010\n",
            "Epoch 61/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.7950\n",
            "Epoch 61: val_loss did not improve from 0.76120\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5149 - accuracy: 0.7950 - val_loss: 0.7727 - val_accuracy: 0.6719 - lr: 0.0010\n",
            "Epoch 62/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5013 - accuracy: 0.8033\n",
            "Epoch 62: val_loss did not improve from 0.76120\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5016 - accuracy: 0.8032 - val_loss: 0.8360 - val_accuracy: 0.6646 - lr: 0.0010\n",
            "Epoch 63/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5045 - accuracy: 0.7982\n",
            "Epoch 63: val_loss improved from 0.76120 to 0.75173, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.5044 - accuracy: 0.7984 - val_loss: 0.7517 - val_accuracy: 0.6844 - lr: 0.0010\n",
            "Epoch 64/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.8147\n",
            "Epoch 64: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.4761 - accuracy: 0.8146 - val_loss: 0.8172 - val_accuracy: 0.6768 - lr: 0.0010\n",
            "Epoch 65/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.8161\n",
            "Epoch 65: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.4715 - accuracy: 0.8160 - val_loss: 0.7577 - val_accuracy: 0.6874 - lr: 0.0010\n",
            "Epoch 66/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.8196\n",
            "Epoch 66: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.4690 - accuracy: 0.8196 - val_loss: 0.7715 - val_accuracy: 0.6901 - lr: 0.0010\n",
            "Epoch 67/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.8239\n",
            "Epoch 67: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.4574 - accuracy: 0.8238 - val_loss: 0.8034 - val_accuracy: 0.6772 - lr: 0.0010\n",
            "Epoch 68/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.8233\n",
            "Epoch 68: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.4569 - accuracy: 0.8233 - val_loss: 0.8238 - val_accuracy: 0.6778 - lr: 0.0010\n",
            "Epoch 69/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4551 - accuracy: 0.8229\n",
            "Epoch 69: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.4554 - accuracy: 0.8229 - val_loss: 0.8178 - val_accuracy: 0.6729 - lr: 0.0010\n",
            "Epoch 70/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5077 - accuracy: 0.8053\n",
            "Epoch 70: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5076 - accuracy: 0.8054 - val_loss: 0.7818 - val_accuracy: 0.6904 - lr: 0.0010\n",
            "Epoch 71/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8330\n",
            "Epoch 71: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.4368 - accuracy: 0.8329 - val_loss: 0.7629 - val_accuracy: 0.6870 - lr: 0.0010\n",
            "Epoch 72/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4236 - accuracy: 0.8407\n",
            "Epoch 72: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.4238 - accuracy: 0.8407 - val_loss: 0.7666 - val_accuracy: 0.6892 - lr: 0.0010\n",
            "Epoch 73/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8407\n",
            "Epoch 73: val_loss did not improve from 0.75173\n",
            "\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.4229 - accuracy: 0.8406 - val_loss: 0.7565 - val_accuracy: 0.6921 - lr: 0.0010\n",
            "Epoch 74/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.8883\n",
            "Epoch 74: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.3263 - accuracy: 0.8884 - val_loss: 0.7731 - val_accuracy: 0.7034 - lr: 5.0000e-04\n",
            "Epoch 75/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2885 - accuracy: 0.9059\n",
            "Epoch 75: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2886 - accuracy: 0.9059 - val_loss: 0.7836 - val_accuracy: 0.7015 - lr: 5.0000e-04\n",
            "Epoch 76/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.9056\n",
            "Epoch 76: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2943 - accuracy: 0.9055 - val_loss: 0.7876 - val_accuracy: 0.6982 - lr: 5.0000e-04\n",
            "Epoch 77/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.9056\n",
            "Epoch 77: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2922 - accuracy: 0.9058 - val_loss: 0.7989 - val_accuracy: 0.6984 - lr: 5.0000e-04\n",
            "Epoch 78/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.9066\n",
            "Epoch 78: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2844 - accuracy: 0.9066 - val_loss: 0.7618 - val_accuracy: 0.6986 - lr: 5.0000e-04\n",
            "Epoch 79/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.9102\n",
            "Epoch 79: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2813 - accuracy: 0.9102 - val_loss: 0.7754 - val_accuracy: 0.6990 - lr: 5.0000e-04\n",
            "Epoch 80/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9100\n",
            "Epoch 80: val_loss did not improve from 0.75173\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2764 - accuracy: 0.9099 - val_loss: 0.7879 - val_accuracy: 0.7019 - lr: 5.0000e-04\n",
            "Epoch 81/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9125\n",
            "Epoch 81: val_loss improved from 0.75173 to 0.74139, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2730 - accuracy: 0.9126 - val_loss: 0.7414 - val_accuracy: 0.7068 - lr: 5.0000e-04\n",
            "Epoch 82/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.9113\n",
            "Epoch 82: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2766 - accuracy: 0.9112 - val_loss: 0.7798 - val_accuracy: 0.6990 - lr: 5.0000e-04\n",
            "Epoch 83/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9135\n",
            "Epoch 83: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2676 - accuracy: 0.9133 - val_loss: 0.7882 - val_accuracy: 0.7018 - lr: 5.0000e-04\n",
            "Epoch 84/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9167\n",
            "Epoch 84: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2605 - accuracy: 0.9169 - val_loss: 0.7842 - val_accuracy: 0.7018 - lr: 5.0000e-04\n",
            "Epoch 85/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9191\n",
            "Epoch 85: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2577 - accuracy: 0.9190 - val_loss: 0.8087 - val_accuracy: 0.7079 - lr: 5.0000e-04\n",
            "Epoch 86/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.9226\n",
            "Epoch 86: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2503 - accuracy: 0.9224 - val_loss: 0.9580 - val_accuracy: 0.6764 - lr: 5.0000e-04\n",
            "Epoch 87/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9254\n",
            "Epoch 87: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2435 - accuracy: 0.9255 - val_loss: 0.8757 - val_accuracy: 0.6992 - lr: 5.0000e-04\n",
            "Epoch 88/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.9240\n",
            "Epoch 88: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2459 - accuracy: 0.9239 - val_loss: 0.8176 - val_accuracy: 0.7030 - lr: 5.0000e-04\n",
            "Epoch 89/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2384 - accuracy: 0.9255\n",
            "Epoch 89: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2387 - accuracy: 0.9254 - val_loss: 0.7880 - val_accuracy: 0.7109 - lr: 5.0000e-04\n",
            "Epoch 90/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2235 - accuracy: 0.9341\n",
            "Epoch 90: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2236 - accuracy: 0.9340 - val_loss: 0.8198 - val_accuracy: 0.7052 - lr: 5.0000e-04\n",
            "Epoch 91/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9293\n",
            "Epoch 91: val_loss did not improve from 0.74139\n",
            "\n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2321 - accuracy: 0.9294 - val_loss: 0.7949 - val_accuracy: 0.7070 - lr: 5.0000e-04\n",
            "Epoch 92/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9608\n",
            "Epoch 92: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1593 - accuracy: 0.9608 - val_loss: 0.8287 - val_accuracy: 0.7137 - lr: 2.5000e-04\n",
            "Epoch 93/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9679\n",
            "Epoch 93: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1353 - accuracy: 0.9680 - val_loss: 0.8605 - val_accuracy: 0.7074 - lr: 2.5000e-04\n",
            "Epoch 94/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9723\n",
            "Epoch 94: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1299 - accuracy: 0.9723 - val_loss: 0.8641 - val_accuracy: 0.7116 - lr: 2.5000e-04\n",
            "Epoch 95/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9735\n",
            "Epoch 95: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1264 - accuracy: 0.9735 - val_loss: 0.8688 - val_accuracy: 0.7094 - lr: 2.5000e-04\n",
            "Epoch 96/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9735\n",
            "Epoch 96: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1257 - accuracy: 0.9735 - val_loss: 0.8442 - val_accuracy: 0.7106 - lr: 2.5000e-04\n",
            "Epoch 97/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9745\n",
            "Epoch 97: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1238 - accuracy: 0.9745 - val_loss: 0.8750 - val_accuracy: 0.7126 - lr: 2.5000e-04\n",
            "Epoch 98/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9728\n",
            "Epoch 98: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1299 - accuracy: 0.9728 - val_loss: 0.8624 - val_accuracy: 0.7118 - lr: 2.5000e-04\n",
            "Epoch 99/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9737\n",
            "Epoch 99: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1242 - accuracy: 0.9737 - val_loss: 0.8657 - val_accuracy: 0.7109 - lr: 2.5000e-04\n",
            "Epoch 100/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9720\n",
            "Epoch 100: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1288 - accuracy: 0.9719 - val_loss: 0.8985 - val_accuracy: 0.7097 - lr: 2.5000e-04\n",
            "Epoch 101/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9764\n",
            "Epoch 101: val_loss did not improve from 0.74139\n",
            "\n",
            "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1167 - accuracy: 0.9764 - val_loss: 0.8760 - val_accuracy: 0.7069 - lr: 2.5000e-04\n",
            "Epoch 102/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9834\n",
            "Epoch 102: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0957 - accuracy: 0.9834 - val_loss: 0.8841 - val_accuracy: 0.7123 - lr: 1.2500e-04\n",
            "Epoch 103/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9858\n",
            "Epoch 103: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0861 - accuracy: 0.9858 - val_loss: 0.8769 - val_accuracy: 0.7129 - lr: 1.2500e-04\n",
            "Epoch 104/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0821 - accuracy: 0.9875\n",
            "Epoch 104: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0823 - accuracy: 0.9874 - val_loss: 0.8752 - val_accuracy: 0.7119 - lr: 1.2500e-04\n",
            "Epoch 105/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9887\n",
            "Epoch 105: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0802 - accuracy: 0.9887 - val_loss: 0.8714 - val_accuracy: 0.7110 - lr: 1.2500e-04\n",
            "Epoch 106/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9883\n",
            "Epoch 106: val_loss did not improve from 0.74139\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0821 - accuracy: 0.9883 - val_loss: 0.8806 - val_accuracy: 0.7128 - lr: 1.2500e-04\n",
            "Epoch 106: early stopping\n"
          ]
        }
      ],
      "source": [
        "#if doing 3 label categories\n",
        "model_ub = DeepConvNet(input_shape=(1,3,2000),\n",
        "                    num_class=4,\n",
        "                    dropout_rate=0,\n",
        "                    patience = 10,\n",
        "                    epochs = 300,\n",
        "                    factor = 0.5,\n",
        "                    lr = 1e-3,\n",
        "                    min_lr = 1e-6,\n",
        "                    es_patience = 25,\n",
        "                    batch_size = 256,\n",
        "                    shuffle=True\n",
        "                    )\n",
        "model_ub.fit(x_train, y_train_ub, x_test, y_test_ub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62bOZtp9xgXD",
        "outputId": "827c1011-9d4e-4143-d04e-69ef1b9fccf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1, 3, 2000)]      0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 25, 3, 1996)       150       \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 25, 1, 1996)       1900      \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 25, 1, 1996)      100       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 25, 1, 1996)       0         \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 25, 1, 998)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 25, 1, 998)        0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 50, 1, 994)        6300      \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 50, 1, 994)       200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 50, 1, 994)        0         \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 50, 1, 497)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 50, 1, 497)        0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 100, 1, 493)       25100     \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 100, 1, 493)      400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 100, 1, 493)       0         \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 100, 1, 246)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 100, 1, 246)       0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 200, 1, 242)       100200    \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 200, 1, 242)      800       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 200, 1, 242)       0         \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 200, 1, 121)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 200, 1, 121)       0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 24200)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 96804     \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231,954\n",
            "Trainable params: 231,204\n",
            "Non-trainable params: 750\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "  5/170 [..............................] - ETA: 6s - loss: 10.2864 - accuracy: 0.3398WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0204s). Check your callbacks.\n",
            "169/170 [============================>.] - ETA: 0s - loss: 2.5507 - accuracy: 0.5614\n",
            "Epoch 1: val_loss improved from inf to 0.96839, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 9s 46ms/step - loss: 2.5421 - accuracy: 0.5621 - val_loss: 0.9684 - val_accuracy: 0.6521 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9595 - accuracy: 0.6524\n",
            "Epoch 2: val_loss improved from 0.96839 to 0.91145, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.9596 - accuracy: 0.6524 - val_loss: 0.9115 - val_accuracy: 0.6803 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9206 - accuracy: 0.6633\n",
            "Epoch 3: val_loss did not improve from 0.91145\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.9196 - accuracy: 0.6638 - val_loss: 0.9199 - val_accuracy: 0.6719 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8838 - accuracy: 0.6722\n",
            "Epoch 4: val_loss did not improve from 0.91145\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.8844 - accuracy: 0.6721 - val_loss: 0.9130 - val_accuracy: 0.6648 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8475 - accuracy: 0.6796\n",
            "Epoch 5: val_loss improved from 0.91145 to 0.82341, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.8475 - accuracy: 0.6796 - val_loss: 0.8234 - val_accuracy: 0.6874 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8177 - accuracy: 0.6920\n",
            "Epoch 6: val_loss improved from 0.82341 to 0.76792, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.8172 - accuracy: 0.6921 - val_loss: 0.7679 - val_accuracy: 0.6972 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7825 - accuracy: 0.6991\n",
            "Epoch 7: val_loss did not improve from 0.76792\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.7824 - accuracy: 0.6992 - val_loss: 0.8624 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7548 - accuracy: 0.7062\n",
            "Epoch 8: val_loss improved from 0.76792 to 0.69513, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.7545 - accuracy: 0.7062 - val_loss: 0.6951 - val_accuracy: 0.6983 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.6622 - accuracy: 0.7463\n",
            "Epoch 9: val_loss improved from 0.69513 to 0.61931, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.6616 - accuracy: 0.7466 - val_loss: 0.6193 - val_accuracy: 0.7718 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.8000\n",
            "Epoch 10: val_loss improved from 0.61931 to 0.46736, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.5202 - accuracy: 0.7998 - val_loss: 0.4674 - val_accuracy: 0.7780 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.8194\n",
            "Epoch 11: val_loss improved from 0.46736 to 0.40034, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.4610 - accuracy: 0.8193 - val_loss: 0.4003 - val_accuracy: 0.8517 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.8477\n",
            "Epoch 12: val_loss improved from 0.40034 to 0.37018, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.4048 - accuracy: 0.8479 - val_loss: 0.3702 - val_accuracy: 0.8608 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.3633 - accuracy: 0.8633\n",
            "Epoch 13: val_loss improved from 0.37018 to 0.35476, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.3638 - accuracy: 0.8633 - val_loss: 0.3548 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.8747\n",
            "Epoch 14: val_loss improved from 0.35476 to 0.32611, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.3327 - accuracy: 0.8743 - val_loss: 0.3261 - val_accuracy: 0.8859 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.8882\n",
            "Epoch 15: val_loss improved from 0.32611 to 0.31909, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.3112 - accuracy: 0.8880 - val_loss: 0.3191 - val_accuracy: 0.8916 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2876 - accuracy: 0.8958\n",
            "Epoch 16: val_loss improved from 0.31909 to 0.30811, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2878 - accuracy: 0.8956 - val_loss: 0.3081 - val_accuracy: 0.8907 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.8994\n",
            "Epoch 17: val_loss did not improve from 0.30811\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2830 - accuracy: 0.8990 - val_loss: 0.3162 - val_accuracy: 0.8874 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.9117\n",
            "Epoch 18: val_loss improved from 0.30811 to 0.23612, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2468 - accuracy: 0.9118 - val_loss: 0.2361 - val_accuracy: 0.9143 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9172\n",
            "Epoch 19: val_loss did not improve from 0.23612\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2337 - accuracy: 0.9173 - val_loss: 0.2619 - val_accuracy: 0.9150 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9230\n",
            "Epoch 20: val_loss did not improve from 0.23612\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2200 - accuracy: 0.9230 - val_loss: 0.2444 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9225\n",
            "Epoch 21: val_loss did not improve from 0.23612\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2205 - accuracy: 0.9225 - val_loss: 0.2578 - val_accuracy: 0.9037 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9173\n",
            "Epoch 22: val_loss did not improve from 0.23612\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2351 - accuracy: 0.9176 - val_loss: 0.4826 - val_accuracy: 0.8032 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9189\n",
            "Epoch 23: val_loss improved from 0.23612 to 0.20253, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2195 - accuracy: 0.9189 - val_loss: 0.2025 - val_accuracy: 0.9308 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.9270\n",
            "Epoch 24: val_loss did not improve from 0.20253\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2023 - accuracy: 0.9271 - val_loss: 0.2148 - val_accuracy: 0.9235 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1965 - accuracy: 0.9309\n",
            "Epoch 25: val_loss did not improve from 0.20253\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1967 - accuracy: 0.9309 - val_loss: 0.2084 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1939 - accuracy: 0.9308\n",
            "Epoch 26: val_loss did not improve from 0.20253\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1944 - accuracy: 0.9305 - val_loss: 0.2816 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9307\n",
            "Epoch 27: val_loss did not improve from 0.20253\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1922 - accuracy: 0.9307 - val_loss: 0.2416 - val_accuracy: 0.9073 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.9331\n",
            "Epoch 28: val_loss improved from 0.20253 to 0.19591, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1901 - accuracy: 0.9331 - val_loss: 0.1959 - val_accuracy: 0.9317 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9372\n",
            "Epoch 29: val_loss did not improve from 0.19591\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1748 - accuracy: 0.9372 - val_loss: 0.1968 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9378\n",
            "Epoch 30: val_loss improved from 0.19591 to 0.19319, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1727 - accuracy: 0.9379 - val_loss: 0.1932 - val_accuracy: 0.9321 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9380\n",
            "Epoch 31: val_loss did not improve from 0.19319\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1680 - accuracy: 0.9381 - val_loss: 0.2229 - val_accuracy: 0.9220 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9378\n",
            "Epoch 32: val_loss did not improve from 0.19319\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1724 - accuracy: 0.9378 - val_loss: 0.2193 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9380\n",
            "Epoch 33: val_loss improved from 0.19319 to 0.19287, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1705 - accuracy: 0.9379 - val_loss: 0.1929 - val_accuracy: 0.9266 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9380\n",
            "Epoch 34: val_loss did not improve from 0.19287\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1696 - accuracy: 0.9381 - val_loss: 0.1956 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9436\n",
            "Epoch 35: val_loss improved from 0.19287 to 0.19224, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1552 - accuracy: 0.9435 - val_loss: 0.1922 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9411\n",
            "Epoch 36: val_loss did not improve from 0.19224\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1609 - accuracy: 0.9412 - val_loss: 0.2461 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9446\n",
            "Epoch 37: val_loss improved from 0.19224 to 0.17157, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1491 - accuracy: 0.9446 - val_loss: 0.1716 - val_accuracy: 0.9363 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9405\n",
            "Epoch 38: val_loss did not improve from 0.17157\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1629 - accuracy: 0.9405 - val_loss: 0.1815 - val_accuracy: 0.9347 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9438\n",
            "Epoch 39: val_loss improved from 0.17157 to 0.17010, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1542 - accuracy: 0.9439 - val_loss: 0.1701 - val_accuracy: 0.9367 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9459\n",
            "Epoch 40: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.1852 - val_accuracy: 0.9312 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9447\n",
            "Epoch 41: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1485 - accuracy: 0.9447 - val_loss: 0.1710 - val_accuracy: 0.9390 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9474\n",
            "Epoch 42: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1410 - accuracy: 0.9473 - val_loss: 0.1850 - val_accuracy: 0.9328 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9462\n",
            "Epoch 43: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1470 - accuracy: 0.9461 - val_loss: 0.1708 - val_accuracy: 0.9372 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9474\n",
            "Epoch 44: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1447 - accuracy: 0.9474 - val_loss: 0.1909 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9495\n",
            "Epoch 45: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1339 - accuracy: 0.9495 - val_loss: 0.1867 - val_accuracy: 0.9320 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9506\n",
            "Epoch 46: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1308 - accuracy: 0.9506 - val_loss: 0.2568 - val_accuracy: 0.9033 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9472\n",
            "Epoch 47: val_loss did not improve from 0.17010\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1435 - accuracy: 0.9473 - val_loss: 0.1969 - val_accuracy: 0.9274 - lr: 0.0010\n",
            "Epoch 48/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9530\n",
            "Epoch 48: val_loss improved from 0.17010 to 0.15531, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.1286 - accuracy: 0.9528 - val_loss: 0.1553 - val_accuracy: 0.9417 - lr: 0.0010\n",
            "Epoch 49/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9526\n",
            "Epoch 49: val_loss did not improve from 0.15531\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1274 - accuracy: 0.9525 - val_loss: 0.1945 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Epoch 50/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9522\n",
            "Epoch 50: val_loss did not improve from 0.15531\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1273 - accuracy: 0.9522 - val_loss: 0.1885 - val_accuracy: 0.9317 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 0.9512\n",
            "Epoch 51: val_loss did not improve from 0.15531\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1322 - accuracy: 0.9512 - val_loss: 0.3238 - val_accuracy: 0.8723 - lr: 0.0010\n",
            "Epoch 52/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9514\n",
            "Epoch 52: val_loss did not improve from 0.15531\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1308 - accuracy: 0.9514 - val_loss: 0.1715 - val_accuracy: 0.9368 - lr: 0.0010\n",
            "Epoch 53/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9582\n",
            "Epoch 53: val_loss improved from 0.15531 to 0.14874, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1103 - accuracy: 0.9582 - val_loss: 0.1487 - val_accuracy: 0.9452 - lr: 0.0010\n",
            "Epoch 54/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9539\n",
            "Epoch 54: val_loss did not improve from 0.14874\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1237 - accuracy: 0.9538 - val_loss: 0.1743 - val_accuracy: 0.9360 - lr: 0.0010\n",
            "Epoch 55/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.9561\n",
            "Epoch 55: val_loss did not improve from 0.14874\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1201 - accuracy: 0.9561 - val_loss: 0.2135 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 56/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9580\n",
            "Epoch 56: val_loss did not improve from 0.14874\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1136 - accuracy: 0.9579 - val_loss: 0.1738 - val_accuracy: 0.9373 - lr: 0.0010\n",
            "Epoch 57/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9581\n",
            "Epoch 57: val_loss did not improve from 0.14874\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1110 - accuracy: 0.9580 - val_loss: 0.1970 - val_accuracy: 0.9314 - lr: 0.0010\n",
            "Epoch 58/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9572\n",
            "Epoch 58: val_loss improved from 0.14874 to 0.14690, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1139 - accuracy: 0.9570 - val_loss: 0.1469 - val_accuracy: 0.9452 - lr: 0.0010\n",
            "Epoch 59/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9641\n",
            "Epoch 59: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0948 - accuracy: 0.9641 - val_loss: 0.1568 - val_accuracy: 0.9430 - lr: 0.0010\n",
            "Epoch 60/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9598\n",
            "Epoch 60: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1088 - accuracy: 0.9598 - val_loss: 0.1626 - val_accuracy: 0.9411 - lr: 0.0010\n",
            "Epoch 61/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9614\n",
            "Epoch 61: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1009 - accuracy: 0.9616 - val_loss: 0.1580 - val_accuracy: 0.9389 - lr: 0.0010\n",
            "Epoch 62/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1095 - accuracy: 0.9604\n",
            "Epoch 62: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1096 - accuracy: 0.9604 - val_loss: 0.1505 - val_accuracy: 0.9437 - lr: 0.0010\n",
            "Epoch 63/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1267 - accuracy: 0.9538\n",
            "Epoch 63: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1267 - accuracy: 0.9538 - val_loss: 0.1508 - val_accuracy: 0.9405 - lr: 0.0010\n",
            "Epoch 64/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9636\n",
            "Epoch 64: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0987 - accuracy: 0.9636 - val_loss: 0.1762 - val_accuracy: 0.9376 - lr: 0.0010\n",
            "Epoch 65/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9642\n",
            "Epoch 65: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0974 - accuracy: 0.9642 - val_loss: 0.1485 - val_accuracy: 0.9457 - lr: 0.0010\n",
            "Epoch 66/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9633\n",
            "Epoch 66: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0997 - accuracy: 0.9633 - val_loss: 0.1628 - val_accuracy: 0.9380 - lr: 0.0010\n",
            "Epoch 67/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9687\n",
            "Epoch 67: val_loss did not improve from 0.14690\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0855 - accuracy: 0.9688 - val_loss: 0.1563 - val_accuracy: 0.9412 - lr: 0.0010\n",
            "Epoch 68/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9671\n",
            "Epoch 68: val_loss did not improve from 0.14690\n",
            "\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0925 - accuracy: 0.9672 - val_loss: 0.1494 - val_accuracy: 0.9443 - lr: 0.0010\n",
            "Epoch 69/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9816\n",
            "Epoch 69: val_loss improved from 0.14690 to 0.13202, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.0540 - accuracy: 0.9817 - val_loss: 0.1320 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
            "Epoch 70/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9877\n",
            "Epoch 70: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.1420 - val_accuracy: 0.9466 - lr: 5.0000e-04\n",
            "Epoch 71/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9881\n",
            "Epoch 71: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.1329 - val_accuracy: 0.9514 - lr: 5.0000e-04\n",
            "Epoch 72/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9861\n",
            "Epoch 72: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.1443 - val_accuracy: 0.9473 - lr: 5.0000e-04\n",
            "Epoch 73/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9853\n",
            "Epoch 73: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.1554 - val_accuracy: 0.9446 - lr: 5.0000e-04\n",
            "Epoch 74/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9857\n",
            "Epoch 74: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.1452 - val_accuracy: 0.9461 - lr: 5.0000e-04\n",
            "Epoch 75/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9861\n",
            "Epoch 75: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.1562 - val_accuracy: 0.9432 - lr: 5.0000e-04\n",
            "Epoch 76/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9853\n",
            "Epoch 76: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 0.1536 - val_accuracy: 0.9450 - lr: 5.0000e-04\n",
            "Epoch 77/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9848\n",
            "Epoch 77: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.1470 - val_accuracy: 0.9498 - lr: 5.0000e-04\n",
            "Epoch 78/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9873\n",
            "Epoch 78: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.1451 - val_accuracy: 0.9500 - lr: 5.0000e-04\n",
            "Epoch 79/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9841\n",
            "Epoch 79: val_loss did not improve from 0.13202\n",
            "\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 0.1805 - val_accuracy: 0.9383 - lr: 5.0000e-04\n",
            "Epoch 80/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9926\n",
            "Epoch 80: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.1441 - val_accuracy: 0.9510 - lr: 2.5000e-04\n",
            "Epoch 81/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9963\n",
            "Epoch 81: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.1435 - val_accuracy: 0.9512 - lr: 2.5000e-04\n",
            "Epoch 82/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9974\n",
            "Epoch 82: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 0.1482 - val_accuracy: 0.9495 - lr: 2.5000e-04\n",
            "Epoch 83/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9977\n",
            "Epoch 83: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1546 - val_accuracy: 0.9494 - lr: 2.5000e-04\n",
            "Epoch 84/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9966\n",
            "Epoch 84: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.1468 - val_accuracy: 0.9522 - lr: 2.5000e-04\n",
            "Epoch 85/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9975\n",
            "Epoch 85: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.1468 - val_accuracy: 0.9526 - lr: 2.5000e-04\n",
            "Epoch 86/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9964\n",
            "Epoch 86: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.1576 - val_accuracy: 0.9493 - lr: 2.5000e-04\n",
            "Epoch 87/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9936\n",
            "Epoch 87: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 0.1828 - val_accuracy: 0.9357 - lr: 2.5000e-04\n",
            "Epoch 88/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9947\n",
            "Epoch 88: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.1554 - val_accuracy: 0.9481 - lr: 2.5000e-04\n",
            "Epoch 89/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9966\n",
            "Epoch 89: val_loss did not improve from 0.13202\n",
            "\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 0.1562 - val_accuracy: 0.9507 - lr: 2.5000e-04\n",
            "Epoch 90/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9988\n",
            "Epoch 90: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.1543 - val_accuracy: 0.9510 - lr: 1.2500e-04\n",
            "Epoch 91/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9993\n",
            "Epoch 91: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.1481 - val_accuracy: 0.9540 - lr: 1.2500e-04\n",
            "Epoch 92/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9989\n",
            "Epoch 92: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.1474 - val_accuracy: 0.9534 - lr: 1.2500e-04\n",
            "Epoch 93/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9990\n",
            "Epoch 93: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.1486 - val_accuracy: 0.9517 - lr: 1.2500e-04\n",
            "Epoch 94/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993\n",
            "Epoch 94: val_loss did not improve from 0.13202\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.1513 - val_accuracy: 0.9537 - lr: 1.2500e-04\n",
            "Epoch 94: early stopping\n"
          ]
        }
      ],
      "source": [
        "#if doing 3 label categories\n",
        "model_ma = DeepConvNet(input_shape=(1,3,2000),\n",
        "                    num_class=4,\n",
        "                    dropout_rate=0,\n",
        "                    patience = 10,\n",
        "                    epochs = 300,\n",
        "                    factor = 0.5,\n",
        "                    lr = 1e-3,\n",
        "                    min_lr = 1e-6,\n",
        "                    es_patience = 25,\n",
        "                    batch_size = 256,\n",
        "                    shuffle=True\n",
        "                    )\n",
        "model_ma.fit(x_train, y_train_ma, x_test, y_test_ma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUjp8AGUxgg2",
        "outputId": "0be192ed-ff2d-4591-b0c3-22204de4ed14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1, 3, 2000)]      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 25, 3, 1996)       150       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 25, 1, 1996)       1900      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 25, 1, 1996)      100       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 25, 1, 1996)       0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 25, 1, 998)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 25, 1, 998)        0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 50, 1, 994)        6300      \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 50, 1, 994)       200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 50, 1, 994)        0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 50, 1, 497)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 50, 1, 497)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 100, 1, 493)       25100     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 100, 1, 493)      400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 100, 1, 493)       0         \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 100, 1, 246)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 100, 1, 246)       0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 200, 1, 242)       100200    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 200, 1, 242)      800       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 200, 1, 242)       0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 200, 1, 121)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 200, 1, 121)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 24200)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 121005    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,155\n",
            "Trainable params: 255,405\n",
            "Non-trainable params: 750\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "  5/170 [..............................] - ETA: 6s - loss: 11.4980 - accuracy: 0.2422WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0161s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.\n",
            "169/170 [============================>.] - ETA: 0s - loss: 2.6841 - accuracy: 0.5377\n",
            "Epoch 1: val_loss improved from inf to 1.16284, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 9s 46ms/step - loss: 2.6774 - accuracy: 0.5378 - val_loss: 1.1628 - val_accuracy: 0.6314 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.1075 - accuracy: 0.6221\n",
            "Epoch 2: val_loss improved from 1.16284 to 0.99739, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 1.1066 - accuracy: 0.6223 - val_loss: 0.9974 - val_accuracy: 0.6517 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 1.0022 - accuracy: 0.6383\n",
            "Epoch 3: val_loss improved from 0.99739 to 0.93806, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 1.0024 - accuracy: 0.6380 - val_loss: 0.9381 - val_accuracy: 0.6593 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9584 - accuracy: 0.6537\n",
            "Epoch 4: val_loss improved from 0.93806 to 0.91751, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.9595 - accuracy: 0.6537 - val_loss: 0.9175 - val_accuracy: 0.6770 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9735 - accuracy: 0.6466\n",
            "Epoch 5: val_loss did not improve from 0.91751\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.9730 - accuracy: 0.6468 - val_loss: 0.9747 - val_accuracy: 0.6677 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9073 - accuracy: 0.6646\n",
            "Epoch 6: val_loss improved from 0.91751 to 0.84959, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.9070 - accuracy: 0.6646 - val_loss: 0.8496 - val_accuracy: 0.6779 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.6568\n",
            "Epoch 7: val_loss did not improve from 0.84959\n",
            "170/170 [==============================] - 8s 45ms/step - loss: 0.9328 - accuracy: 0.6566 - val_loss: 0.9696 - val_accuracy: 0.6462 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8680 - accuracy: 0.6761\n",
            "Epoch 8: val_loss did not improve from 0.84959\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.8674 - accuracy: 0.6763 - val_loss: 0.8580 - val_accuracy: 0.6648 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.8061 - accuracy: 0.6996\n",
            "Epoch 9: val_loss improved from 0.84959 to 0.75516, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.8061 - accuracy: 0.6997 - val_loss: 0.7552 - val_accuracy: 0.7372 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.7534 - accuracy: 0.7246\n",
            "Epoch 10: val_loss improved from 0.75516 to 0.61390, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.7530 - accuracy: 0.7251 - val_loss: 0.6139 - val_accuracy: 0.7881 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.7683\n",
            "Epoch 11: val_loss improved from 0.61390 to 0.56833, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 43ms/step - loss: 0.6435 - accuracy: 0.7683 - val_loss: 0.5683 - val_accuracy: 0.8096 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7990\n",
            "Epoch 12: val_loss did not improve from 0.56833\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.5674 - accuracy: 0.7989 - val_loss: 0.5797 - val_accuracy: 0.8112 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.8308\n",
            "Epoch 13: val_loss improved from 0.56833 to 0.54287, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.4870 - accuracy: 0.8306 - val_loss: 0.5429 - val_accuracy: 0.8090 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.8408\n",
            "Epoch 14: val_loss improved from 0.54287 to 0.37223, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.4633 - accuracy: 0.8411 - val_loss: 0.3722 - val_accuracy: 0.8660 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8725\n",
            "Epoch 15: val_loss did not improve from 0.37223\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.3667 - accuracy: 0.8725 - val_loss: 0.4078 - val_accuracy: 0.8746 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.3462 - accuracy: 0.8825\n",
            "Epoch 16: val_loss did not improve from 0.37223\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.3460 - accuracy: 0.8826 - val_loss: 0.3792 - val_accuracy: 0.8702 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.8916\n",
            "Epoch 17: val_loss improved from 0.37223 to 0.29288, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.3195 - accuracy: 0.8917 - val_loss: 0.2929 - val_accuracy: 0.9040 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2971 - accuracy: 0.9006\n",
            "Epoch 18: val_loss improved from 0.29288 to 0.28413, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2965 - accuracy: 0.9008 - val_loss: 0.2841 - val_accuracy: 0.9114 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.9000\n",
            "Epoch 19: val_loss improved from 0.28413 to 0.26654, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2953 - accuracy: 0.9002 - val_loss: 0.2665 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9165\n",
            "Epoch 20: val_loss improved from 0.26654 to 0.26396, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2459 - accuracy: 0.9166 - val_loss: 0.2640 - val_accuracy: 0.9192 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.9056\n",
            "Epoch 21: val_loss did not improve from 0.26396\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2802 - accuracy: 0.9055 - val_loss: 0.3747 - val_accuracy: 0.8707 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9136\n",
            "Epoch 22: val_loss did not improve from 0.26396\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2568 - accuracy: 0.9136 - val_loss: 0.2834 - val_accuracy: 0.8893 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.9142\n",
            "Epoch 23: val_loss did not improve from 0.26396\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2552 - accuracy: 0.9140 - val_loss: 0.2684 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9206\n",
            "Epoch 24: val_loss improved from 0.26396 to 0.26323, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2329 - accuracy: 0.9207 - val_loss: 0.2632 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9243\n",
            "Epoch 25: val_loss improved from 0.26323 to 0.22426, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.2181 - accuracy: 0.9243 - val_loss: 0.2243 - val_accuracy: 0.9264 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9332\n",
            "Epoch 26: val_loss improved from 0.22426 to 0.20523, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1895 - accuracy: 0.9331 - val_loss: 0.2052 - val_accuracy: 0.9263 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9288\n",
            "Epoch 27: val_loss did not improve from 0.20523\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.2034 - accuracy: 0.9286 - val_loss: 0.2095 - val_accuracy: 0.9300 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9348\n",
            "Epoch 28: val_loss did not improve from 0.20523\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1847 - accuracy: 0.9348 - val_loss: 0.2119 - val_accuracy: 0.9349 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9362\n",
            "Epoch 29: val_loss improved from 0.20523 to 0.17768, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1799 - accuracy: 0.9362 - val_loss: 0.1777 - val_accuracy: 0.9373 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9361\n",
            "Epoch 30: val_loss did not improve from 0.17768\n",
            "170/170 [==============================] - 7s 44ms/step - loss: 0.1812 - accuracy: 0.9359 - val_loss: 0.3938 - val_accuracy: 0.8608 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9311\n",
            "Epoch 31: val_loss did not improve from 0.17768\n",
            "170/170 [==============================] - 8s 44ms/step - loss: 0.1925 - accuracy: 0.9310 - val_loss: 0.2514 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9361\n",
            "Epoch 32: val_loss improved from 0.17768 to 0.16184, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1773 - accuracy: 0.9361 - val_loss: 0.1618 - val_accuracy: 0.9392 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.9341\n",
            "Epoch 33: val_loss did not improve from 0.16184\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1884 - accuracy: 0.9338 - val_loss: 0.2048 - val_accuracy: 0.9218 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9421\n",
            "Epoch 34: val_loss improved from 0.16184 to 0.15942, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1612 - accuracy: 0.9420 - val_loss: 0.1594 - val_accuracy: 0.9399 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9386\n",
            "Epoch 35: val_loss did not improve from 0.15942\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1716 - accuracy: 0.9386 - val_loss: 0.2047 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9421\n",
            "Epoch 36: val_loss improved from 0.15942 to 0.15870, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1623 - accuracy: 0.9422 - val_loss: 0.1587 - val_accuracy: 0.9380 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9442\n",
            "Epoch 37: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1549 - accuracy: 0.9441 - val_loss: 0.2154 - val_accuracy: 0.9182 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9389\n",
            "Epoch 38: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1702 - accuracy: 0.9390 - val_loss: 0.2129 - val_accuracy: 0.9332 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9429\n",
            "Epoch 39: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1577 - accuracy: 0.9428 - val_loss: 0.1931 - val_accuracy: 0.9295 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9406\n",
            "Epoch 40: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1622 - accuracy: 0.9405 - val_loss: 0.2028 - val_accuracy: 0.9246 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9420\n",
            "Epoch 41: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1586 - accuracy: 0.9420 - val_loss: 0.1824 - val_accuracy: 0.9369 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1400 - accuracy: 0.9492\n",
            "Epoch 42: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.1400 - accuracy: 0.9492 - val_loss: 0.1843 - val_accuracy: 0.9297 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9458\n",
            "Epoch 43: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1481 - accuracy: 0.9459 - val_loss: 0.1587 - val_accuracy: 0.9383 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9491\n",
            "Epoch 44: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1367 - accuracy: 0.9492 - val_loss: 0.2126 - val_accuracy: 0.9196 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9465\n",
            "Epoch 45: val_loss did not improve from 0.15870\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1457 - accuracy: 0.9465 - val_loss: 0.1639 - val_accuracy: 0.9357 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 0.9523\n",
            "Epoch 46: val_loss did not improve from 0.15870\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.1294 - accuracy: 0.9521 - val_loss: 0.1626 - val_accuracy: 0.9418 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0868 - accuracy: 0.9684\n",
            "Epoch 47: val_loss improved from 0.15870 to 0.13394, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0871 - accuracy: 0.9682 - val_loss: 0.1339 - val_accuracy: 0.9494 - lr: 5.0000e-04\n",
            "Epoch 48/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9749\n",
            "Epoch 48: val_loss improved from 0.13394 to 0.13349, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.1335 - val_accuracy: 0.9500 - lr: 5.0000e-04\n",
            "Epoch 49/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9751\n",
            "Epoch 49: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0754 - accuracy: 0.9751 - val_loss: 0.1490 - val_accuracy: 0.9417 - lr: 5.0000e-04\n",
            "Epoch 50/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9759\n",
            "Epoch 50: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0734 - accuracy: 0.9759 - val_loss: 0.1589 - val_accuracy: 0.9443 - lr: 5.0000e-04\n",
            "Epoch 51/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 0.9742\n",
            "Epoch 51: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0766 - accuracy: 0.9743 - val_loss: 0.1372 - val_accuracy: 0.9490 - lr: 5.0000e-04\n",
            "Epoch 52/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9729\n",
            "Epoch 52: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0792 - accuracy: 0.9728 - val_loss: 0.1426 - val_accuracy: 0.9459 - lr: 5.0000e-04\n",
            "Epoch 53/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9769\n",
            "Epoch 53: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0687 - accuracy: 0.9769 - val_loss: 0.1374 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
            "Epoch 54/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9741\n",
            "Epoch 54: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0750 - accuracy: 0.9741 - val_loss: 0.1446 - val_accuracy: 0.9452 - lr: 5.0000e-04\n",
            "Epoch 55/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9746\n",
            "Epoch 55: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: 0.1430 - val_accuracy: 0.9472 - lr: 5.0000e-04\n",
            "Epoch 56/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9742\n",
            "Epoch 56: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0740 - accuracy: 0.9742 - val_loss: 0.1486 - val_accuracy: 0.9454 - lr: 5.0000e-04\n",
            "Epoch 57/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9727\n",
            "Epoch 57: val_loss did not improve from 0.13349\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0776 - accuracy: 0.9728 - val_loss: 0.1469 - val_accuracy: 0.9499 - lr: 5.0000e-04\n",
            "Epoch 58/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9753\n",
            "Epoch 58: val_loss did not improve from 0.13349\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.1351 - val_accuracy: 0.9501 - lr: 5.0000e-04\n",
            "Epoch 59/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9870\n",
            "Epoch 59: val_loss improved from 0.13349 to 0.12948, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.1295 - val_accuracy: 0.9538 - lr: 2.5000e-04\n",
            "Epoch 60/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9902\n",
            "Epoch 60: val_loss improved from 0.12948 to 0.12500, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0373 - accuracy: 0.9903 - val_loss: 0.1250 - val_accuracy: 0.9541 - lr: 2.5000e-04\n",
            "Epoch 61/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9911\n",
            "Epoch 61: val_loss improved from 0.12500 to 0.12359, saving model to logs/DeepConvNet_out_weights.h5\n",
            "170/170 [==============================] - 7s 42ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 0.1236 - val_accuracy: 0.9557 - lr: 2.5000e-04\n",
            "Epoch 62/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9908\n",
            "Epoch 62: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0353 - accuracy: 0.9908 - val_loss: 0.1272 - val_accuracy: 0.9519 - lr: 2.5000e-04\n",
            "Epoch 63/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9898\n",
            "Epoch 63: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0376 - accuracy: 0.9898 - val_loss: 0.1326 - val_accuracy: 0.9541 - lr: 2.5000e-04\n",
            "Epoch 64/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9899\n",
            "Epoch 64: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 0.1342 - val_accuracy: 0.9521 - lr: 2.5000e-04\n",
            "Epoch 65/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9900\n",
            "Epoch 65: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.1277 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
            "Epoch 66/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9913\n",
            "Epoch 66: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.1261 - val_accuracy: 0.9541 - lr: 2.5000e-04\n",
            "Epoch 67/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9896\n",
            "Epoch 67: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.1305 - val_accuracy: 0.9523 - lr: 2.5000e-04\n",
            "Epoch 68/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9913\n",
            "Epoch 68: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0340 - accuracy: 0.9913 - val_loss: 0.1243 - val_accuracy: 0.9559 - lr: 2.5000e-04\n",
            "Epoch 69/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9918\n",
            "Epoch 69: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0330 - accuracy: 0.9918 - val_loss: 0.1272 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
            "Epoch 70/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9920\n",
            "Epoch 70: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0322 - accuracy: 0.9920 - val_loss: 0.1372 - val_accuracy: 0.9512 - lr: 2.5000e-04\n",
            "Epoch 71/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9900\n",
            "Epoch 71: val_loss did not improve from 0.12359\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0377 - accuracy: 0.9900 - val_loss: 0.1316 - val_accuracy: 0.9541 - lr: 2.5000e-04\n",
            "Epoch 72/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9948\n",
            "Epoch 72: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.1308 - val_accuracy: 0.9561 - lr: 1.2500e-04\n",
            "Epoch 73/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9967\n",
            "Epoch 73: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0199 - accuracy: 0.9967 - val_loss: 0.1377 - val_accuracy: 0.9527 - lr: 1.2500e-04\n",
            "Epoch 74/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9974\n",
            "Epoch 74: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0178 - accuracy: 0.9974 - val_loss: 0.1400 - val_accuracy: 0.9551 - lr: 1.2500e-04\n",
            "Epoch 75/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9973\n",
            "Epoch 75: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0180 - accuracy: 0.9973 - val_loss: 0.1356 - val_accuracy: 0.9543 - lr: 1.2500e-04\n",
            "Epoch 76/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9981\n",
            "Epoch 76: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0159 - accuracy: 0.9981 - val_loss: 0.1284 - val_accuracy: 0.9579 - lr: 1.2500e-04\n",
            "Epoch 77/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9973\n",
            "Epoch 77: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 0.1316 - val_accuracy: 0.9575 - lr: 1.2500e-04\n",
            "Epoch 78/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9974\n",
            "Epoch 78: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.1289 - val_accuracy: 0.9567 - lr: 1.2500e-04\n",
            "Epoch 79/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9977\n",
            "Epoch 79: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0169 - accuracy: 0.9977 - val_loss: 0.1360 - val_accuracy: 0.9570 - lr: 1.2500e-04\n",
            "Epoch 80/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9981\n",
            "Epoch 80: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0156 - accuracy: 0.9981 - val_loss: 0.1335 - val_accuracy: 0.9558 - lr: 1.2500e-04\n",
            "Epoch 81/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9972\n",
            "Epoch 81: val_loss did not improve from 0.12359\n",
            "\n",
            "Epoch 81: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0178 - accuracy: 0.9971 - val_loss: 0.1305 - val_accuracy: 0.9560 - lr: 1.2500e-04\n",
            "Epoch 82/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9987\n",
            "Epoch 82: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0138 - accuracy: 0.9987 - val_loss: 0.1387 - val_accuracy: 0.9534 - lr: 6.2500e-05\n",
            "Epoch 83/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9991\n",
            "Epoch 83: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0122 - accuracy: 0.9991 - val_loss: 0.1327 - val_accuracy: 0.9556 - lr: 6.2500e-05\n",
            "Epoch 84/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9987\n",
            "Epoch 84: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0121 - accuracy: 0.9987 - val_loss: 0.1276 - val_accuracy: 0.9584 - lr: 6.2500e-05\n",
            "Epoch 85/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9993\n",
            "Epoch 85: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0113 - accuracy: 0.9993 - val_loss: 0.1293 - val_accuracy: 0.9579 - lr: 6.2500e-05\n",
            "Epoch 86/300\n",
            "169/170 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9992\n",
            "Epoch 86: val_loss did not improve from 0.12359\n",
            "170/170 [==============================] - 7s 41ms/step - loss: 0.0113 - accuracy: 0.9992 - val_loss: 0.1316 - val_accuracy: 0.9564 - lr: 6.2500e-05\n",
            "Epoch 86: early stopping\n"
          ]
        }
      ],
      "source": [
        "#if doing 3 label categories\n",
        "model_mp = DeepConvNet(input_shape=(1,3,2000),\n",
        "                    num_class=5,\n",
        "                    dropout_rate=0,\n",
        "                    patience = 10,\n",
        "                    epochs = 300,\n",
        "                    factor = 0.5,\n",
        "                    lr = 1e-3,\n",
        "                    min_lr = 1e-6,\n",
        "                    es_patience = 25,\n",
        "                    batch_size = 256,\n",
        "                    shuffle=True\n",
        "                    )\n",
        "model_mp.fit(x_train, y_train_mp, x_test, y_test_mp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_m0yenUUf-4"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4ux6cLzGpCa",
        "outputId": "e73d232b-f5e6-4e26-a981-c1bebfde21cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-07 13:07:17--  https://learn.aiat.or.th/download/rgh4h5/final_test_dataset.zip\n",
            "Resolving learn.aiat.or.th (learn.aiat.or.th)... 110.78.211.34\n",
            "Connecting to learn.aiat.or.th (learn.aiat.or.th)|110.78.211.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 562054701 (536M) [application/zip]\n",
            "Saving to: ‘final_test_dataset.zip’\n",
            "\n",
            "final_test_dataset. 100%[===================>] 536.02M  15.9MB/s    in 37s     \n",
            "\n",
            "2022-04-07 13:07:55 (14.6 MB/s) - ‘final_test_dataset.zip’ saved [562054701/562054701]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://learn.aiat.or.th/download/rgh4h5/final_test_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0EwqgyvHzyZ"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/test_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxDxacOcHXnJ",
        "outputId": "e31ec80f-bd47-45ea-e1c9-9ded2f09e229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/final_test_dataset.zip\n",
            "   creating: /content/test_dataset/final_125000_test_dataset/\n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data0.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data10.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data100.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1000.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1001.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1002.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1003.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1004.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1005.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1006.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1007.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1008.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1009.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data101.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1010.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1011.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1012.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1013.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1014.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1015.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1016.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1017.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1018.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1019.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data102.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1020.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1021.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1022.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1023.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1024.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1025.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1026.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1027.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1028.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1029.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data103.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1030.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1031.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1032.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1033.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1034.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1035.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1036.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1037.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1038.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1039.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data104.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1040.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1041.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1042.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1043.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1044.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1045.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1046.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1047.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1048.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1049.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data105.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1050.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1051.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1052.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1053.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1054.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1055.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1056.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1057.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1058.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1059.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data106.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1060.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1061.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1062.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1063.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1064.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1065.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1066.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1067.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1068.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1069.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data107.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1070.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1071.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1072.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1073.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1074.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1075.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1076.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1077.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1078.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1079.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data108.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1080.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1081.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1082.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1083.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1084.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1085.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1086.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1087.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1088.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1089.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data109.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1090.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1091.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1092.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1093.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1094.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1095.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1096.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1097.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1098.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1099.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data11.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data110.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1100.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1101.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1102.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1103.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1104.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1105.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1106.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1107.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1108.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1109.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data111.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1110.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1111.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1112.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1113.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1114.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1115.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1116.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1117.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1118.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1119.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data112.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1120.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1121.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1122.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1123.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1124.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1125.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1126.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1127.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1128.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1129.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data113.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1130.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1131.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1132.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1133.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1134.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1135.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1136.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1137.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1138.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1139.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data114.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1140.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1141.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1142.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1143.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1144.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1145.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1146.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1147.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1148.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1149.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data115.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1150.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1151.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1152.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1153.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1154.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1155.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1156.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1157.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1158.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1159.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data116.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1160.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1161.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1162.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1163.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1164.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1165.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1166.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1167.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1168.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1169.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data117.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1170.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1171.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1172.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1173.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1174.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1175.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1176.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1177.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1178.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1179.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data118.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1180.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1181.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1182.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1183.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1184.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1185.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1186.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1187.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1188.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1189.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data119.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1190.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1191.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1192.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1193.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1194.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1195.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1196.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1197.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1198.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1199.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data12.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data120.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1200.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1201.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1202.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1203.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1204.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1205.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1206.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1207.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1208.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1209.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data121.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1210.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1211.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1212.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1213.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1214.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1215.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1216.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1217.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1218.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1219.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data122.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1220.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1221.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1222.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1223.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1224.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1225.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1226.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1227.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1228.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1229.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data123.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1230.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1231.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1232.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1233.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1234.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1235.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1236.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1237.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1238.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1239.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data124.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1240.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1241.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1242.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1243.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1244.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1245.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1246.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1247.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1248.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1249.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data125.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1250.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1251.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1252.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1253.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1254.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1255.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1256.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1257.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1258.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1259.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data126.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1260.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1261.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1262.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1263.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1264.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1265.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1266.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1267.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1268.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1269.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data127.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1270.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1271.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1272.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1273.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1274.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1275.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1276.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1277.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1278.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1279.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data128.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1280.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1281.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1282.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1283.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1284.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1285.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1286.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1287.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1288.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1289.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data129.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1290.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1291.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1292.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1293.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1294.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1295.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1296.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1297.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1298.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1299.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data13.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data130.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1300.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1301.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1302.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1303.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1304.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1305.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1306.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1307.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1308.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1309.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data131.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1310.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1311.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1312.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1313.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1314.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1315.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1316.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1317.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1318.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1319.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data132.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1320.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1321.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1322.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1323.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1324.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1325.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1326.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1327.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1328.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1329.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data133.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1330.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1331.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1332.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1333.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1334.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1335.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1336.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1337.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1338.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1339.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data134.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1340.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1341.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1342.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1343.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1344.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1345.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1346.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1347.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1348.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1349.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data135.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1350.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1351.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1352.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1353.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1354.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1355.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1356.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1357.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1358.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1359.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data136.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1360.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1361.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1362.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1363.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1364.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1365.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1366.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1367.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1368.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1369.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data137.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1370.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1371.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1372.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1373.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1374.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1375.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1376.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1377.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1378.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1379.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data138.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1380.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1381.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1382.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1383.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1384.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1385.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1386.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1387.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1388.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1389.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data139.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1390.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1391.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1392.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1393.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1394.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1395.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1396.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1397.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1398.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1399.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data14.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data140.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1400.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1401.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1402.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1403.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1404.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1405.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1406.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1407.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1408.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1409.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data141.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1410.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1411.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1412.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1413.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1414.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1415.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1416.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1417.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1418.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1419.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data142.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1420.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1421.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1422.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1423.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1424.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1425.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1426.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1427.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1428.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1429.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data143.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1430.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1431.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1432.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1433.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1434.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1435.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1436.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1437.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1438.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1439.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data144.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1440.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1441.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1442.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1443.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1444.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1445.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1446.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1447.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1448.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1449.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data145.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1450.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1451.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1452.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1453.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1454.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1455.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1456.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1457.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1458.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1459.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data146.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1460.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1461.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1462.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1463.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1464.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1465.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1466.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1467.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1468.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1469.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data147.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1470.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1471.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1472.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1473.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1474.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1475.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1476.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1477.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1478.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1479.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data148.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1480.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1481.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1482.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1483.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1484.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1485.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1486.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1487.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1488.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1489.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data149.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1490.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1491.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1492.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1493.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1494.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1495.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1496.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1497.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1498.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1499.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data15.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data150.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1500.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1501.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1502.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1503.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1504.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1505.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1506.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1507.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1508.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1509.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data151.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1510.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1511.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1512.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1513.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1514.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1515.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1516.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1517.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1518.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1519.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data152.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1520.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1521.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1522.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1523.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1524.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1525.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1526.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1527.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1528.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1529.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data153.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1530.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1531.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1532.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1533.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1534.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1535.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1536.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1537.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1538.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1539.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data154.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1540.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1541.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1542.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1543.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1544.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1545.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1546.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1547.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1548.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1549.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data155.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1550.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1551.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1552.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1553.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1554.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1555.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1556.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1557.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1558.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1559.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data156.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1560.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1561.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1562.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1563.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1564.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1565.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1566.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1567.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1568.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1569.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data157.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1570.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1571.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1572.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1573.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1574.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1575.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1576.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1577.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1578.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1579.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data158.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1580.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1581.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1582.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1583.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1584.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1585.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1586.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1587.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1588.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1589.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data159.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1590.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1591.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1592.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1593.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1594.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1595.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1596.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1597.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1598.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1599.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data16.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data160.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1600.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1601.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1602.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1603.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1604.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1605.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1606.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1607.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1608.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1609.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data161.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1610.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1611.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1612.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1613.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1614.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1615.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1616.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1617.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1618.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1619.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data162.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1620.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1621.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1622.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1623.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1624.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1625.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1626.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1627.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1628.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1629.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data163.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1630.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1631.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1632.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1633.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1634.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1635.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1636.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1637.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1638.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1639.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data164.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1640.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1641.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1642.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1643.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1644.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1645.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1646.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1647.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1648.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1649.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data165.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1650.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1651.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1652.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1653.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1654.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1655.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1656.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1657.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1658.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1659.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data166.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1660.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1661.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1662.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1663.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1664.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1665.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1666.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1667.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1668.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1669.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data167.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1670.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1671.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1672.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1673.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1674.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1675.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1676.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1677.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1678.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1679.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data168.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1680.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1681.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1682.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1683.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1684.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1685.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1686.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1687.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1688.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1689.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data169.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1690.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1691.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1692.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1693.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1694.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1695.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1696.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1697.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1698.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1699.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data17.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data170.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1700.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1701.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1702.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1703.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1704.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1705.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1706.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1707.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1708.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1709.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data171.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1710.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1711.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1712.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1713.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1714.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1715.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1716.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1717.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1718.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1719.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data172.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1720.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1721.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1722.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1723.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1724.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1725.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1726.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1727.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1728.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1729.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data173.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1730.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1731.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1732.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1733.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1734.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1735.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1736.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1737.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1738.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1739.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data174.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1740.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1741.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1742.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1743.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1744.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1745.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1746.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1747.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1748.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1749.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data175.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1750.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1751.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1752.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1753.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1754.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1755.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1756.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1757.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1758.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1759.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data176.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1760.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1761.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1762.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1763.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1764.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1765.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1766.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1767.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1768.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1769.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data177.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1770.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1771.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1772.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1773.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1774.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1775.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1776.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1777.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1778.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1779.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data178.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1780.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1781.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1782.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1783.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1784.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1785.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1786.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1787.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1788.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1789.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data179.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1790.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1791.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1792.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1793.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1794.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1795.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1796.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1797.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1798.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data1799.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data18.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data180.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data181.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data182.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data183.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data184.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data185.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data186.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data187.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data188.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data189.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data19.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data190.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data191.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data192.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data193.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data194.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data195.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data196.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data197.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data198.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data199.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data2.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data20.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data200.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data201.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data202.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data203.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data204.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data205.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data206.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data207.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data208.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data209.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data21.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data210.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data211.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data212.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data213.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data214.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data215.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data216.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data217.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data218.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data219.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data22.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data220.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data221.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data222.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data223.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data224.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data225.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data226.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data227.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data228.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data229.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data23.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data230.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data231.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data232.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data233.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data234.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data235.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data236.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data237.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data238.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data239.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data24.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data240.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data241.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data242.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data243.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data244.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data245.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data246.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data247.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data248.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data249.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data25.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data250.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data251.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data252.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data253.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data254.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data255.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data256.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data257.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data258.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data259.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data26.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data260.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data261.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data262.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data263.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data264.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data265.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data266.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data267.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data268.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data269.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data27.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data270.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data271.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data272.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data273.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data274.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data275.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data276.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data277.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data278.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data279.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data28.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data280.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data281.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data282.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data283.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data284.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data285.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data286.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data287.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data288.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data289.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data29.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data290.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data291.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data292.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data293.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data294.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data295.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data296.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data297.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data298.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data299.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data3.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data30.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data300.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data301.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data302.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data303.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data304.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data305.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data306.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data307.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data308.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data309.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data31.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data310.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data311.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data312.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data313.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data314.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data315.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data316.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data317.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data318.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data319.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data32.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data320.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data321.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data322.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data323.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data324.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data325.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data326.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data327.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data328.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data329.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data33.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data330.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data331.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data332.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data333.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data334.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data335.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data336.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data337.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data338.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data339.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data34.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data340.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data341.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data342.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data343.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data344.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data345.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data346.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data347.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data348.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data349.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data35.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data350.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data351.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data352.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data353.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data354.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data355.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data356.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data357.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data358.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data359.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data36.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data360.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data361.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data362.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data363.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data364.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data365.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data366.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data367.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data368.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data369.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data37.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data370.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data371.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data372.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data373.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data374.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data375.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data376.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data377.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data378.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data379.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data38.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data380.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data381.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data382.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data383.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data384.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data385.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data386.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data387.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data388.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data389.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data39.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data390.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data391.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data392.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data393.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data394.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data395.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data396.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data397.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data398.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data399.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data4.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data40.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data400.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data401.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data402.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data403.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data404.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data405.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data406.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data407.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data408.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data409.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data41.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data410.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data411.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data412.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data413.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data414.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data415.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data416.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data417.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data418.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data419.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data42.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data420.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data421.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data422.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data423.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data424.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data425.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data426.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data427.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data428.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data429.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data43.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data430.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data431.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data432.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data433.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data434.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data435.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data436.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data437.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data438.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data439.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data44.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data440.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data441.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data442.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data443.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data444.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data445.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data446.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data447.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data448.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data449.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data45.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data450.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data451.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data452.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data453.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data454.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data455.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data456.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data457.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data458.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data459.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data46.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data460.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data461.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data462.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data463.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data464.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data465.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data466.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data467.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data468.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data469.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data47.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data470.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data471.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data472.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data473.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data474.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data475.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data476.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data477.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data478.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data479.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data48.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data480.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data481.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data482.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data483.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data484.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data485.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data486.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data487.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data488.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data489.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data49.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data490.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data491.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data492.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data493.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data494.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data495.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data496.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data497.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data498.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data499.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data5.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data50.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data500.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data501.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data502.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data503.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data504.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data505.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data506.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data507.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data508.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data509.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data51.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data510.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data511.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data512.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data513.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data514.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data515.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data516.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data517.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data518.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data519.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data52.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data520.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data521.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data522.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data523.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data524.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data525.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data526.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data527.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data528.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data529.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data53.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data530.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data531.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data532.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data533.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data534.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data535.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data536.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data537.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data538.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data539.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data54.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data540.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data541.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data542.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data543.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data544.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data545.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data546.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data547.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data548.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data549.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data55.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data550.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data551.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data552.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data553.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data554.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data555.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data556.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data557.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data558.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data559.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data56.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data560.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data561.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data562.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data563.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data564.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data565.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data566.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data567.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data568.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data569.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data57.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data570.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data571.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data572.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data573.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data574.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data575.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data576.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data577.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data578.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data579.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data58.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data580.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data581.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data582.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data583.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data584.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data585.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data586.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data587.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data588.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data589.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data59.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data590.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data591.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data592.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data593.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data594.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data595.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data596.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data597.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data598.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data599.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data6.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data60.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data600.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data601.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data602.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data603.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data604.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data605.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data606.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data607.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data608.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data609.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data61.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data610.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data611.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data612.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data613.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data614.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data615.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data616.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data617.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data618.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data619.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data62.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data620.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data621.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data622.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data623.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data624.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data625.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data626.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data627.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data628.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data629.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data63.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data630.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data631.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data632.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data633.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data634.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data635.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data636.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data637.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data638.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data639.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data64.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data640.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data641.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data642.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data643.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data644.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data645.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data646.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data647.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data648.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data649.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data65.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data650.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data651.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data652.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data653.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data654.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data655.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data656.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data657.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data658.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data659.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data66.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data660.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data661.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data662.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data663.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data664.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data665.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data666.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data667.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data668.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data669.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data67.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data670.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data671.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data672.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data673.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data674.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data675.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data676.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data677.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data678.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data679.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data68.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data680.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data681.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data682.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data683.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data684.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data685.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data686.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data687.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data688.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data689.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data69.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data690.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data691.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data692.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data693.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data694.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data695.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data696.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data697.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data698.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data699.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data7.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data70.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data700.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data701.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data702.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data703.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data704.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data705.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data706.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data707.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data708.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data709.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data71.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data710.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data711.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data712.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data713.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data714.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data715.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data716.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data717.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data718.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data719.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data72.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data720.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data721.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data722.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data723.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data724.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data725.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data726.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data727.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data728.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data729.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data73.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data730.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data731.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data732.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data733.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data734.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data735.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data736.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data737.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data738.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data739.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data74.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data740.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data741.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data742.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data743.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data744.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data745.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data746.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data747.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data748.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data749.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data75.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data750.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data751.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data752.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data753.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data754.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data755.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data756.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data757.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data758.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data759.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data76.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data760.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data761.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data762.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data763.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data764.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data765.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data766.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data767.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data768.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data769.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data77.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data770.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data771.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data772.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data773.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data774.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data775.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data776.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data777.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data778.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data779.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data78.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data780.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data781.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data782.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data783.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data784.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data785.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data786.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data787.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data788.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data789.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data79.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data790.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data791.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data792.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data793.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data794.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data795.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data796.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data797.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data798.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data799.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data8.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data80.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data800.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data801.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data802.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data803.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data804.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data805.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data806.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data807.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data808.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data809.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data81.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data810.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data811.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data812.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data813.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data814.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data815.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data816.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data817.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data818.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data819.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data82.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data820.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data821.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data822.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data823.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data824.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data825.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data826.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data827.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data828.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data829.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data83.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data830.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data831.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data832.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data833.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data834.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data835.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data836.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data837.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data838.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data839.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data84.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data840.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data841.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data842.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data843.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data844.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data845.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data846.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data847.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data848.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data849.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data85.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data850.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data851.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data852.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data853.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data854.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data855.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data856.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data857.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data858.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data859.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data86.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data860.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data861.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data862.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data863.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data864.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data865.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data866.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data867.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data868.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data869.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data87.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data870.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data871.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data872.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data873.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data874.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data875.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data876.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data877.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data878.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data879.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data88.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data880.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data881.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data882.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data883.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data884.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data885.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data886.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data887.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data888.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data889.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data89.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data890.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data891.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data892.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data893.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data894.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data895.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data896.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data897.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data898.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data899.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data9.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data90.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data900.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data901.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data902.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data903.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data904.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data905.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data906.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data907.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data908.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data909.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data91.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data910.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data911.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data912.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data913.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data914.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data915.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data916.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data917.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data918.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data919.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data92.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data920.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data921.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data922.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data923.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data924.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data925.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data926.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data927.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data928.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data929.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data93.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data930.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data931.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data932.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data933.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data934.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data935.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data936.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data937.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data938.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data939.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data94.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data940.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data941.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data942.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data943.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data944.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data945.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data946.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data947.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data948.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data949.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data95.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data950.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data951.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data952.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data953.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data954.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data955.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data956.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data957.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data958.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data959.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data96.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data960.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data961.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data962.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data963.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data964.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data965.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data966.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data967.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data968.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data969.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data97.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data970.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data971.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data972.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data973.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data974.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data975.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data976.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data977.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data978.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data979.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data98.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data980.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data981.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data982.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data983.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data984.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data985.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data986.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data987.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data988.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data989.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data99.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data990.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data991.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data992.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data993.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data994.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data995.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data996.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data997.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data998.csv  \n",
            "  inflating: /content/test_dataset/final_125000_test_dataset/test_data999.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/final_test_dataset.zip -d /content/test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOWiLg8RMWeY",
        "outputId": "293d4866-b2fc-47de-d6f5-ed4c402247b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9001"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count=0\n",
        "for filename in os.listdir('/content/test_dataset'):\n",
        "  #if filename.endswith('.csv'):\n",
        "    count+=1\n",
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvl-mE9jHdVD",
        "outputId": "2be66b09-7879-4c71-c71e-12a0b1ae0066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1800/1800 [00:16<00:00, 107.21it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.00383867, 0.01327733, 0.02578502, ..., 0.05492069,\n",
              "          0.05364118, 0.03558253],\n",
              "         [0.00430348, 0.01015933, 0.01290986, ..., 0.01448439,\n",
              "          0.03051759, 0.0130348 ],\n",
              "         [0.00783522, 0.0172916 , 0.03496742, ..., 0.04422406,\n",
              "          0.0380878 , 0.03940645]]],\n",
              "\n",
              "\n",
              "       [[[0.00286146, 0.00818032, 0.00959736, ..., 0.01927995,\n",
              "          0.02927332, 0.01633788],\n",
              "         [0.00411028, 0.00732311, 0.00844265, ..., 0.00409388,\n",
              "          0.02514697, 0.01253675],\n",
              "         [0.00515118, 0.01359107, 0.01168747, ..., 0.03552276,\n",
              "          0.04347438, 0.02475249]]],\n",
              "\n",
              "\n",
              "       [[[0.00951685, 0.01880737, 0.02492013, ..., 0.06219242,\n",
              "          0.07574457, 0.07466477],\n",
              "         [0.00143503, 0.00734462, 0.01257323, ..., 0.02315752,\n",
              "          0.02552488, 0.01997022],\n",
              "         [0.01255551, 0.0550151 , 0.06428   , ..., 0.05799996,\n",
              "          0.0813975 , 0.07216995]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.00587882, 0.00807228, 0.02209996, ..., 0.02436702,\n",
              "          0.04976074, 0.04765764],\n",
              "         [0.00208772, 0.00603565, 0.01299082, ..., 0.00853206,\n",
              "          0.0278866 , 0.02560625],\n",
              "         [0.0127234 , 0.0215985 , 0.02497764, ..., 0.0527152 ,\n",
              "          0.06801617, 0.1721993 ]]],\n",
              "\n",
              "\n",
              "       [[[0.00738542, 0.03424564, 0.03144372, ..., 0.0302271 ,\n",
              "          0.02512818, 0.0215165 ],\n",
              "         [0.00515735, 0.01048774, 0.01404787, ..., 0.02730637,\n",
              "          0.03332337, 0.01790045],\n",
              "         [0.01259502, 0.03208266, 0.06269451, ..., 0.05623909,\n",
              "          0.10825269, 0.04992542]]],\n",
              "\n",
              "\n",
              "       [[[0.00449885, 0.01675986, 0.0493857 , ..., 0.03056113,\n",
              "          0.04214096, 0.04891485],\n",
              "         [0.00095338, 0.0049888 , 0.03244458, ..., 0.02465377,\n",
              "          0.02465216, 0.01047847],\n",
              "         [0.00443501, 0.01971599, 0.04076587, ..., 0.07363584,\n",
              "          0.05612138, 0.03889974]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "test_preprocessed, file_list = preprocessing('/content/test_dataset/final_125000_test_dataset', False)\n",
        "test_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N8Tei4phbo5"
      },
      "outputs": [],
      "source": [
        "#test_preprocessed = np.expand_dims(test_preprocessed, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw11rWxENmf2",
        "outputId": "c429ff53-1ab5-4e9b-bacf-ed0d031b420d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800, 1, 3, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "test_preprocessed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX8TON_MNR2A",
        "outputId": "f60420d6-05f7-4b37-c7e8-1f8b4bf175f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_data795.csv',\n",
              " 'test_data1110.csv',\n",
              " 'test_data1363.csv',\n",
              " 'test_data769.csv',\n",
              " 'test_data1442.csv',\n",
              " 'test_data1425.csv',\n",
              " 'test_data277.csv',\n",
              " 'test_data1165.csv',\n",
              " 'test_data345.csv',\n",
              " 'test_data1392.csv',\n",
              " 'test_data197.csv',\n",
              " 'test_data896.csv',\n",
              " 'test_data172.csv',\n",
              " 'test_data951.csv',\n",
              " 'test_data786.csv',\n",
              " 'test_data1028.csv',\n",
              " 'test_data1320.csv',\n",
              " 'test_data1691.csv',\n",
              " 'test_data676.csv',\n",
              " 'test_data625.csv',\n",
              " 'test_data1495.csv',\n",
              " 'test_data414.csv',\n",
              " 'test_data517.csv',\n",
              " 'test_data645.csv',\n",
              " 'test_data1043.csv',\n",
              " 'test_data1637.csv',\n",
              " 'test_data408.csv',\n",
              " 'test_data655.csv',\n",
              " 'test_data1724.csv',\n",
              " 'test_data1535.csv',\n",
              " 'test_data382.csv',\n",
              " 'test_data1465.csv',\n",
              " 'test_data688.csv',\n",
              " 'test_data1711.csv',\n",
              " 'test_data1595.csv',\n",
              " 'test_data1047.csv',\n",
              " 'test_data1423.csv',\n",
              " 'test_data1548.csv',\n",
              " 'test_data12.csv',\n",
              " 'test_data1745.csv',\n",
              " 'test_data623.csv',\n",
              " 'test_data349.csv',\n",
              " 'test_data921.csv',\n",
              " 'test_data1104.csv',\n",
              " 'test_data681.csv',\n",
              " 'test_data929.csv',\n",
              " 'test_data754.csv',\n",
              " 'test_data1348.csv',\n",
              " 'test_data668.csv',\n",
              " 'test_data599.csv',\n",
              " 'test_data1233.csv',\n",
              " 'test_data1112.csv',\n",
              " 'test_data1355.csv',\n",
              " 'test_data163.csv',\n",
              " 'test_data1264.csv',\n",
              " 'test_data432.csv',\n",
              " 'test_data234.csv',\n",
              " 'test_data1017.csv',\n",
              " 'test_data1794.csv',\n",
              " 'test_data1343.csv',\n",
              " 'test_data1005.csv',\n",
              " 'test_data16.csv',\n",
              " 'test_data1367.csv',\n",
              " 'test_data603.csv',\n",
              " 'test_data99.csv',\n",
              " 'test_data1590.csv',\n",
              " 'test_data1587.csv',\n",
              " 'test_data451.csv',\n",
              " 'test_data684.csv',\n",
              " 'test_data749.csv',\n",
              " 'test_data146.csv',\n",
              " 'test_data1290.csv',\n",
              " 'test_data385.csv',\n",
              " 'test_data298.csv',\n",
              " 'test_data1144.csv',\n",
              " 'test_data1421.csv',\n",
              " 'test_data222.csv',\n",
              " 'test_data932.csv',\n",
              " 'test_data1424.csv',\n",
              " 'test_data953.csv',\n",
              " 'test_data779.csv',\n",
              " 'test_data1473.csv',\n",
              " 'test_data1676.csv',\n",
              " 'test_data1704.csv',\n",
              " 'test_data1577.csv',\n",
              " 'test_data26.csv',\n",
              " 'test_data228.csv',\n",
              " 'test_data1799.csv',\n",
              " 'test_data140.csv',\n",
              " 'test_data593.csv',\n",
              " 'test_data106.csv',\n",
              " 'test_data1321.csv',\n",
              " 'test_data1661.csv',\n",
              " 'test_data740.csv',\n",
              " 'test_data1693.csv',\n",
              " 'test_data214.csv',\n",
              " 'test_data1143.csv',\n",
              " 'test_data238.csv',\n",
              " 'test_data907.csv',\n",
              " 'test_data665.csv',\n",
              " 'test_data158.csv',\n",
              " 'test_data86.csv',\n",
              " 'test_data1708.csv',\n",
              " 'test_data1251.csv',\n",
              " 'test_data1352.csv',\n",
              " 'test_data938.csv',\n",
              " 'test_data1344.csv',\n",
              " 'test_data640.csv',\n",
              " 'test_data168.csv',\n",
              " 'test_data404.csv',\n",
              " 'test_data1778.csv',\n",
              " 'test_data955.csv',\n",
              " 'test_data853.csv',\n",
              " 'test_data1717.csv',\n",
              " 'test_data74.csv',\n",
              " 'test_data1114.csv',\n",
              " 'test_data1067.csv',\n",
              " 'test_data278.csv',\n",
              " 'test_data669.csv',\n",
              " 'test_data252.csv',\n",
              " 'test_data589.csv',\n",
              " 'test_data1390.csv',\n",
              " 'test_data1329.csv',\n",
              " 'test_data1129.csv',\n",
              " 'test_data602.csv',\n",
              " 'test_data687.csv',\n",
              " 'test_data402.csv',\n",
              " 'test_data1569.csv',\n",
              " 'test_data917.csv',\n",
              " 'test_data1081.csv',\n",
              " 'test_data813.csv',\n",
              " 'test_data1195.csv',\n",
              " 'test_data1740.csv',\n",
              " 'test_data1157.csv',\n",
              " 'test_data1457.csv',\n",
              " 'test_data387.csv',\n",
              " 'test_data59.csv',\n",
              " 'test_data184.csv',\n",
              " 'test_data900.csv',\n",
              " 'test_data125.csv',\n",
              " 'test_data1540.csv',\n",
              " 'test_data1524.csv',\n",
              " 'test_data84.csv',\n",
              " 'test_data2.csv',\n",
              " 'test_data240.csv',\n",
              " 'test_data1189.csv',\n",
              " 'test_data581.csv',\n",
              " 'test_data131.csv',\n",
              " 'test_data221.csv',\n",
              " 'test_data80.csv',\n",
              " 'test_data62.csv',\n",
              " 'test_data960.csv',\n",
              " 'test_data559.csv',\n",
              " 'test_data366.csv',\n",
              " 'test_data1113.csv',\n",
              " 'test_data452.csv',\n",
              " 'test_data926.csv',\n",
              " 'test_data622.csv',\n",
              " 'test_data1761.csv',\n",
              " 'test_data45.csv',\n",
              " 'test_data1252.csv',\n",
              " 'test_data922.csv',\n",
              " 'test_data1785.csv',\n",
              " 'test_data1262.csv',\n",
              " 'test_data405.csv',\n",
              " 'test_data504.csv',\n",
              " 'test_data1769.csv',\n",
              " 'test_data367.csv',\n",
              " 'test_data282.csv',\n",
              " 'test_data757.csv',\n",
              " 'test_data912.csv',\n",
              " 'test_data1230.csv',\n",
              " 'test_data1080.csv',\n",
              " 'test_data1089.csv',\n",
              " 'test_data901.csv',\n",
              " 'test_data890.csv',\n",
              " 'test_data1624.csv',\n",
              " 'test_data1307.csv',\n",
              " 'test_data109.csv',\n",
              " 'test_data727.csv',\n",
              " 'test_data1350.csv',\n",
              " 'test_data532.csv',\n",
              " 'test_data1088.csv',\n",
              " 'test_data472.csv',\n",
              " 'test_data32.csv',\n",
              " 'test_data927.csv',\n",
              " 'test_data1356.csv',\n",
              " 'test_data1478.csv',\n",
              " 'test_data570.csv',\n",
              " 'test_data350.csv',\n",
              " 'test_data1167.csv',\n",
              " 'test_data1664.csv',\n",
              " 'test_data822.csv',\n",
              " 'test_data438.csv',\n",
              " 'test_data266.csv',\n",
              " 'test_data1083.csv',\n",
              " 'test_data11.csv',\n",
              " 'test_data288.csv',\n",
              " 'test_data821.csv',\n",
              " 'test_data1531.csv',\n",
              " 'test_data124.csv',\n",
              " 'test_data1187.csv',\n",
              " 'test_data1115.csv',\n",
              " 'test_data1138.csv',\n",
              " 'test_data1280.csv',\n",
              " 'test_data1256.csv',\n",
              " 'test_data291.csv',\n",
              " 'test_data748.csv',\n",
              " 'test_data729.csv',\n",
              " 'test_data212.csv',\n",
              " 'test_data1360.csv',\n",
              " 'test_data390.csv',\n",
              " 'test_data134.csv',\n",
              " 'test_data281.csv',\n",
              " 'test_data395.csv',\n",
              " 'test_data958.csv',\n",
              " 'test_data957.csv',\n",
              " 'test_data843.csv',\n",
              " 'test_data1191.csv',\n",
              " 'test_data381.csv',\n",
              " 'test_data516.csv',\n",
              " 'test_data565.csv',\n",
              " 'test_data1776.csv',\n",
              " 'test_data933.csv',\n",
              " 'test_data587.csv',\n",
              " 'test_data966.csv',\n",
              " 'test_data632.csv',\n",
              " 'test_data1402.csv',\n",
              " 'test_data186.csv',\n",
              " 'test_data1434.csv',\n",
              " 'test_data1357.csv',\n",
              " 'test_data309.csv',\n",
              " 'test_data108.csv',\n",
              " 'test_data1249.csv',\n",
              " 'test_data703.csv',\n",
              " 'test_data982.csv',\n",
              " 'test_data241.csv',\n",
              " 'test_data1645.csv',\n",
              " 'test_data728.csv',\n",
              " 'test_data178.csv',\n",
              " 'test_data1263.csv',\n",
              " 'test_data963.csv',\n",
              " 'test_data1161.csv',\n",
              " 'test_data549.csv',\n",
              " 'test_data1250.csv',\n",
              " 'test_data17.csv',\n",
              " 'test_data442.csv',\n",
              " 'test_data507.csv',\n",
              " 'test_data83.csv',\n",
              " 'test_data138.csv',\n",
              " 'test_data293.csv',\n",
              " 'test_data1393.csv',\n",
              " 'test_data1022.csv',\n",
              " 'test_data500.csv',\n",
              " 'test_data1620.csv',\n",
              " 'test_data1485.csv',\n",
              " 'test_data1066.csv',\n",
              " 'test_data1148.csv',\n",
              " 'test_data750.csv',\n",
              " 'test_data1592.csv',\n",
              " 'test_data219.csv',\n",
              " 'test_data470.csv',\n",
              " 'test_data225.csv',\n",
              " 'test_data300.csv',\n",
              " 'test_data1775.csv',\n",
              " 'test_data324.csv',\n",
              " 'test_data1497.csv',\n",
              " 'test_data188.csv',\n",
              " 'test_data1617.csv',\n",
              " 'test_data1500.csv',\n",
              " 'test_data1447.csv',\n",
              " 'test_data38.csv',\n",
              " 'test_data39.csv',\n",
              " 'test_data919.csv',\n",
              " 'test_data51.csv',\n",
              " 'test_data1384.csv',\n",
              " 'test_data1151.csv',\n",
              " 'test_data770.csv',\n",
              " 'test_data734.csv',\n",
              " 'test_data1065.csv',\n",
              " 'test_data459.csv',\n",
              " 'test_data1723.csv',\n",
              " 'test_data265.csv',\n",
              " 'test_data198.csv',\n",
              " 'test_data1700.csv',\n",
              " 'test_data1278.csv',\n",
              " 'test_data975.csv',\n",
              " 'test_data1093.csv',\n",
              " 'test_data1332.csv',\n",
              " 'test_data1546.csv',\n",
              " 'test_data1287.csv',\n",
              " 'test_data477.csv',\n",
              " 'test_data527.csv',\n",
              " 'test_data161.csv',\n",
              " 'test_data195.csv',\n",
              " 'test_data120.csv',\n",
              " 'test_data487.csv',\n",
              " 'test_data1506.csv',\n",
              " 'test_data1739.csv',\n",
              " 'test_data476.csv',\n",
              " 'test_data1010.csv',\n",
              " 'test_data0.csv',\n",
              " 'test_data1658.csv',\n",
              " 'test_data1614.csv',\n",
              " 'test_data326.csv',\n",
              " 'test_data1729.csv',\n",
              " 'test_data1633.csv',\n",
              " 'test_data936.csv',\n",
              " 'test_data1697.csv',\n",
              " 'test_data1007.csv',\n",
              " 'test_data1293.csv',\n",
              " 'test_data1207.csv',\n",
              " 'test_data617.csv',\n",
              " 'test_data636.csv',\n",
              " 'test_data1222.csv',\n",
              " 'test_data976.csv',\n",
              " 'test_data1174.csv',\n",
              " 'test_data711.csv',\n",
              " 'test_data368.csv',\n",
              " 'test_data1362.csv',\n",
              " 'test_data1229.csv',\n",
              " 'test_data174.csv',\n",
              " 'test_data167.csv',\n",
              " 'test_data1482.csv',\n",
              " 'test_data1458.csv',\n",
              " 'test_data384.csv',\n",
              " 'test_data1400.csv',\n",
              " 'test_data663.csv',\n",
              " 'test_data315.csv',\n",
              " 'test_data1127.csv',\n",
              " 'test_data356.csv',\n",
              " 'test_data486.csv',\n",
              " 'test_data792.csv',\n",
              " 'test_data150.csv',\n",
              " 'test_data1439.csv',\n",
              " 'test_data259.csv',\n",
              " 'test_data905.csv',\n",
              " 'test_data802.csv',\n",
              " 'test_data48.csv',\n",
              " 'test_data175.csv',\n",
              " 'test_data81.csv',\n",
              " 'test_data817.csv',\n",
              " 'test_data1002.csv',\n",
              " 'test_data798.csv',\n",
              " 'test_data717.csv',\n",
              " 'test_data585.csv',\n",
              " 'test_data169.csv',\n",
              " 'test_data489.csv',\n",
              " 'test_data1331.csv',\n",
              " 'test_data733.csv',\n",
              " 'test_data629.csv',\n",
              " 'test_data1319.csv',\n",
              " 'test_data1095.csv',\n",
              " 'test_data1108.csv',\n",
              " 'test_data132.csv',\n",
              " 'test_data707.csv',\n",
              " 'test_data1663.csv',\n",
              " 'test_data1796.csv',\n",
              " 'test_data1651.csv',\n",
              " 'test_data1.csv',\n",
              " 'test_data157.csv',\n",
              " 'test_data237.csv',\n",
              " 'test_data19.csv',\n",
              " 'test_data1217.csv',\n",
              " 'test_data143.csv',\n",
              " 'test_data615.csv',\n",
              " 'test_data660.csv',\n",
              " 'test_data331.csv',\n",
              " 'test_data1186.csv',\n",
              " 'test_data1016.csv',\n",
              " 'test_data1282.csv',\n",
              " 'test_data5.csv',\n",
              " 'test_data1585.csv',\n",
              " 'test_data1417.csv',\n",
              " 'test_data273.csv',\n",
              " 'test_data54.csv',\n",
              " 'test_data1206.csv',\n",
              " 'test_data979.csv',\n",
              " 'test_data1600.csv',\n",
              " 'test_data1561.csv',\n",
              " 'test_data891.csv',\n",
              " 'test_data465.csv',\n",
              " 'test_data575.csv',\n",
              " 'test_data191.csv',\n",
              " 'test_data147.csv',\n",
              " 'test_data77.csv',\n",
              " 'test_data1101.csv',\n",
              " 'test_data313.csv',\n",
              " 'test_data1533.csv',\n",
              " 'test_data1395.csv',\n",
              " 'test_data1210.csv',\n",
              " 'test_data1145.csv',\n",
              " 'test_data389.csv',\n",
              " 'test_data1489.csv',\n",
              " 'test_data482.csv',\n",
              " 'test_data785.csv',\n",
              " 'test_data1121.csv',\n",
              " 'test_data488.csv',\n",
              " 'test_data1311.csv',\n",
              " 'test_data871.csv',\n",
              " 'test_data768.csv',\n",
              " 'test_data311.csv',\n",
              " 'test_data1406.csv',\n",
              " 'test_data49.csv',\n",
              " 'test_data92.csv',\n",
              " 'test_data741.csv',\n",
              " 'test_data781.csv',\n",
              " 'test_data1212.csv',\n",
              " 'test_data449.csv',\n",
              " 'test_data591.csv',\n",
              " 'test_data626.csv',\n",
              " 'test_data1709.csv',\n",
              " 'test_data1003.csv',\n",
              " 'test_data788.csv',\n",
              " 'test_data1133.csv',\n",
              " 'test_data1295.csv',\n",
              " 'test_data596.csv',\n",
              " 'test_data1130.csv',\n",
              " 'test_data1615.csv',\n",
              " 'test_data1268.csv',\n",
              " 'test_data439.csv',\n",
              " 'test_data386.csv',\n",
              " 'test_data659.csv',\n",
              " 'test_data1551.csv',\n",
              " 'test_data949.csv',\n",
              " 'test_data1152.csv',\n",
              " 'test_data1100.csv',\n",
              " 'test_data751.csv',\n",
              " 'test_data745.csv',\n",
              " 'test_data1735.csv',\n",
              " 'test_data1604.csv',\n",
              " 'test_data1055.csv',\n",
              " 'test_data66.csv',\n",
              " 'test_data1509.csv',\n",
              " 'test_data887.csv',\n",
              " 'test_data797.csv',\n",
              " 'test_data888.csv',\n",
              " 'test_data1405.csv',\n",
              " 'test_data1791.csv',\n",
              " 'test_data302.csv',\n",
              " 'test_data436.csv',\n",
              " 'test_data1200.csv',\n",
              " 'test_data1086.csv',\n",
              " 'test_data1001.csv',\n",
              " 'test_data1580.csv',\n",
              " 'test_data605.csv',\n",
              " 'test_data597.csv',\n",
              " 'test_data423.csv',\n",
              " 'test_data455.csv',\n",
              " 'test_data1754.csv',\n",
              " 'test_data783.csv',\n",
              " 'test_data1239.csv',\n",
              " 'test_data833.csv',\n",
              " 'test_data183.csv',\n",
              " 'test_data208.csv',\n",
              " 'test_data647.csv',\n",
              " 'test_data1258.csv',\n",
              " 'test_data1487.csv',\n",
              " 'test_data978.csv',\n",
              " 'test_data863.csv',\n",
              " 'test_data229.csv',\n",
              " 'test_data1349.csv',\n",
              " 'test_data904.csv',\n",
              " 'test_data1582.csv',\n",
              " 'test_data1132.csv',\n",
              " 'test_data1638.csv',\n",
              " 'test_data772.csv',\n",
              " 'test_data1459.csv',\n",
              " 'test_data876.csv',\n",
              " 'test_data1323.csv',\n",
              " 'test_data1048.csv',\n",
              " 'test_data721.csv',\n",
              " 'test_data1236.csv',\n",
              " 'test_data604.csv',\n",
              " 'test_data182.csv',\n",
              " 'test_data72.csv',\n",
              " 'test_data431.csv',\n",
              " 'test_data989.csv',\n",
              " 'test_data913.csv',\n",
              " 'test_data608.csv',\n",
              " 'test_data42.csv',\n",
              " 'test_data1601.csv',\n",
              " 'test_data159.csv',\n",
              " 'test_data653.csv',\n",
              " 'test_data518.csv',\n",
              " 'test_data690.csv',\n",
              " 'test_data481.csv',\n",
              " 'test_data1588.csv',\n",
              " 'test_data46.csv',\n",
              " 'test_data1722.csv',\n",
              " 'test_data253.csv',\n",
              " 'test_data790.csv',\n",
              " 'test_data1616.csv',\n",
              " 'test_data1747.csv',\n",
              " 'test_data594.csv',\n",
              " 'test_data388.csv',\n",
              " 'test_data9.csv',\n",
              " 'test_data1351.csv',\n",
              " 'test_data347.csv',\n",
              " 'test_data1173.csv',\n",
              " 'test_data68.csv',\n",
              " 'test_data945.csv',\n",
              " 'test_data1274.csv',\n",
              " 'test_data1135.csv',\n",
              " 'test_data712.csv',\n",
              " 'test_data1681.csv',\n",
              " 'test_data1748.csv',\n",
              " 'test_data418.csv',\n",
              " 'test_data251.csv',\n",
              " 'test_data409.csv',\n",
              " 'test_data284.csv',\n",
              " 'test_data519.csv',\n",
              " 'test_data1361.csv',\n",
              " 'test_data1656.csv',\n",
              " 'test_data1027.csv',\n",
              " 'test_data1315.csv',\n",
              " 'test_data1682.csv',\n",
              " 'test_data630.csv',\n",
              " 'test_data601.csv',\n",
              " 'test_data1394.csv',\n",
              " 'test_data889.csv',\n",
              " 'test_data105.csv',\n",
              " 'test_data1654.csv',\n",
              " 'test_data1764.csv',\n",
              " 'test_data364.csv',\n",
              " 'test_data1255.csv',\n",
              " 'test_data1199.csv',\n",
              " 'test_data1403.csv',\n",
              " 'test_data879.csv',\n",
              " 'test_data128.csv',\n",
              " 'test_data335.csv',\n",
              " 'test_data1784.csv',\n",
              " 'test_data1686.csv',\n",
              " 'test_data1058.csv',\n",
              " 'test_data34.csv',\n",
              " 'test_data454.csv',\n",
              " 'test_data495.csv',\n",
              " 'test_data255.csv',\n",
              " 'test_data1225.csv',\n",
              " 'test_data1555.csv',\n",
              " 'test_data199.csv',\n",
              " 'test_data689.csv',\n",
              " 'test_data529.csv',\n",
              " 'test_data358.csv',\n",
              " 'test_data1134.csv',\n",
              " 'test_data1369.csv',\n",
              " 'test_data522.csv',\n",
              " 'test_data1211.csv',\n",
              " 'test_data1716.csv',\n",
              " 'test_data1516.csv',\n",
              " 'test_data424.csv',\n",
              " 'test_data22.csv',\n",
              " 'test_data1365.csv',\n",
              " 'test_data618.csv',\n",
              " 'test_data1572.csv',\n",
              " 'test_data998.csv',\n",
              " 'test_data1105.csv',\n",
              " 'test_data1164.csv',\n",
              " 'test_data1275.csv',\n",
              " 'test_data807.csv',\n",
              " 'test_data1109.csv',\n",
              " 'test_data1644.csv',\n",
              " 'test_data1742.csv',\n",
              " 'test_data127.csv',\n",
              " 'test_data1117.csv',\n",
              " 'test_data946.csv',\n",
              " 'test_data1571.csv',\n",
              " 'test_data1684.csv',\n",
              " 'test_data643.csv',\n",
              " 'test_data1504.csv',\n",
              " 'test_data1154.csv',\n",
              " 'test_data1131.csv',\n",
              " 'test_data301.csv',\n",
              " 'test_data1544.csv',\n",
              " 'test_data421.csv',\n",
              " 'test_data705.csv',\n",
              " 'test_data884.csv',\n",
              " 'test_data536.csv',\n",
              " 'test_data875.csv',\n",
              " 'test_data1786.csv',\n",
              " 'test_data1483.csv',\n",
              " 'test_data392.csv',\n",
              " 'test_data318.csv',\n",
              " 'test_data484.csv',\n",
              " 'test_data320.csv',\n",
              " 'test_data825.csv',\n",
              " 'test_data1142.csv',\n",
              " 'test_data1286.csv',\n",
              " 'test_data502.csv',\n",
              " 'test_data672.csv',\n",
              " 'test_data1358.csv',\n",
              " 'test_data353.csv',\n",
              " 'test_data1528.csv',\n",
              " 'test_data1288.csv',\n",
              " 'test_data943.csv',\n",
              " 'test_data1197.csv',\n",
              " 'test_data479.csv',\n",
              " 'test_data515.csv',\n",
              " 'test_data837.csv',\n",
              " 'test_data271.csv',\n",
              " 'test_data524.csv',\n",
              " 'test_data1713.csv',\n",
              " 'test_data323.csv',\n",
              " 'test_data365.csv',\n",
              " 'test_data656.csv',\n",
              " 'test_data50.csv',\n",
              " 'test_data1685.csv',\n",
              " 'test_data1308.csv',\n",
              " 'test_data403.csv',\n",
              " 'test_data753.csv',\n",
              " 'test_data961.csv',\n",
              " 'test_data190.csv',\n",
              " 'test_data1075.csv',\n",
              " 'test_data1257.csv',\n",
              " 'test_data1514.csv',\n",
              " 'test_data867.csv',\n",
              " 'test_data1241.csv',\n",
              " 'test_data548.csv',\n",
              " 'test_data348.csv',\n",
              " 'test_data654.csv',\n",
              " 'test_data378.csv',\n",
              " 'test_data478.csv',\n",
              " 'test_data1231.csv',\n",
              " 'test_data542.csv',\n",
              " 'test_data1289.csv',\n",
              " 'test_data1147.csv',\n",
              " 'test_data207.csv',\n",
              " 'test_data329.csv',\n",
              " 'test_data473.csv',\n",
              " 'test_data1667.csv',\n",
              " 'test_data1221.csv',\n",
              " 'test_data1756.csv',\n",
              " 'test_data1787.csv',\n",
              " 'test_data677.csv',\n",
              " 'test_data1054.csv',\n",
              " 'test_data1481.csv',\n",
              " 'test_data847.csv',\n",
              " 'test_data1501.csv',\n",
              " 'test_data1375.csv',\n",
              " 'test_data1039.csv',\n",
              " 'test_data492.csv',\n",
              " 'test_data997.csv',\n",
              " 'test_data801.csv',\n",
              " 'test_data171.csv',\n",
              " 'test_data1581.csv',\n",
              " 'test_data192.csv',\n",
              " 'test_data1464.csv',\n",
              " 'test_data1396.csv',\n",
              " 'test_data540.csv',\n",
              " 'test_data44.csv',\n",
              " 'test_data110.csv',\n",
              " 'test_data777.csv',\n",
              " 'test_data1502.csv',\n",
              " 'test_data1549.csv',\n",
              " 'test_data67.csv',\n",
              " 'test_data1612.csv',\n",
              " 'test_data1041.csv',\n",
              " 'test_data1774.csv',\n",
              " 'test_data261.csv',\n",
              " 'test_data804.csv',\n",
              " 'test_data1422.csv',\n",
              " 'test_data1136.csv',\n",
              " 'test_data248.csv',\n",
              " 'test_data1714.csv',\n",
              " 'test_data1074.csv',\n",
              " 'test_data616.csv',\n",
              " 'test_data722.csv',\n",
              " 'test_data1618.csv',\n",
              " 'test_data1630.csv',\n",
              " 'test_data1398.csv',\n",
              " 'test_data1556.csv',\n",
              " 'test_data818.csv',\n",
              " 'test_data1031.csv',\n",
              " 'test_data173.csv',\n",
              " 'test_data697.csv',\n",
              " 'test_data1523.csv',\n",
              " 'test_data133.csv',\n",
              " 'test_data1653.csv',\n",
              " 'test_data1092.csv',\n",
              " 'test_data1034.csv',\n",
              " 'test_data1493.csv',\n",
              " 'test_data1107.csv',\n",
              " 'test_data1463.csv',\n",
              " 'test_data149.csv',\n",
              " 'test_data1437.csv',\n",
              " 'test_data1781.csv',\n",
              " 'test_data547.csv',\n",
              " 'test_data1744.csv',\n",
              " 'test_data1407.csv',\n",
              " 'test_data1192.csv',\n",
              " 'test_data249.csv',\n",
              " 'test_data651.csv',\n",
              " 'test_data1550.csv',\n",
              " 'test_data448.csv',\n",
              " 'test_data1382.csv',\n",
              " 'test_data60.csv',\n",
              " 'test_data1797.csv',\n",
              " 'test_data63.csv',\n",
              " 'test_data859.csv',\n",
              " 'test_data1476.csv',\n",
              " 'test_data1220.csv',\n",
              " 'test_data354.csv',\n",
              " 'test_data1411.csv',\n",
              " 'test_data1123.csv',\n",
              " 'test_data37.csv',\n",
              " 'test_data1160.csv',\n",
              " 'test_data1732.csv',\n",
              " 'test_data1334.csv',\n",
              " 'test_data577.csv',\n",
              " 'test_data1364.csv',\n",
              " 'test_data713.csv',\n",
              " 'test_data113.csv',\n",
              " 'test_data950.csv',\n",
              " 'test_data1642.csv',\n",
              " 'test_data809.csv',\n",
              " 'test_data944.csv',\n",
              " 'test_data902.csv',\n",
              " 'test_data336.csv',\n",
              " 'test_data1701.csv',\n",
              " 'test_data1520.csv',\n",
              " 'test_data1119.csv',\n",
              " 'test_data444.csv',\n",
              " 'test_data612.csv',\n",
              " 'test_data243.csv',\n",
              " 'test_data494.csv',\n",
              " 'test_data417.csv',\n",
              " 'test_data1018.csv',\n",
              " 'test_data383.csv',\n",
              " 'test_data1705.csv',\n",
              " 'test_data1381.csv',\n",
              " 'test_data650.csv',\n",
              " 'test_data925.csv',\n",
              " 'test_data765.csv',\n",
              " 'test_data410.csv',\n",
              " 'test_data499.csv',\n",
              " 'test_data909.csv',\n",
              " 'test_data642.csv',\n",
              " 'test_data304.csv',\n",
              " 'test_data1466.csv',\n",
              " 'test_data1116.csv',\n",
              " 'test_data539.csv',\n",
              " 'test_data1260.csv',\n",
              " 'test_data1499.csv',\n",
              " 'test_data1628.csv',\n",
              " 'test_data1177.csv',\n",
              " 'test_data30.csv',\n",
              " 'test_data1202.csv',\n",
              " 'test_data838.csv',\n",
              " 'test_data620.csv',\n",
              " 'test_data1036.csv',\n",
              " 'test_data523.csv',\n",
              " 'test_data1013.csv',\n",
              " 'test_data69.csv',\n",
              " 'test_data1622.csv',\n",
              " 'test_data129.csv',\n",
              " 'test_data53.csv',\n",
              " 'test_data1322.csv',\n",
              " 'test_data1158.csv',\n",
              " 'test_data878.csv',\n",
              " 'test_data624.csv',\n",
              " 'test_data1298.csv',\n",
              " 'test_data1374.csv',\n",
              " 'test_data1621.csv',\n",
              " 'test_data983.csv',\n",
              " 'test_data631.csv',\n",
              " 'test_data648.csv',\n",
              " 'test_data242.csv',\n",
              " 'test_data1456.csv',\n",
              " 'test_data1518.csv',\n",
              " 'test_data700.csv',\n",
              " 'test_data1440.csv',\n",
              " 'test_data1276.csv',\n",
              " 'test_data1150.csv',\n",
              " 'test_data746.csv',\n",
              " 'test_data1057.csv',\n",
              " 'test_data864.csv',\n",
              " 'test_data1743.csv',\n",
              " 'test_data1443.csv',\n",
              " 'test_data848.csv',\n",
              " 'test_data512.csv',\n",
              " 'test_data1162.csv',\n",
              " 'test_data257.csv',\n",
              " 'test_data1120.csv',\n",
              " 'test_data865.csv',\n",
              " 'test_data586.csv',\n",
              " 'test_data1175.csv',\n",
              " 'test_data546.csv',\n",
              " 'test_data464.csv',\n",
              " 'test_data1176.csv',\n",
              " 'test_data332.csv',\n",
              " 'test_data578.csv',\n",
              " 'test_data782.csv',\n",
              " 'test_data275.csv',\n",
              " 'test_data170.csv',\n",
              " 'test_data800.csv',\n",
              " 'test_data52.csv',\n",
              " 'test_data373.csv',\n",
              " 'test_data377.csv',\n",
              " 'test_data375.csv',\n",
              " 'test_data412.csv',\n",
              " 'test_data1449.csv',\n",
              " 'test_data1330.csv',\n",
              " 'test_data726.csv',\n",
              " 'test_data41.csv',\n",
              " 'test_data553.csv',\n",
              " 'test_data985.csv',\n",
              " 'test_data584.csv',\n",
              " 'test_data126.csv',\n",
              " 'test_data1648.csv',\n",
              " 'test_data280.csv',\n",
              " 'test_data1416.csv',\n",
              " 'test_data906.csv',\n",
              " 'test_data1455.csv',\n",
              " 'test_data1179.csv',\n",
              " 'test_data680.csv',\n",
              " 'test_data534.csv',\n",
              " 'test_data1659.csv',\n",
              " 'test_data877.csv',\n",
              " 'test_data1666.csv',\n",
              " 'test_data1435.csv',\n",
              " 'test_data245.csv',\n",
              " 'test_data854.csv',\n",
              " 'test_data43.csv',\n",
              " 'test_data1575.csv',\n",
              " 'test_data977.csv',\n",
              " 'test_data430.csv',\n",
              " 'test_data362.csv',\n",
              " 'test_data1389.csv',\n",
              " 'test_data1408.csv',\n",
              " 'test_data235.csv',\n",
              " 'test_data969.csv',\n",
              " 'test_data679.csv',\n",
              " 'test_data1259.csv',\n",
              " 'test_data1484.csv',\n",
              " 'test_data535.csv',\n",
              " 'test_data794.csv',\n",
              " 'test_data483.csv',\n",
              " 'test_data369.csv',\n",
              " 'test_data1683.csv',\n",
              " 'test_data426.csv',\n",
              " 'test_data972.csv',\n",
              " 'test_data1227.csv',\n",
              " 'test_data686.csv',\n",
              " 'test_data1636.csv',\n",
              " 'test_data981.csv',\n",
              " 'test_data287.csv',\n",
              " 'test_data1545.csv',\n",
              " 'test_data1284.csv',\n",
              " 'test_data18.csv',\n",
              " 'test_data771.csv',\n",
              " 'test_data1789.csv',\n",
              " 'test_data609.csv',\n",
              " 'test_data307.csv',\n",
              " 'test_data330.csv',\n",
              " 'test_data1310.csv',\n",
              " 'test_data55.csv',\n",
              " 'test_data283.csv',\n",
              " 'test_data1269.csv',\n",
              " 'test_data861.csv',\n",
              " 'test_data724.csv',\n",
              " 'test_data1770.csv',\n",
              " 'test_data391.csv',\n",
              " 'test_data793.csv',\n",
              " 'test_data40.csv',\n",
              " 'test_data393.csv',\n",
              " 'test_data6.csv',\n",
              " 'test_data357.csv',\n",
              " 'test_data1273.csv',\n",
              " 'test_data1767.csv',\n",
              " 'test_data1297.csv',\n",
              " 'test_data1077.csv',\n",
              " 'test_data895.csv',\n",
              " 'test_data1429.csv',\n",
              " 'test_data471.csv',\n",
              " 'test_data611.csv',\n",
              " 'test_data1097.csv',\n",
              " 'test_data883.csv',\n",
              " 'test_data696.csv',\n",
              " 'test_data447.csv',\n",
              " 'test_data1450.csv',\n",
              " 'test_data123.csv',\n",
              " 'test_data1446.csv',\n",
              " 'test_data1532.csv',\n",
              " 'test_data111.csv',\n",
              " 'test_data1674.csv',\n",
              " 'test_data1589.csv',\n",
              " 'test_data994.csv',\n",
              " 'test_data1762.csv',\n",
              " 'test_data511.csv',\n",
              " 'test_data1678.csv',\n",
              " 'test_data920.csv',\n",
              " 'test_data1557.csv',\n",
              " 'test_data1430.csv',\n",
              " 'test_data333.csv',\n",
              " 'test_data1627.csv',\n",
              " 'test_data1205.csv',\n",
              " 'test_data1602.csv',\n",
              " 'test_data1426.csv',\n",
              " 'test_data513.csv',\n",
              " 'test_data856.csv',\n",
              " 'test_data376.csv',\n",
              " 'test_data882.csv',\n",
              " 'test_data999.csv',\n",
              " 'test_data815.csv',\n",
              " 'test_data10.csv',\n",
              " 'test_data1558.csv',\n",
              " 'test_data862.csv',\n",
              " 'test_data1326.csv',\n",
              " 'test_data1707.csv',\n",
              " 'test_data1090.csv',\n",
              " 'test_data1266.csv',\n",
              " 'test_data1184.csv',\n",
              " 'test_data400.csv',\n",
              " 'test_data23.csv',\n",
              " 'test_data562.csv',\n",
              " 'test_data21.csv',\n",
              " 'test_data334.csv',\n",
              " 'test_data510.csv',\n",
              " 'test_data1773.csv',\n",
              " 'test_data1623.csv',\n",
              " 'test_data399.csv',\n",
              " 'test_data990.csv',\n",
              " 'test_data152.csv',\n",
              " 'test_data1011.csv',\n",
              " 'test_data79.csv',\n",
              " 'test_data1025.csv',\n",
              " 'test_data272.csv',\n",
              " 'test_data1591.csv',\n",
              " 'test_data1062.csv',\n",
              " 'test_data1584.csv',\n",
              " 'test_data533.csv',\n",
              " 'test_data1050.csv',\n",
              " 'test_data1313.csv',\n",
              " 'test_data970.csv',\n",
              " 'test_data95.csv',\n",
              " 'test_data1712.csv',\n",
              " 'test_data720.csv',\n",
              " 'test_data203.csv',\n",
              " 'test_data1755.csv',\n",
              " 'test_data1141.csv',\n",
              " 'test_data714.csv',\n",
              " 'test_data135.csv',\n",
              " 'test_data285.csv',\n",
              " 'test_data1283.csv',\n",
              " 'test_data1468.csv',\n",
              " 'test_data830.csv',\n",
              " 'test_data849.csv',\n",
              " 'test_data1267.csv',\n",
              " 'test_data743.csv',\n",
              " 'test_data1519.csv',\n",
              " 'test_data1035.csv',\n",
              " 'test_data1472.csv',\n",
              " 'test_data1710.csv',\n",
              " 'test_data122.csv',\n",
              " 'test_data1237.csv',\n",
              " 'test_data952.csv',\n",
              " 'test_data778.csv',\n",
              " 'test_data1448.csv',\n",
              " 'test_data1688.csv',\n",
              " 'test_data1699.csv',\n",
              " 'test_data1046.csv',\n",
              " 'test_data774.csv',\n",
              " 'test_data1009.csv',\n",
              " 'test_data569.csv',\n",
              " 'test_data1583.csv',\n",
              " 'test_data1721.csv',\n",
              " 'test_data1085.csv',\n",
              " 'test_data845.csv',\n",
              " 'test_data1188.csv',\n",
              " 'test_data828.csv',\n",
              " 'test_data413.csv',\n",
              " 'test_data1340.csv',\n",
              " 'test_data36.csv',\n",
              " 'test_data761.csv',\n",
              " 'test_data744.csv',\n",
              " 'test_data204.csv',\n",
              " 'test_data263.csv',\n",
              " 'test_data317.csv',\n",
              " 'test_data1099.csv',\n",
              " 'test_data844.csv',\n",
              " 'test_data866.csv',\n",
              " 'test_data968.csv',\n",
              " 'test_data1226.csv',\n",
              " 'test_data831.csv',\n",
              " 'test_data340.csv',\n",
              " 'test_data1673.csv',\n",
              " 'test_data1345.csv',\n",
              " 'test_data250.csv',\n",
              " 'test_data543.csv',\n",
              " 'test_data148.csv',\n",
              " 'test_data503.csv',\n",
              " 'test_data1203.csv',\n",
              " 'test_data1511.csv',\n",
              " 'test_data1314.csv',\n",
              " 'test_data1038.csv',\n",
              " 'test_data164.csv',\n",
              " 'test_data7.csv',\n",
              " 'test_data573.csv',\n",
              " 'test_data694.csv',\n",
              " 'test_data555.csv',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4-UVssGNw22"
      },
      "outputs": [],
      "source": [
        "blanks = np.zeros(1800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNe2tKZ-NbA3",
        "outputId": "6cb04944-5ecb-4aba-9abf-7e6ba11adec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 12ms/step - loss: 8.8866 - accuracy: 0.0583\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.06      0.11      1800\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.00      0.00      0.00         0\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       0.00      0.00      0.00         0\n",
            "         8.0       0.00      0.00      0.00         0\n",
            "         9.0       0.00      0.00      0.00         0\n",
            "        10.0       0.00      0.00      0.00         0\n",
            "        11.0       0.00      0.00      0.00         0\n",
            "        12.0       0.00      0.00      0.00         0\n",
            "        13.0       0.00      0.00      0.00         0\n",
            "        14.0       0.00      0.00      0.00         0\n",
            "        15.0       0.00      0.00      0.00         0\n",
            "        16.0       0.00      0.00      0.00         0\n",
            "        17.0       0.00      0.00      0.00         0\n",
            "        18.0       0.00      0.00      0.00         0\n",
            "        19.0       0.00      0.00      0.00         0\n",
            "        20.0       0.00      0.00      0.00         0\n",
            "        21.0       0.00      0.00      0.00         0\n",
            "        22.0       0.00      0.00      0.00         0\n",
            "        23.0       0.00      0.00      0.00         0\n",
            "        24.0       0.00      0.00      0.00         0\n",
            "        25.0       0.00      0.00      0.00         0\n",
            "        26.0       0.00      0.00      0.00         0\n",
            "        27.0       0.00      0.00      0.00         0\n",
            "        28.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.06      1800\n",
            "   macro avg       0.03      0.00      0.00      1800\n",
            "weighted avg       1.00      0.06      0.11      1800\n",
            "\n",
            "F1-score is computed based on macro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "predictions, eval = model.predict(test_preprocessed, blanks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if doing 3 label categories\n",
        "predictions_ub, eval_ub = model_ub.predict(test_preprocessed, blanks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAx8wyoGgHeb",
        "outputId": "a6d417c2-ba4f-4e5f-e9a2-2eddf72c8f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 1s 13ms/step - loss: 4.4963 - accuracy: 0.2950\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.29      0.46      9000\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.29      9000\n",
            "   macro avg       0.25      0.07      0.11      9000\n",
            "weighted avg       1.00      0.29      0.46      9000\n",
            "\n",
            "F1-score is computed based on macro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if doing 3 label categories\n",
        "predictions_ma, eval_ma = model_ma.predict(test_preprocessed, blanks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv9jGbKAlGWD",
        "outputId": "2b9e4d01-3468-483c-8a9d-ed9533136cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 1s 13ms/step - loss: 3.9791 - accuracy: 0.5869\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.59      0.74      9000\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.59      9000\n",
            "   macro avg       0.25      0.15      0.18      9000\n",
            "weighted avg       1.00      0.59      0.74      9000\n",
            "\n",
            "F1-score is computed based on macro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if doing 3 label categories\n",
        "predictions_mp, eval_mp = model_mp.predict(test_preprocessed, blanks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsKXeeE2lIvO",
        "outputId": "19769255-2c93-4b1a-8a2f-3737bdfce1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 1s 13ms/step - loss: 3.8930 - accuracy: 0.5667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.57      0.72      9000\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.57      9000\n",
            "   macro avg       0.20      0.11      0.14      9000\n",
            "weighted avg       1.00      0.57      0.72      9000\n",
            "\n",
            "F1-score is computed based on macro\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if doing 3 label categories\n",
        "label_dict = {\n",
        "    '000' : 0,\n",
        "    '100' : 1,\n",
        "    '200' : 2,\n",
        "    '300' : 3,\n",
        "    '010' : 4,\n",
        "    '020' : 5,\n",
        "    '030' : 6,\n",
        "    '001' : 7,\n",
        "    '002' : 8,\n",
        "    '003' : 9,\n",
        "    '004' : 10,\n",
        "    '110' : 11,\n",
        "    '210' : 12,\n",
        "    '310' : 13,\n",
        "    '120' : 14,\n",
        "    '220' : 15,\n",
        "    '320' : 16,\n",
        "    '130' : 17,\n",
        "    '230' : 18,\n",
        "    '330' : 19,\n",
        "    '101' : 20,\n",
        "    '201' : 21,\n",
        "    '301' : 22,\n",
        "    '102' : 23,\n",
        "    '202' : 24,\n",
        "    '302' : 25,\n",
        "    '103' : 26,\n",
        "    '203' : 27,\n",
        "    '303' : 28,\n",
        "}"
      ],
      "metadata": {
        "id": "E6qKWQsbgTI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if doing 3 label categories\n",
        "predictions = {}\n",
        "predictions['y_pred']=[]\n",
        "for b,a,p in zip(predictions_ub['y_pred'],predictions_ma['y_pred'],predictions_mp['y_pred']):\n",
        "    try:\n",
        "        temp = str(b)+str(a)+str(p)\n",
        "        predictions['y_pred'].append(label_dict[temp])\n",
        "    except:\n",
        "        predictions['y_pred'].append(29)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "owX8a60PgzlV",
        "outputId": "b1b1eed9-db81-4371-a2d7-1a8873f4880d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c635b1c6fed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_ub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions_mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions_ub' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the number of predictions of each labels"
      ],
      "metadata": {
        "id": "5w5QR1zWKGvC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIXQbbE3OHvI",
        "outputId": "32991798-1152-4552-92c1-de87e7042409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys([24, 12, 17, 15, 27, 14, 9, 8, 10, 16, 0, 4, 13, 28, 11, 20, 23, 3, 25, 5, 18, 2, 19, 7, 21, 22, 1, 26, 6])\n",
            "dict_values([87, 40, 40, 44, 130, 31, 112, 248, 64, 69, 105, 53, 76, 49, 30, 38, 71, 40, 49, 162, 27, 20, 33, 35, 40, 16, 36, 27, 28])\n"
          ]
        }
      ],
      "source": [
        "nums = Counter(predictions['y_pred']).values()\n",
        "keys = Counter(predictions['y_pred']).keys()\n",
        "print(keys)\n",
        "print(nums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_c2pJrBnPL5F",
        "outputId": "3db54239-2d0c-40a0-85ea-646374118670"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               filename  code\n",
              "0        test_data0.csv   0.0\n",
              "1        test_data1.csv  16.0\n",
              "2        test_data2.csv  13.0\n",
              "3        test_data3.csv   NaN\n",
              "4        test_data4.csv   NaN\n",
              "...                 ...   ...\n",
              "1795  test_data1795.csv   NaN\n",
              "1796  test_data1796.csv   NaN\n",
              "1797  test_data1797.csv   NaN\n",
              "1798  test_data1798.csv   NaN\n",
              "1799  test_data1799.csv   NaN\n",
              "\n",
              "[1800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c224fa47-929a-45ba-a9cd-3c9a1298b116\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_data0.csv</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_data1.csv</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_data2.csv</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_data3.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_data4.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>test_data1795.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>test_data1796.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>test_data1797.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>test_data1798.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>test_data1799.csv</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c224fa47-929a-45ba-a9cd-3c9a1298b116')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c224fa47-929a-45ba-a9cd-3c9a1298b116 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c224fa47-929a-45ba-a9cd-3c9a1298b116');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "submission = pd.read_csv('/content/drive/Shareddrives/Hackathon_Week11_Smart_Maintenance/sample_submission.csv')\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "tQQEEZxiPBjF",
        "outputId": "9932b19f-d8e3-4677-83c3-52432bbe6398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1800/1800 [00:00<00:00, 1884.23it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               filename  code\n",
              "0        test_data0.csv     0\n",
              "1        test_data1.csv     5\n",
              "2        test_data2.csv    13\n",
              "3        test_data3.csv     2\n",
              "4        test_data4.csv    27\n",
              "...                 ...   ...\n",
              "1795  test_data1795.csv     0\n",
              "1796  test_data1796.csv     0\n",
              "1797  test_data1797.csv     5\n",
              "1798  test_data1798.csv     8\n",
              "1799  test_data1799.csv    27\n",
              "\n",
              "[1800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ddd4285-fbe8-4081-a34b-9a2d1c33c4b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_data0.csv</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_data1.csv</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_data2.csv</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_data3.csv</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_data4.csv</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>test_data1795.csv</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>test_data1796.csv</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>test_data1797.csv</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>test_data1798.csv</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>test_data1799.csv</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ddd4285-fbe8-4081-a34b-9a2d1c33c4b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ddd4285-fbe8-4081-a34b-9a2d1c33c4b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ddd4285-fbe8-4081-a34b-9a2d1c33c4b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "for i in tqdm(range(1800)):\n",
        "    filename = file_list[i]\n",
        "    label = predictions['y_pred'][i]\n",
        "    submission.loc[submission['filename']==filename, 'code'] = label\n",
        "submission['code'] = submission['code'].apply(lambda x: int(x))\n",
        "submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf1hW_E8QOme"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('/content/drive/MyDrive/week11_sub_eeg_weiner_600and1200.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Week11_SmartMaintenance.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1zVjJbBeEuCiRl6aWrJOaRyaj3qDZ6T4S",
      "authorship_tag": "ABX9TyPw5CGxgwJJaTGRyGKrxmW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}